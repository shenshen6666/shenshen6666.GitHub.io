<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://shenshen6666.GitHub.io</id>
    <title>申申丫的</title>
    <updated>2024-05-04T13:57:55.496Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://shenshen6666.GitHub.io"/>
    <link rel="self" href="https://shenshen6666.GitHub.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://shenshen6666.GitHub.io/images/avatar.png</logo>
    <icon>https://shenshen6666.GitHub.io/favicon.ico</icon>
    <rights>All rights reserved 2024, 申申丫的</rights>
    <entry>
        <title type="html"><![CDATA[使用 Spring Security 实现基于 Key 的认证]]></title>
        <id>https://shenshen6666.GitHub.io/post/shi-yong-spring-security-shi-xian-ji-yu-key-de-ren-zheng/</id>
        <link href="https://shenshen6666.GitHub.io/post/shi-yong-spring-security-shi-xian-ji-yu-key-de-ren-zheng/">
        </link>
        <updated>2024-04-24T15:19:01.000Z</updated>
        <content type="html"><![CDATA[<h3 id="教程使用-spring-security-实现基于-key-的认证">教程：使用 Spring Security 实现基于 Key 的认证</h3>
<p>在 Web 应用程序中，保护用户数据和敏感信息是至关重要的。Spring Security 是一个功能强大的框架，可以帮助我们轻松实现身份验证和授权功能。本教程将指导你如何使用 Spring Security 实现基于 Key 的认证，确保只有持有有效 Key 的用户才能访问受保护的资源。</p>
<h3 id="1-准备工作">1. 准备工作</h3>
<p>在开始之前，请确保你的项目已经集成了 Spring Security，并且具有基本的配置。如果你还没有集成 Spring Security，请按照以下步骤进行集成：</p>
<h4 id="集成-spring-security-教程">集成 Spring Security 教程：</h4>
<ol>
<li>
<p><strong>添加 Maven 依赖</strong>：<br>
在项目的 <code>pom.xml</code> 文件中添加 Spring Security 的 Maven 依赖：</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li>
<p><strong>创建 Spring Security 配置类</strong>：<br>
创建一个配置类，用于配置 Spring Security。这个配置类需要继承自 <code>WebSecurityConfigurerAdapter</code> 类，并添加 <code>@EnableWebSecurity</code> 注解。</p>
<pre><code class="language-java">import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;

@Configuration
@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {
    // 这里可以配置安全规则和其他相关的设置
}
</code></pre>
</li>
<li>
<p><strong>配置安全规则</strong>：<br>
在 <code>SecurityConfig</code> 类中，通过重写 <code>configure(HttpSecurity http)</code> 方法来配置安全规则。</p>
<pre><code class="language-java">@Override
protected void configure(HttpSecurity http) throws Exception {
    http
        .authorizeRequests()
            .antMatchers(&quot;/public/**&quot;).permitAll()
            .anyRequest().authenticated()
            .and()
        .formLogin()
            .loginPage(&quot;/login&quot;)
            .permitAll()
            .and()
        .logout()
            .permitAll();
}
</code></pre>
</li>
</ol>
<h3 id="2-创建-keyauthenticationconverter">2. 创建 KeyAuthenticationConverter</h3>
<p>首先，我们需要创建一个类 <code>KeyAuthenticationConverter</code> 来处理从请求中提取 Key 并转换为认证对象的逻辑。该类需要实现 Spring Security 的 <code>AuthenticationConverter</code> 接口。</p>
<pre><code class="language-java">// KeyAuthenticationConverter.java
public class KeyAuthenticationConverter implements AuthenticationConverter {
    // 实现逻辑...
    // 获取认证key 
    // 如果请求头中没有认证key，则尝试从请求参数中获取
    // 如果请求参数中没有认证key，则尝试从Cookie中获取
    return new KeyAuthenticationToken(key)
}
</code></pre>
<h3 id="3-创建-keyauthenticationprovider">3. 创建 KeyAuthenticationProvider</h3>
<p>接下来，我们需要创建一个认证提供者 <code>KeyAuthenticationProvider</code>，用于验证从 <code>KeyAuthenticationConverter</code> 中提取的认证对象。该类需要实现 Spring Security 的 <code>AuthenticationProvider</code> 接口。</p>
<pre><code class="language-java">// KeyAuthenticationProvider.java
public class KeyAuthenticationProvider implements AuthenticationProvider {
    // 实现逻辑...
    // 从KeyAuthenticationToken中获取认证key
    // 根据认证key查询key是否有请求权限
    // 根据认证key查询用户信息,找不到用户则表示key异常
    // 验证用户状态
    return new UserAuthenticationToken(&quot;用户信息&quot;,&quot;身份令牌&quot;);
}
</code></pre>
<h3 id="4-创建-keyauthenticationsuccesshandler">4. 创建 KeyAuthenticationSuccessHandler</h3>
<p>然后，我们创建一个认证成功处理器 <code>KeyAuthenticationSuccessHandler</code>，用于处理认证成功的情况。</p>
<pre><code class="language-java">// KeyAuthenticationSuccessHandler.java
public class KeyAuthenticationSuccessHandler implements AuthenticationSuccessHandler {
    // 实现逻辑...
    // 从认证信息中获取认证用户对象
    // 将认证用户相关信息放入请求头中
    request.setAttribute(&quot;用户信息&quot;);
}
</code></pre>
<h3 id="5-创建-keyauthenticationtoken">5. 创建 KeyAuthenticationToken</h3>
<p>我们还需要创建一个认证令牌 <code>KeyAuthenticationToken</code>，用于表示认证信息。</p>
<pre><code class="language-java">// KeyAuthenticationToken.java
public class KeyAuthenticationToken extends AbstractAuthenticationToken {
    // 实现逻辑...
    /**  
	 * * @param apiKey API 密钥  
	 */
    public KeyAuthenticationToken(String apiKey) {  
    super(null);  
    super.setAuthenticated(false);  
    this.apiKey = apiKey;  
}
}
</code></pre>
<h3 id="6-创建-securityconfigurer">6. 创建 SecurityConfigurer</h3>
<p>最后，我们创建一个配置类 <code>SecurityConfigurer</code>，用于配置 Spring Security。</p>
<pre><code class="language-java">// SecurityConfigurer.java
   @Configuration
   @EnableWebSecurity
   public class SecurityConfig extends WebSecurityConfigurerAdapter {
		// 参考准备工作
         @Override
   protected void configure(HttpSecurity http) throws Exception {
       http
           .authorizeRequests()
               .antMatchers(&quot;/public/**&quot;).permitAll()
               .anyRequest().authenticated()
               .and()
           .formLogin()
               .loginPage(&quot;/login&quot;)
               .permitAll()
               .and()
           .logout()
               .permitAll();
   }
   
   @Override  
	protected void configure(AuthenticationManagerBuilder auth) {   
	    auth.authenticationProvider(keyAuthenticationProvider);  
	}
	@Bean  
	public AuthenticationFilter keyAuthenticationFilter() throws Exception {  
	    AuthenticationFilter filter = new AuthenticationFilter(authenticationManager(), new KeyAuthenticationConverter());  
	    filter.setRequestMatcher(&quot;设置认证路由:/key/**&quot;);  
	    filter.setSuccessHandler(keyAuthenticationSuccessHandler());  
	    filter.setFailureHandler(authenticationEntryPointFailureHandler());  
	    return filter;  
}
   }
</code></pre>
<h3 id="7-创建测试">7. 创建测试</h3>
<pre><code class="language-java">@RequestMapping(&quot;/key&quot;)
public class OpenInstanceController {
    @GetMapping(&quot;/test&quot;)
    public String getTest() {
        return &quot;hello world !!!&quot;;
    }
}

</code></pre>
<p>通过以上步骤，我们成功地实现了基于 Spring Security 的 Key 认证流程。现在，持有有效 Key 的用户也能安全地访问受保护的资源。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一篇看懂MQ]]></title>
        <id>https://shenshen6666.GitHub.io/post/yi-pian-kan-dong-mq/</id>
        <link href="https://shenshen6666.GitHub.io/post/yi-pian-kan-dong-mq/">
        </link>
        <updated>2024-02-03T10:07:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="rabbitmq">RabbitMQ</h1>
<h1 id="1初识mq">1.初识MQ</h1>
<h2 id="11同步和异步通讯">1.1.同步和异步通讯</h2>
<p>微服务间通讯有同步和异步两种方式：</p>
<p>同步通讯：就像打电话，需要实时响应。</p>
<p>异步通讯：就像发邮件，不需要马上回复。</p>
<figure data-type="image" tabindex="1"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717161939695.png" alt="image-20210717161939695" loading="lazy"></figure>
<p>两种方式各有优劣，打电话可以立即得到响应，但是你却不能跟多个人同时通话。发送邮件可以同时与多个人收发邮件，但是往往响应会有延迟。</p>
<h3 id="111同步通讯">1.1.1.同步通讯</h3>
<p>我们之前学习的Feign调用就属于同步方式，虽然调用可以实时得到结果，但存在下面的问题：</p>
<figure data-type="image" tabindex="2"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717162004285.png" alt="image-20210717162004285" loading="lazy"></figure>
<p>总结：</p>
<p>同步调用的优点：</p>
<ul>
<li>时效性较强，可以立即得到结果</li>
</ul>
<p>同步调用的问题：</p>
<ul>
<li>耦合度高</li>
<li>性能和吞吐能力下降</li>
<li>有额外的资源消耗</li>
<li>有级联失败问题</li>
</ul>
<h3 id="112异步通讯">1.1.2.异步通讯</h3>
<p>异步调用则可以避免上述问题：</p>
<p>我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。</p>
<p>在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单id。</p>
<p>订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。</p>
<p>为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到Broker，不关心谁来订阅事件。订阅者从Broker订阅事件，不关心谁发来的消息。</p>
<figure data-type="image" tabindex="3"><img src="https://shenshen6666.GitHub.io/post-images/image-20210422095356088.png" alt="image-20210422095356088" loading="lazy"></figure>
<p>Broker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。</p>
<p>好处：</p>
<ul>
<li>
<p>吞吐量提升：无需等待订阅者处理完成，响应更快速</p>
</li>
<li>
<p>故障隔离：服务没有直接调用，不存在级联失败问题</p>
</li>
<li>
<p>调用间没有阻塞，不会造成无效的资源占用</p>
</li>
<li>
<p>耦合度极低，每个服务都可以灵活插拔，可替换</p>
</li>
<li>
<p>流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件</p>
</li>
</ul>
<p>缺点：</p>
<ul>
<li>架构复杂了，业务没有明显的流程线，不好管理</li>
<li>需要依赖于Broker的可靠、安全、性能</li>
</ul>
<p>好在现在开源软件或云平台上 Broker 的软件是非常成熟的，比较常见的一种就是我们今天要学习的MQ技术。</p>
<h2 id="12技术对比">1.2.技术对比：</h2>
<p>MQ，中文是消息队列（MessageQueue），字面来看就是存放消息的队列。也就是事件驱动架构中的Broker。</p>
<p>比较常见的MQ实现：</p>
<ul>
<li>ActiveMQ</li>
<li>RabbitMQ</li>
<li>RocketMQ</li>
<li>Kafka</li>
</ul>
<p>几种常见MQ的对比：</p>
<table>
<thead>
<tr>
<th></th>
<th><strong>RabbitMQ</strong></th>
<th><strong>ActiveMQ</strong></th>
<th><strong>RocketMQ</strong></th>
<th><strong>Kafka</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>公司/社区</td>
<td>Rabbit</td>
<td>Apache</td>
<td>阿里</td>
<td>Apache</td>
</tr>
<tr>
<td>开发语言</td>
<td>Erlang</td>
<td>Java</td>
<td>Java</td>
<td>Scala&amp;Java</td>
</tr>
<tr>
<td>协议支持</td>
<td>AMQP，XMPP，SMTP，STOMP</td>
<td>OpenWire,STOMP，REST,XMPP,AMQP</td>
<td>自定义协议</td>
<td>自定义协议</td>
</tr>
<tr>
<td>可用性</td>
<td>高</td>
<td>一般</td>
<td>高</td>
<td>高</td>
</tr>
<tr>
<td>单机吞吐量</td>
<td>一般</td>
<td>差</td>
<td>高</td>
<td>非常高</td>
</tr>
<tr>
<td>消息延迟</td>
<td>微秒级</td>
<td>毫秒级</td>
<td>毫秒级</td>
<td>毫秒以内</td>
</tr>
<tr>
<td>消息可靠性</td>
<td>高</td>
<td>一般</td>
<td>高</td>
<td>一般</td>
</tr>
</tbody>
</table>
<p>追求可用性：Kafka、 RocketMQ 、RabbitMQ</p>
<p>追求可靠性：RabbitMQ、RocketMQ</p>
<p>追求吞吐能力：RocketMQ、Kafka</p>
<p>追求消息低延迟：RabbitMQ、Kafka</p>
<h1 id="2快速入门">2.快速入门</h1>
<h2 id="21安装rabbitmq">2.1.安装RabbitMQ</h2>
<p>安装RabbitMQ，参考课前资料：</p>
<figure data-type="image" tabindex="4"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717162628635.png" alt="image-20210717162628635" loading="lazy"></figure>
<p>MQ的基本结构：</p>
<figure data-type="image" tabindex="5"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717162752376.png" alt="image-20210717162752376" loading="lazy"></figure>
<p>RabbitMQ中的一些角色：</p>
<ul>
<li>publisher：生产者</li>
<li>consumer：消费者</li>
<li>exchange个：交换机，负责消息路由</li>
<li>queue：队列，存储消息</li>
<li>virtualHost：虚拟主机，隔离不同租户的exchange、queue、消息的隔离</li>
</ul>
<h2 id="22rabbitmq消息模型">2.2.RabbitMQ消息模型</h2>
<p>RabbitMQ官方提供了5个不同的Demo示例，对应了不同的消息模型：</p>
<figure data-type="image" tabindex="6"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717163332646.png" alt="image-20210717163332646" loading="lazy"></figure>
<h2 id="23导入demo工程">2.3.导入Demo工程</h2>
<p>课前资料提供了一个Demo工程，mq-demo:</p>
<figure data-type="image" tabindex="7"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717163253264.png" alt="image-20210717163253264" loading="lazy"></figure>
<p>导入后可以看到结构如下：</p>
<figure data-type="image" tabindex="8"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717163604330.png" alt="image-20210717163604330" loading="lazy"></figure>
<p>包括三部分：</p>
<ul>
<li>mq-demo：父工程，管理项目依赖</li>
<li>publisher：消息的发送者</li>
<li>consumer：消息的消费者</li>
</ul>
<h2 id="24入门案例">2.4.入门案例</h2>
<p>简单队列模式的模型图：</p>
<figure data-type="image" tabindex="9"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717163434647.png" alt="image-20210717163434647" loading="lazy"></figure>
<p>官方的HelloWorld是基于最基础的消息队列模型来实现的，只包括三个角色：</p>
<ul>
<li>publisher：消息发布者，将消息发送到队列queue</li>
<li>queue：消息队列，负责接受并缓存消息</li>
<li>consumer：订阅队列，处理队列中的消息</li>
</ul>
<h3 id="241publisher实现">2.4.1.publisher实现</h3>
<p>思路：</p>
<ul>
<li>建立连接</li>
<li>创建Channel</li>
<li>声明队列</li>
<li>发送消息</li>
<li>关闭连接和channel</li>
</ul>
<p>代码实现：</p>
<pre><code class="language-java">package cn.itcast.mq.helloworld;

import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;
import org.junit.Test;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class PublisherTest {
    @Test
    public void testSendMessage() throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost(&quot;192.168.150.101&quot;);
        factory.setPort(5672);
        factory.setVirtualHost(&quot;/&quot;);
        factory.setUsername(&quot;itcast&quot;);
        factory.setPassword(&quot;123321&quot;);
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = &quot;simple.queue&quot;;
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.发送消息
        String message = &quot;hello, rabbitmq!&quot;;
        channel.basicPublish(&quot;&quot;, queueName, null, message.getBytes());
        System.out.println(&quot;发送消息成功：【&quot; + message + &quot;】&quot;);

        // 5.关闭通道和连接
        channel.close();
        connection.close();

    }
}
</code></pre>
<h3 id="242consumer实现">2.4.2.consumer实现</h3>
<p>代码思路：</p>
<ul>
<li>建立连接</li>
<li>创建Channel</li>
<li>声明队列</li>
<li>订阅消息</li>
</ul>
<p>代码实现：</p>
<pre><code class="language-java">package cn.itcast.mq.helloworld;

import com.rabbitmq.client.*;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class ConsumerTest {

    public static void main(String[] args) throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost(&quot;192.168.150.101&quot;);
        factory.setPort(5672);
        factory.setVirtualHost(&quot;/&quot;);
        factory.setUsername(&quot;itcast&quot;);
        factory.setPassword(&quot;123321&quot;);
        // 1.2.建立连接
        Connection connection = factory.newConnection();

        // 2.创建通道Channel
        Channel channel = connection.createChannel();

        // 3.创建队列
        String queueName = &quot;simple.queue&quot;;
        channel.queueDeclare(queueName, false, false, false, null);

        // 4.订阅消息
        channel.basicConsume(queueName, true, new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope,
                                       AMQP.BasicProperties properties, byte[] body) throws IOException {
                // 5.处理消息
                String message = new String(body);
                System.out.println(&quot;接收到消息：【&quot; + message + &quot;】&quot;);
            }
        });
        System.out.println(&quot;等待接收消息。。。。&quot;);
    }
}
</code></pre>
<h2 id="25总结">2.5.总结</h2>
<p>基本消息队列的消息发送流程：</p>
<ol>
<li>
<p>建立connection</p>
</li>
<li>
<p>创建channel</p>
</li>
<li>
<p>利用channel声明队列</p>
</li>
<li>
<p>利用channel向队列发送消息</p>
</li>
</ol>
<p>基本消息队列的消息接收流程：</p>
<ol>
<li>
<p>建立connection</p>
</li>
<li>
<p>创建channel</p>
</li>
<li>
<p>利用channel声明队列</p>
</li>
<li>
<p>定义consumer的消费行为handleDelivery()</p>
</li>
<li>
<p>利用channel将消费者与队列绑定</p>
</li>
</ol>
<h1 id="3springamqp">3.SpringAMQP</h1>
<p>SpringAMQP是基于RabbitMQ封装的一套模板，并且还利用SpringBoot对其实现了自动装配，使用起来非常方便。</p>
<p>SpringAmqp的官方地址：https://spring.io/projects/spring-amqp</p>
<figure data-type="image" tabindex="10"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717164024967.png" alt="image-20210717164024967" loading="lazy"></figure>
<figure data-type="image" tabindex="11"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717164038678.png" alt="image-20210717164038678" loading="lazy"></figure>
<p>SpringAMQP提供了三个功能：</p>
<ul>
<li>自动声明队列、交换机及其绑定关系</li>
<li>基于注解的监听器模式，异步接收消息</li>
<li>封装了RabbitTemplate工具，用于发送消息</li>
</ul>
<h2 id="31basic-queue-简单队列模型">3.1.Basic Queue 简单队列模型</h2>
<p>在父工程mq-demo中引入依赖</p>
<pre><code class="language-xml">&lt;!--AMQP依赖，包含RabbitMQ--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="311消息发送">3.1.1.消息发送</h3>
<p>首先配置MQ地址，在publisher服务的application.yml中添加配置：</p>
<pre><code class="language-yaml">spring:
  rabbitmq:
    host: 192.168.150.101 # 主机名
    port: 5672 # 端口
    virtual-host: / # 虚拟主机
    username: itcast # 用户名
    password: 123321 # 密码
</code></pre>
<p>然后在publisher服务中编写测试类SpringAmqpTest，并利用RabbitTemplate实现消息发送：</p>
<pre><code class="language-java">package cn.itcast.mq.spring;

import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.test.context.junit4.SpringRunner;

@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAmqpTest {

    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Test
    public void testSimpleQueue() {
        // 队列名称
        String queueName = &quot;simple.queue&quot;;
        // 消息
        String message = &quot;hello, spring amqp!&quot;;
        // 发送消息
        rabbitTemplate.convertAndSend(queueName, message);
    }
}
</code></pre>
<h3 id="312消息接收">3.1.2.消息接收</h3>
<p>首先配置MQ地址，在consumer服务的application.yml中添加配置：</p>
<pre><code class="language-yaml">spring:
  rabbitmq:
    host: 192.168.150.101 # 主机名
    port: 5672 # 端口
    virtual-host: / # 虚拟主机
    username: itcast # 用户名
    password: 123321 # 密码
</code></pre>
<p>然后在consumer服务的<code>cn.itcast.mq.listener</code>包中新建一个类SpringRabbitListener，代码如下：</p>
<pre><code class="language-java">package cn.itcast.mq.listener;

import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Component;

@Component
public class SpringRabbitListener {

    @RabbitListener(queues = &quot;simple.queue&quot;)
    public void listenSimpleQueueMessage(String msg) throws InterruptedException {
        System.out.println(&quot;spring 消费者接收到消息：【&quot; + msg + &quot;】&quot;);
    }
}
</code></pre>
<h3 id="313测试">3.1.3.测试</h3>
<p>启动consumer服务，然后在publisher服务中运行测试代码，发送MQ消息</p>
<h2 id="32workqueue">3.2.WorkQueue</h2>
<p>Work queues，也被称为（Task queues），任务模型。简单来说就是<strong>让多个消费者绑定到一个队列，共同消费队列中的消息</strong>。</p>
<figure data-type="image" tabindex="12"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717164238910.png" alt="image-20210717164238910" loading="lazy"></figure>
<p>当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。</p>
<p>此时就可以使用work 模型，多个消费者共同处理消息处理，速度就能大大提高了。</p>
<h3 id="321消息发送">3.2.1.消息发送</h3>
<p>这次我们循环发送，模拟大量消息堆积现象。</p>
<p>在publisher服务中的SpringAmqpTest类中添加一个测试方法：</p>
<pre><code class="language-java">/**
     * workQueue
     * 向队列中不停发送消息，模拟消息堆积。
     */
@Test
public void testWorkQueue() throws InterruptedException {
    // 队列名称
    String queueName = &quot;simple.queue&quot;;
    // 消息
    String message = &quot;hello, message_&quot;;
    for (int i = 0; i &lt; 50; i++) {
        // 发送消息
        rabbitTemplate.convertAndSend(queueName, message + i);
        Thread.sleep(20);
    }
}
</code></pre>
<h3 id="322消息接收">3.2.2.消息接收</h3>
<p>要模拟多个消费者绑定同一个队列，我们在consumer服务的SpringRabbitListener中添加2个新的方法：</p>
<pre><code class="language-java">@RabbitListener(queues = &quot;simple.queue&quot;)
public void listenWorkQueue1(String msg) throws InterruptedException {
    System.out.println(&quot;消费者1接收到消息：【&quot; + msg + &quot;】&quot; + LocalTime.now());
    Thread.sleep(20);
}

@RabbitListener(queues = &quot;simple.queue&quot;)
public void listenWorkQueue2(String msg) throws InterruptedException {
    System.err.println(&quot;消费者2........接收到消息：【&quot; + msg + &quot;】&quot; + LocalTime.now());
    Thread.sleep(200);
}

</code></pre>
<p>注意到这个消费者sleep了1000秒，模拟任务耗时。</p>
<h3 id="323测试">3.2.3.测试</h3>
<p>启动ConsumerApplication后，在执行publisher服务中刚刚编写的发送测试方法testWorkQueue。</p>
<p>可以看到消费者1很快完成了自己的25条消息。消费者2却在缓慢的处理自己的25条消息。</p>
<p>也就是说消息是平均分配给每个消费者，并没有考虑到消费者的处理能力。这样显然是有问题的。</p>
<h3 id="324能者多劳">3.2.4.能者多劳</h3>
<p>在spring中有一个简单的配置，可以解决这个问题。我们修改consumer服务的application.yml文件，添加配置：</p>
<pre><code class="language-yaml">spring:
  rabbitmq:
    listener:
      simple:
        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息

</code></pre>
<h3 id="325总结">3.2.5.总结</h3>
<p>Work模型的使用：</p>
<ul>
<li>多个消费者绑定到一个队列，同一条消息只会被一个消费者处理</li>
<li>通过设置prefetch来控制消费者预取的消息数量</li>
</ul>
<h2 id="33发布订阅">3.3.发布/订阅</h2>
<p>发布订阅的模型如图：</p>
<figure data-type="image" tabindex="13"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717165309625.png" alt="image-20210717165309625" loading="lazy"></figure>
<p>可以看到，在订阅模型中，多了一个exchange角色，而且过程略有变化：</p>
<ul>
<li>Publisher：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机）</li>
<li>Exchange：交换机，图中的X。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有以下3种类型：
<ul>
<li>Fanout：广播，将消息交给所有绑定到交换机的队列</li>
<li>Direct：定向，把消息交给符合指定routing key 的队列</li>
<li>Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列</li>
</ul>
</li>
<li>Consumer：消费者，与以前一样，订阅队列，没有变化</li>
<li>Queue：消息队列也与以前一样，接收消息、缓存消息。</li>
</ul>
<p><strong>Exchange（交换机）只负责转发消息，不具备存储消息的能力</strong>，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！</p>
<h2 id="34fanout">3.4.Fanout</h2>
<p>Fanout，英文翻译是扇出，我觉得在MQ中叫广播更合适。</p>
<figure data-type="image" tabindex="14"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717165438225.png" alt="image-20210717165438225" loading="lazy"></figure>
<p>在广播模式下，消息发送流程是这样的：</p>
<ul>
<li>1）  可以有多个队列</li>
<li>2）  每个队列都要绑定到Exchange（交换机）</li>
<li>3）  生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定</li>
<li>4）  交换机把消息发送给绑定过的所有队列</li>
<li>5）  订阅队列的消费者都能拿到消息</li>
</ul>
<p>我们的计划是这样的：</p>
<ul>
<li>创建一个交换机 itcast.fanout，类型是Fanout</li>
<li>创建两个队列fanout.queue1和fanout.queue2，绑定到交换机itcast.fanout</li>
</ul>
<figure data-type="image" tabindex="15"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717165509466.png" alt="image-20210717165509466" loading="lazy"></figure>
<h3 id="341声明队列和交换机">3.4.1.声明队列和交换机</h3>
<p>Spring提供了一个接口Exchange，来表示所有不同类型的交换机：</p>
<figure data-type="image" tabindex="16"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717165552676.png" alt="image-20210717165552676" loading="lazy"></figure>
<p>在consumer中创建一个类，声明队列和交换机：</p>
<pre><code class="language-java">package cn.itcast.mq.config;

import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.FanoutExchange;
import org.springframework.amqp.core.Queue;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class FanoutConfig {
    /**
     * 声明交换机
     * @return Fanout类型交换机
     */
    @Bean
    public FanoutExchange fanoutExchange(){
        return new FanoutExchange(&quot;itcast.fanout&quot;);
    }

    /**
     * 第1个队列
     */
    @Bean
    public Queue fanoutQueue1(){
        return new Queue(&quot;fanout.queue1&quot;);
    }

    /**
     * 绑定队列和交换机
     */
    @Bean
    public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange){
        return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange);
    }

    /**
     * 第2个队列
     */
    @Bean
    public Queue fanoutQueue2(){
        return new Queue(&quot;fanout.queue2&quot;);
    }

    /**
     * 绑定队列和交换机
     */
    @Bean
    public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange){
        return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange);
    }
}

</code></pre>
<h3 id="342消息发送">3.4.2.消息发送</h3>
<p>在publisher服务的SpringAmqpTest类中添加测试方法：</p>
<pre><code class="language-java">@Test
public void testFanoutExchange() {
    // 队列名称
    String exchangeName = &quot;itcast.fanout&quot;;
    // 消息
    String message = &quot;hello, everyone!&quot;;
    rabbitTemplate.convertAndSend(exchangeName, &quot;&quot;, message);
}

</code></pre>
<h3 id="343消息接收">3.4.3.消息接收</h3>
<p>在consumer服务的SpringRabbitListener中添加两个方法，作为消费者：</p>
<pre><code class="language-java">@RabbitListener(queues = &quot;fanout.queue1&quot;)
public void listenFanoutQueue1(String msg) {
    System.out.println(&quot;消费者1接收到Fanout消息：【&quot; + msg + &quot;】&quot;);
}

@RabbitListener(queues = &quot;fanout.queue2&quot;)
public void listenFanoutQueue2(String msg) {
    System.out.println(&quot;消费者2接收到Fanout消息：【&quot; + msg + &quot;】&quot;);
}

</code></pre>
<h3 id="344总结">3.4.4.总结</h3>
<p>交换机的作用是什么？</p>
<ul>
<li>接收publisher发送的消息</li>
<li>将消息按照规则路由到与之绑定的队列</li>
<li>不能缓存消息，路由失败，消息丢失</li>
<li>FanoutExchange的会将消息路由到每个绑定的队列</li>
</ul>
<p>声明队列、交换机、绑定关系的Bean是什么？</p>
<ul>
<li>Queue</li>
<li>FanoutExchange</li>
<li>Binding</li>
</ul>
<h2 id="35direct">3.5.Direct</h2>
<p>在Fanout模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到Direct类型的Exchange。</p>
<figure data-type="image" tabindex="17"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717170041447.png" alt="image-20210717170041447" loading="lazy"></figure>
<p>在Direct模型下：</p>
<ul>
<li>队列与交换机的绑定，不能是任意绑定了，而是要指定一个<code>RoutingKey</code>（路由key）</li>
<li>消息的发送方在 向 Exchange发送消息时，也必须指定消息的 <code>RoutingKey</code>。</li>
<li>Exchange不再把消息交给每一个绑定的队列，而是根据消息的<code>Routing Key</code>进行判断，只有队列的<code>Routingkey</code>与消息的 <code>Routing key</code>完全一致，才会接收到消息</li>
</ul>
<p><strong>案例需求如下</strong>：</p>
<ol>
<li>
<p>利用@RabbitListener声明Exchange、Queue、RoutingKey</p>
</li>
<li>
<p>在consumer服务中，编写两个消费者方法，分别监听direct.queue1和direct.queue2</p>
</li>
<li>
<p>在publisher中编写测试方法，向itcast. direct发送消息</p>
</li>
</ol>
<figure data-type="image" tabindex="18"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717170223317.png" alt="image-20210717170223317" loading="lazy"></figure>
<h3 id="351基于注解声明队列和交换机">3.5.1.基于注解声明队列和交换机</h3>
<p>基于@Bean的方式声明队列和交换机比较麻烦，Spring还提供了基于注解方式来声明。</p>
<p>在consumer的SpringRabbitListener中添加两个消费者，同时基于注解来声明队列和交换机：</p>
<pre><code class="language-java">@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = &quot;direct.queue1&quot;),
    exchange = @Exchange(name = &quot;itcast.direct&quot;, type = ExchangeTypes.DIRECT),
    key = {&quot;red&quot;, &quot;blue&quot;}
))
public void listenDirectQueue1(String msg){
    System.out.println(&quot;消费者接收到direct.queue1的消息：【&quot; + msg + &quot;】&quot;);
}

@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = &quot;direct.queue2&quot;),
    exchange = @Exchange(name = &quot;itcast.direct&quot;, type = ExchangeTypes.DIRECT),
    key = {&quot;red&quot;, &quot;yellow&quot;}
))
public void listenDirectQueue2(String msg){
    System.out.println(&quot;消费者接收到direct.queue2的消息：【&quot; + msg + &quot;】&quot;);
}

</code></pre>
<h3 id="352消息发送">3.5.2.消息发送</h3>
<p>在publisher服务的SpringAmqpTest类中添加测试方法：</p>
<pre><code class="language-java">@Test
public void testSendDirectExchange() {
    // 交换机名称
    String exchangeName = &quot;itcast.direct&quot;;
    // 消息
    String message = &quot;红色警报！日本乱排核废水，导致海洋生物变异，惊现哥斯拉！&quot;;
    // 发送消息
    rabbitTemplate.convertAndSend(exchangeName, &quot;red&quot;, message);
}

</code></pre>
<h3 id="353总结">3.5.3.总结</h3>
<p>描述下Direct交换机与Fanout交换机的差异？</p>
<ul>
<li>Fanout交换机将消息路由给每一个与之绑定的队列</li>
<li>Direct交换机根据RoutingKey判断路由给哪个队列</li>
<li>如果多个队列具有相同的RoutingKey，则与Fanout功能类似</li>
</ul>
<p>基于@RabbitListener注解声明队列和交换机有哪些常见注解？</p>
<ul>
<li>@Queue</li>
<li>@Exchange</li>
</ul>
<h2 id="36topic">3.6.Topic</h2>
<h3 id="361说明">3.6.1.说明</h3>
<p><code>Topic</code>类型的<code>Exchange</code>与<code>Direct</code>相比，都是可以根据<code>RoutingKey</code>把消息路由到不同的队列。只不过<code>Topic</code>类型<code>Exchange</code>可以让队列在绑定<code>Routing key</code> 的时候使用通配符！</p>
<p><code>Routingkey</code> 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： <code>item.insert</code></p>
<p>通配符规则：</p>
<p><code>#</code>：匹配一个或多个词</p>
<p><code>*</code>：匹配不多不少恰好1个词</p>
<p>举例：</p>
<p><code>item.#</code>：能够匹配<code>item.spu.insert</code> 或者 <code>item.spu</code></p>
<p><code>item.*</code>：只能匹配<code>item.spu</code></p>
<p>​</p>
<p>图示：</p>
<figure data-type="image" tabindex="19"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717170705380.png" alt="image-20210717170705380" loading="lazy"></figure>
<p>解释：</p>
<ul>
<li>Queue1：绑定的是<code>china.#</code> ，因此凡是以 <code>china.</code>开头的<code>routing key</code> 都会被匹配到。包括china.news和china.weather</li>
<li>Queue2：绑定的是<code>#.news</code> ，因此凡是以 <code>.news</code>结尾的 <code>routing key</code> 都会被匹配。包括china.news和japan.news</li>
</ul>
<p>案例需求：</p>
<p>实现思路如下：</p>
<ol>
<li>
<p>并利用@RabbitListener声明Exchange、Queue、RoutingKey</p>
</li>
<li>
<p>在consumer服务中，编写两个消费者方法，分别监听topic.queue1和topic.queue2</p>
</li>
<li>
<p>在publisher中编写测试方法，向itcast. topic发送消息</p>
</li>
</ol>
<figure data-type="image" tabindex="20"><img src="https://shenshen6666.GitHub.io/post-images/image-20210717170829229.png" alt="image-20210717170829229" loading="lazy"></figure>
<h3 id="362消息发送">3.6.2.消息发送</h3>
<p>在publisher服务的SpringAmqpTest类中添加测试方法：</p>
<pre><code class="language-java">/**
     * topicExchange
     */
@Test
public void testSendTopicExchange() {
    // 交换机名称
    String exchangeName = &quot;itcast.topic&quot;;
    // 消息
    String message = &quot;喜报！孙悟空大战哥斯拉，胜!&quot;;
    // 发送消息
    rabbitTemplate.convertAndSend(exchangeName, &quot;china.news&quot;, message);
}

</code></pre>
<h3 id="363消息接收">3.6.3.消息接收</h3>
<p>在consumer服务的SpringRabbitListener中添加方法：</p>
<pre><code class="language-java">@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = &quot;topic.queue1&quot;),
    exchange = @Exchange(name = &quot;itcast.topic&quot;, type = ExchangeTypes.TOPIC),
    key = &quot;china.#&quot;
))
public void listenTopicQueue1(String msg){
    System.out.println(&quot;消费者接收到topic.queue1的消息：【&quot; + msg + &quot;】&quot;);
}

@RabbitListener(bindings = @QueueBinding(
    value = @Queue(name = &quot;topic.queue2&quot;),
    exchange = @Exchange(name = &quot;itcast.topic&quot;, type = ExchangeTypes.TOPIC),
    key = &quot;#.news&quot;
))
public void listenTopicQueue2(String msg){
    System.out.println(&quot;消费者接收到topic.queue2的消息：【&quot; + msg + &quot;】&quot;);
}

</code></pre>
<h3 id="364总结">3.6.4.总结</h3>
<p>描述下Direct交换机与Topic交换机的差异？</p>
<ul>
<li>Topic交换机接收的消息RoutingKey必须是多个单词，以 <code>**.**</code> 分割</li>
<li>Topic交换机与队列绑定时的bindingKey可以指定通配符</li>
<li><code>#</code>：代表0个或多个词</li>
<li><code>*</code>：代表1个词</li>
</ul>
<h2 id="37消息转换器">3.7.消息转换器</h2>
<p>之前说过，Spring会把你发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。</p>
<figure data-type="image" tabindex="21"><img src="https://shenshen6666.GitHub.io/post-images/image-20200525170410401.png" alt="image-20200525170410401" loading="lazy"></figure>
<p>只不过，默认情况下Spring采用的序列化方式是JDK序列化。众所周知，JDK序列化存在下列问题：</p>
<ul>
<li>数据体积过大</li>
<li>有安全漏洞</li>
<li>可读性差</li>
</ul>
<p>我们来测试一下。</p>
<h3 id="371测试默认转换器">3.7.1.测试默认转换器</h3>
<p>我们修改消息发送的代码，发送一个Map对象：</p>
<pre><code class="language-java">@Test
public void testSendMap() throws InterruptedException {
    // 准备消息
    Map&lt;String,Object&gt; msg = new HashMap&lt;&gt;();
    msg.put(&quot;name&quot;, &quot;Jack&quot;);
    msg.put(&quot;age&quot;, 21);
    // 发送消息
    rabbitTemplate.convertAndSend(&quot;simple.queue&quot;,&quot;&quot;, msg);
}

</code></pre>
<p>停止consumer服务</p>
<p>发送消息后查看控制台：</p>
<figure data-type="image" tabindex="22"><img src="https://shenshen6666.GitHub.io/post-images/image-20210422232835363.png" alt="image-20210422232835363" loading="lazy"></figure>
<h3 id="372配置json转换器">3.7.2.配置JSON转换器</h3>
<p>显然，JDK序列化方式并不合适。我们希望消息体的体积更小、可读性更高，因此可以使用JSON方式来做序列化和反序列化。</p>
<p>在publisher和consumer两个服务中都引入依赖：</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt;
    &lt;version&gt;2.9.10&lt;/version&gt;
&lt;/dependency&gt;

</code></pre>
<p>配置消息转换器。</p>
<p>在启动类中添加一个Bean即可：</p>
<pre><code class="language-java">@Bean
public MessageConverter jsonMessageConverter(){
    return new Jackson2JsonMessageConverter();
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一些常见Java集合类的详细比较]]></title>
        <id>https://shenshen6666.GitHub.io/post/yi-xie-chang-jian-java-ji-he-lei-de-xiang-xi-bi-jiao/</id>
        <link href="https://shenshen6666.GitHub.io/post/yi-xie-chang-jian-java-ji-he-lei-de-xiang-xi-bi-jiao/">
        </link>
        <updated>2024-01-16T07:36:15.000Z</updated>
        <content type="html"><![CDATA[<p>以下是Java集合框架中一些常见类和它们之间的详细比较：</p>
<h2 id="目录">目录</h2>
<ol>
<li><a href="#java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6">Java集合框架</a><br>
1.1 <a href="#list-%E6%8E%A5%E5%8F%A3">List 接口</a><br>
1.1.1 <a href="#arraylist">ArrayList</a><br>
1.1.2 <a href="#linkedlist">LinkedList</a><br>
1.1.3 <a href="#vector">Vector</a><br>
1.2 <a href="#set-%E6%8E%A5%E5%8F%A3">Set 接口</a><br>
1.2.1 <a href="#hashset">HashSet</a><br>
1.2.2 <a href="#linkedhashset">LinkedHashSet</a><br>
1.2.3 <a href="#treeset">TreeSet</a><br>
1.3 <a href="#queue-%E6%8E%A5%E5%8F%A3">Queue 接口</a><br>
1.3.1 <a href="#linkedlist-1">LinkedList</a><br>
1.3.2 <a href="#priorityqueue">PriorityQueue</a><br>
1.4 <a href="#map-%E6%8E%A5%E5%8F%A3">Map 接口</a><br>
1.4.1 <a href="#hashmap">HashMap</a><br>
1.4.2 <a href="#linkedhashmap">LinkedHashMap</a><br>
1.4.3 <a href="#treemap">TreeMap</a></li>
<li><a href="#stringstringbuffer%E5%92%8Cstringbuilder%E5%8C%BA%E5%88%AB">String、StringBuffer和StringBuilder区别</a></li>
<li><a href="#arraylist%E5%92%8Clinkedlist%E5%8C%BA%E5%88%AB">ArrayList和LinkedList区别</a></li>
<li><a href="#arraylist%E5%92%8Cvector%E7%9A%84%E5%8C%BA%E5%88%AB">ArrayList和Vector的区别</a></li>
<li><a href="#hashmap%E5%92%8Chashtable%E7%9A%84%E5%8C%BA%E5%88%AB">HashMap和Hashtable的区别</a></li>
<li><a href="#arraylist%E5%92%8Clinkedlist%E7%9A%84%E5%8C%BA%E5%88%AB">ArrayList和LinkedList的区别</a></li>
<li><a href="#arraylist%E5%92%8Carray%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB">ArrayList和Array有什么区别</a></li>
<li><a href="#comparator%E5%92%8Ccomparable%E7%9A%84%E5%8C%BA%E5%88%AB">Comparator和Comparable的区别</a></li>
</ol>
<h2 id="1-list-接口">1. List 接口：</h2>
<h4 id="arraylist">ArrayList:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于动态数组实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>随机访问速度快，适合读取操作较多的场景。</li>
<li>插入和删除元素可能较慢，因为需要移动元素。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<h4 id="linkedlist">LinkedList:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于双向链表实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>插入和删除操作较快，适合频繁插入和删除的场景。</li>
<li>访问速度较慢。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<h4 id="vector">Vector:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>与ArrayList类似，但是线程安全。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>同步操作会影响性能。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>线程安全，但通常不推荐在大多数情况下使用。</li>
</ul>
</li>
</ul>
<p><strong>对比：</strong></p>
<ul>
<li>ArrayList和LinkedList适用于不同的使用场景。ArrayList对于随机访问较快，而LinkedList对于频繁插入和删除较快。</li>
</ul>
<h3 id="2-set-接口">2. Set 接口：</h3>
<h4 id="hashset">HashSet:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于哈希表实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>不保证元素的顺序。</li>
<li>查找元素速度快。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<h4 id="linkedhashset">LinkedHashSet:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于哈希表和链表实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>以插入顺序维护元素。</li>
<li>查找元素速度较快。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<h4 id="treeset">TreeSet:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于红黑树实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>元素按照自然排序或者指定比较器排序。</li>
<li>查找元素速度较慢。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<p><strong>对比：</strong></p>
<ul>
<li>HashSet适用于快速查找元素，LinkedHashSet适用于保持插入顺序，TreeSet适用于有序的元素。</li>
</ul>
<h3 id="3-queue-接口">3. Queue 接口：</h3>
<h4 id="linkedlist-2">LinkedList:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于链表实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>可用作队列或双端队列。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<h4 id="priorityqueue">PriorityQueue:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于堆实现的优先队列。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>元素按照优先级检索。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<p><strong>对比：</strong></p>
<ul>
<li>LinkedList可以用作队列或双端队列，而PriorityQueue适用于按照优先级检索元素的场景。</li>
</ul>
<h3 id="4-map-接口">4. Map 接口：</h3>
<h4 id="hashmap">HashMap:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于哈希表实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>不保证元素的顺序。</li>
<li>查找键值对速度快。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<h4 id="linkedhashmap">LinkedHashMap:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于哈希表和链表实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>以插入顺序维护元素。</li>
<li>查找键值对速度较快。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<h4 id="treemap">TreeMap:</h4>
<ul>
<li><strong>实现机制：</strong>
<ul>
<li>基于红黑树实现。</li>
</ul>
</li>
<li><strong>性能特点：</strong>
<ul>
<li>键按照自然排序或者指定比较器排序。</li>
<li>查找键值对速度较慢。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>非线程安全。</li>
</ul>
</li>
</ul>
<h2 id="string-stringbuffer-和-stringbuilder-是-java-中字符串处理的三个主要类它们有以下区别"><code>String</code>、<code>StringBuffer</code> 和 <code>StringBuilder</code> 是 Java 中字符串处理的三个主要类，它们有以下区别：</h2>
<h2 id="1-string不可变字符串">1. String（不可变字符串）：</h2>
<ul>
<li><strong>不可变性：</strong>
<ul>
<li><code>String</code> 对象一旦创建就是不可变的。任何对字符串的修改都会创建一个新的字符串对象。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li>由于不可变性，<code>String</code> 是线程安全的。</li>
</ul>
</li>
<li><strong>性能：</strong>
<ul>
<li>拼接字符串时会创建新的字符串对象，性能可能受到影响。</li>
</ul>
</li>
<li><strong>适用场景：</strong>
<ul>
<li>当字符串内容不经常变化，且需要线程安全时，使用 <code>String</code>。</li>
</ul>
</li>
</ul>
<h3 id="2-stringbuffer可变字符串线程安全">2. StringBuffer（可变字符串，线程安全）：</h3>
<ul>
<li><strong>可变性：</strong>
<ul>
<li><code>StringBuffer</code> 对象是可变的，可以进行修改而不创建新对象。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li><code>StringBuffer</code> 是线程安全的，内部的方法都使用了 <code>synchronized</code> 关键字进行同步。</li>
</ul>
</li>
<li><strong>性能：</strong>
<ul>
<li>由于同步机制，相对于 <code>StringBuilder</code> 性能较低。</li>
</ul>
</li>
<li><strong>适用场景：</strong>
<ul>
<li>在多线程环境下需要进行字符串拼接或修改时，使用 <code>StringBuffer</code>。</li>
</ul>
</li>
</ul>
<h3 id="3-stringbuilder可变字符串非线程安全">3. StringBuilder（可变字符串，非线程安全）：</h3>
<ul>
<li><strong>可变性：</strong>
<ul>
<li><code>StringBuilder</code> 对象是可变的，可以进行修改而不创建新对象。</li>
</ul>
</li>
<li><strong>线程安全：</strong>
<ul>
<li><code>StringBuilder</code> 不是线程安全的，不使用同步机制。</li>
</ul>
</li>
<li><strong>性能：</strong>
<ul>
<li>由于不使用同步机制，相对于 <code>StringBuffer</code> 性能较高。</li>
</ul>
</li>
<li><strong>适用场景：</strong>
<ul>
<li>在单线程环境下需要进行字符串拼接或修改时，使用 <code>StringBuilder</code>。</li>
</ul>
</li>
</ul>
<h3 id="总结">总结：</h3>
<ul>
<li>如果字符串内容不经常变化，且需要线程安全，使用 <code>String</code>。</li>
<li>如果在多线程环境下需要进行字符串拼接或修改，使用 <code>StringBuffer</code>。</li>
<li>如果在单线程环境下需要进行字符串拼接或修改，使用 <code>StringBuilder</code>。</li>
</ul>
<h2 id="arraylist-和-linkedlist-是-java-中-list-接口的两个不同实现它们有以下主要区别"><code>ArrayList</code> 和 <code>LinkedList</code> 是 Java 中 <code>List</code> 接口的两个不同实现，它们有以下主要区别：</h2>
<h3 id="1-底层数据结构">1. 底层数据结构：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>基于动态数组实现。</li>
<li>通过数组实现，可以快速随机访问元素，时间复杂度为 O(1)。</li>
<li>适合读取操作较多的场景。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>基于双向链表实现。</li>
<li>链表结构使得在任意位置插入或删除元素的操作更快，时间复杂度为 O(1)。</li>
<li>适合频繁插入和删除的场景。</li>
</ul>
</li>
</ul>
<h3 id="2-访问速度">2. 访问速度：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>支持快速随机访问，因为可以通过索引直接访问数组元素。</li>
<li>get 操作的时间复杂度为 O(1)。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>需要从头或尾遍历链表来访问元素，访问速度相对较慢。</li>
<li>get 操作的时间复杂度为 O(n)，其中 n 为链表长度的一半。</li>
</ul>
</li>
</ul>
<h3 id="3-插入和删除操作">3. 插入和删除操作：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>插入和删除元素可能较慢，因为需要移动元素。</li>
<li>时间复杂度为 O(n)，其中 n 为数组的长度。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>插入和删除操作较快，因为只需改变相邻节点的引用。</li>
<li>时间复杂度为 O(1)。</li>
</ul>
</li>
</ul>
<h3 id="4-空间复杂度">4. 空间复杂度：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>每个元素都需要固定的空间，因此占用的空间相对较小。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>每个元素除了存储数据外，还需要存储两个引用，占用的空间相对较大。</li>
</ul>
</li>
</ul>
<h3 id="5-适用场景">5. 适用场景：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>适合读取操作较多的场景，需要快速随机访问元素的情况。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>适合频繁插入和删除操作的场景，以及需要在中间位置插入或删除元素的情况。</li>
</ul>
</li>
</ul>
<h3 id="总结-2">总结：</h3>
<ul>
<li>使用 <code>ArrayList</code> 时，如果主要是读取操作较多，而不涉及频繁的插入和删除，是一个较好的选择。</li>
<li>使用 <code>LinkedList</code> 时，如果需要频繁进行插入和删除操作，特别是在列表的中间位置，是一个更为合适的选择。</li>
</ul>
<h2 id="arraylist-和-vector-是-java-中-list-接口的两个实现类它们有一些区别主要涉及到同步性和性能方面"><code>ArrayList</code> 和 <code>Vector</code> 是 Java 中 <code>List</code> 接口的两个实现类，它们有一些区别，主要涉及到同步性和性能方面：</h2>
<h3 id="1-线程安全性">1. 线程安全性：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li><code>ArrayList</code> 是非线程安全的。</li>
<li>在多线程环境下，如果多个线程同时修改 <code>ArrayList</code>，可能导致不可预测的结果。</li>
</ul>
</li>
<li>
<p><strong>Vector：</strong></p>
<ul>
<li><code>Vector</code> 是线程安全的。</li>
<li>所有的方法都是同步的，通过在方法上使用 <code>synchronized</code> 关键字来保证线程安全。</li>
</ul>
</li>
</ul>
<h3 id="2-同步机制">2. 同步机制：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>由于不是线程安全的，因此没有同步开销，适用于单线程环境。</li>
</ul>
</li>
<li>
<p><strong>Vector：</strong></p>
<ul>
<li>由于是线程安全的，所有方法都使用了同步机制，会引入额外的开销。</li>
<li>在单线程环境下性能可能较差。</li>
</ul>
</li>
</ul>
<h3 id="3-扩容机制">3. 扩容机制：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>默认情况下，<code>ArrayList</code> 的初始容量是10，每次扩容会增加当前容量的一半。</li>
<li>扩容时需要重新创建一个更大的数组，并将原数组中的元素复制到新数组。</li>
</ul>
</li>
<li>
<p><strong>Vector：</strong></p>
<ul>
<li>默认情况下，<code>Vector</code> 的初始容量是10，每次扩容会翻倍当前容量。</li>
<li>扩容时需要重新创建一个更大的数组，并将原数组中的元素复制到新数组。</li>
</ul>
</li>
</ul>
<h3 id="4-性能比较">4. 性能比较：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>在单线程环境下，由于没有同步机制，性能相对较好。</li>
<li>在多线程环境下，由于非线程安全，性能可能较差。</li>
</ul>
</li>
<li>
<p><strong>Vector：</strong></p>
<ul>
<li>在单线程环境下，由于同步机制的存在，性能相对较差。</li>
<li>在多线程环境下，由于线程安全，性能相对较好。</li>
</ul>
</li>
</ul>
<h3 id="5-推荐使用">5. 推荐使用：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>推荐在单线程环境或者是明确知道不会涉及到多线程并发修改的情况下使用。</li>
</ul>
</li>
<li>
<p><strong>Vector：</strong></p>
<ul>
<li>推荐在多线程环境下或者需要保证线程安全的情况下使用。然而，由于现代 Java 中有更好的线程安全的替代方案，通常建议使用 <code>ArrayList</code> 配合 <code>Collections.synchronizedList()</code> 或者使用 <code>CopyOnWriteArrayList</code> 来代替 <code>Vector</code>。</li>
</ul>
</li>
</ul>
<h3 id="总结-3">总结：</h3>
<ul>
<li>如果不需要考虑线程安全，并且在单线程环境下使用，一般选择 <code>ArrayList</code>。</li>
<li>如果需要考虑线程安全，或者在多线程环境下使用，可以选择 <code>Vector</code> 或者更现代的线程安全集合替代方案。</li>
</ul>
<h2 id="hashmap-和-hashtable-是-java-中用于存储键值对的两个类它们之间有一些区别"><code>HashMap</code> 和 <code>Hashtable</code> 是 Java 中用于存储键值对的两个类，它们之间有一些区别：</h2>
<h3 id="1-线程安全性-2">1. 线程安全性：</h3>
<ul>
<li>
<p><strong>HashMap：</strong></p>
<ul>
<li><code>HashMap</code> 是非线程安全的，不进行同步操作。</li>
<li>在多线程环境下，需要使用外部同步手段来保证线程安全，或者使用 <code>Collections.synchronizedMap()</code> 方法将其包装成线程安全的 <code>Map</code>。</li>
</ul>
</li>
<li>
<p><strong>Hashtable：</strong></p>
<ul>
<li><code>Hashtable</code> 是线程安全的，所有的方法都使用了同步机制。</li>
<li>在多线程环境下可以直接使用，但由于同步开销，性能可能相对较低。</li>
</ul>
</li>
</ul>
<h3 id="2-null-键值的处理">2. Null 键值的处理：</h3>
<ul>
<li>
<p><strong>HashMap：</strong></p>
<ul>
<li>允许键和值都为 <code>null</code>。</li>
<li>允许有一个 <code>null</code> 键和多个 <code>null</code> 值。</li>
</ul>
</li>
<li>
<p><strong>Hashtable：</strong></p>
<ul>
<li>不允许键和值为 <code>null</code>，会抛出 <code>NullPointerException</code>。</li>
</ul>
</li>
</ul>
<h3 id="3-继承关系">3. 继承关系：</h3>
<ul>
<li>
<p><strong>HashMap：</strong></p>
<ul>
<li>继承自 <code>AbstractMap</code>，实现了 <code>Map</code> 接口。</li>
</ul>
</li>
<li>
<p><strong>Hashtable：</strong></p>
<ul>
<li>继承自 <code>Dictionary</code> 类，实现了 <code>Map</code> 接口。</li>
</ul>
</li>
</ul>
<h3 id="4-初始容量和扩容机制">4. 初始容量和扩容机制：</h3>
<ul>
<li>
<p><strong>HashMap：</strong></p>
<ul>
<li>默认初始容量为16，扩容时每次增加当前容量的一倍。</li>
<li>可以通过构造函数指定初始容量和负载因子。</li>
</ul>
</li>
<li>
<p><strong>Hashtable：</strong></p>
<ul>
<li>默认初始容量为11，扩容时每次增加当前容量的两倍加一。</li>
<li>不提供直接设置负载因子的方法。</li>
</ul>
</li>
</ul>
<h3 id="5-遍历方式">5. 遍历方式：</h3>
<ul>
<li>
<p><strong>HashMap：</strong></p>
<ul>
<li>迭代器遍历或者使用增强的 <code>for-each</code> 循环。</li>
</ul>
</li>
<li>
<p><strong>Hashtable：</strong></p>
<ul>
<li>迭代器遍历或者使用增强的 <code>for-each</code> 循环。</li>
</ul>
</li>
</ul>
<h3 id="6-性能比较">6. 性能比较：</h3>
<ul>
<li>
<p><strong>HashMap：</strong></p>
<ul>
<li>由于不进行同步操作，相对于 <code>Hashtable</code> 在多线程环境下性能较好。</li>
</ul>
</li>
<li>
<p><strong>Hashtable：</strong></p>
<ul>
<li>由于同步机制的存在，性能相对较差，不推荐在单线程环境中使用。</li>
</ul>
</li>
</ul>
<h3 id="总结-4">总结：</h3>
<ul>
<li>如果不考虑线程安全，并且在单线程环境下使用，一般选择 <code>HashMap</code>。</li>
<li>如果需要线程安全，可以选择 <code>Hashtable</code>，但在现代 Java 中，更推荐使用 <code>ConcurrentHashMap</code> 或者通过 <code>Collections.synchronizedMap()</code> 包装 <code>HashMap</code> 来实现线程安全。</li>
</ul>
<h2 id="arraylist-和-linkedlist-是-java-中-list-接口的两个实现类它们之间有一些关键区别"><code>ArrayList</code> 和 <code>LinkedList</code> 是 Java 中 <code>List</code> 接口的两个实现类，它们之间有一些关键区别：</h2>
<h3 id="1-底层数据结构-2">1. 底层数据结构：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>基于动态数组实现。</li>
<li>支持快速随机访问，时间复杂度为 O(1)。</li>
<li>适用于读取操作较多的场景。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>基于双向链表实现。</li>
<li>支持高效的插入和删除操作，时间复杂度为 O(1)。</li>
<li>适用于频繁插入和删除的场景。</li>
</ul>
</li>
</ul>
<h3 id="2-访问速度-2">2. 访问速度：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>由于支持快速随机访问，get 操作的时间复杂度为 O(1)。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>需要从头或尾遍历链表来访问元素，访问速度相对较慢。get 操作的时间复杂度为 O(n)，其中 n 为链表长度的一半。</li>
</ul>
</li>
</ul>
<h3 id="3-插入和删除操作-2">3. 插入和删除操作：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>插入和删除元素可能较慢，因为需要移动元素。时间复杂度为 O(n)，其中 n 为数组的长度。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>插入和删除操作较快，因为只需改变相邻节点的引用。时间复杂度为 O(1)。</li>
</ul>
</li>
</ul>
<h3 id="4-空间复杂度-2">4. 空间复杂度：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>每个元素都需要固定的空间，占用的空间相对较小。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>每个元素需要存储数据和两个引用，占用的空间相对较大。</li>
</ul>
</li>
</ul>
<h3 id="5-适用场景-2">5. 适用场景：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>适合读取操作较多的场景，需要快速随机访问元素的情况。</li>
</ul>
</li>
<li>
<p><strong>LinkedList：</strong></p>
<ul>
<li>适合频繁插入和删除操作的场景，以及需要在中间位置插入或删除元素的情况。</li>
</ul>
</li>
</ul>
<h3 id="总结-5">总结：</h3>
<ul>
<li>使用 <code>ArrayList</code> 时，如果主要是读取操作较多，而不涉及频繁的插入和删除，是一个较好的选择。</li>
<li>使用 <code>LinkedList</code> 时，如果需要频繁进行插入和删除操作，特别是在列表的中间位置，是一个更为合适的选择。</li>
</ul>
<h2 id="arraylist-和数组-array-是两种不同的数据结构它们之间有一些关键区别"><code>ArrayList</code> 和数组 (<code>Array</code>) 是两种不同的数据结构，它们之间有一些关键区别：</h2>
<h3 id="1-动态性">1. 动态性：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li><code>ArrayList</code> 是 Java 中的集合类，基于动态数组实现。</li>
<li>具有动态性，可以根据需要动态调整容量，不需要提前指定数组大小。</li>
</ul>
</li>
<li>
<p><strong>数组 (<code>Array</code>)：</strong></p>
<ul>
<li>数组是一种静态数据结构，一旦创建后，大小就是固定的，不能动态改变。</li>
<li>需要在创建时指定数组的大小。</li>
</ul>
</li>
</ul>
<h3 id="2-长度变化">2. 长度变化：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li><code>ArrayList</code> 可以动态增长或缩小，可以方便地进行元素的添加、删除等操作。</li>
</ul>
</li>
<li>
<p><strong>数组 (<code>Array</code>)：</strong></p>
<ul>
<li>数组的长度是固定的，一旦创建后，不能改变。如果需要更改大小，需要创建一个新的数组。</li>
</ul>
</li>
</ul>
<h3 id="3-类型灵活性">3. 类型灵活性：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li><code>ArrayList</code> 可以存储对象，可以存储不同类型的元素。</li>
</ul>
</li>
<li>
<p><strong>数组 (<code>Array</code>)：</strong></p>
<ul>
<li>数组可以存储基本数据类型和对象，但一旦创建时确定了类型，不能存储其他类型的元素。</li>
</ul>
</li>
</ul>
<h3 id="4-内置方法">4. 内置方法：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li><code>ArrayList</code> 提供了丰富的方法，例如 <code>add</code>、<code>remove</code>、<code>get</code> 等，方便对元素进行操作。</li>
</ul>
</li>
<li>
<p><strong>数组 (<code>Array</code>)：</strong></p>
<ul>
<li>数组提供了一些基本的方法，如数组的拷贝、排序等，但没有像 <code>ArrayList</code> 那样的丰富方法。</li>
</ul>
</li>
</ul>
<h3 id="5-自动装箱与拆箱">5. 自动装箱与拆箱：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li><code>ArrayList</code> 中可以直接存储对象，自动进行装箱（将基本数据类型转换为对应的包装类）和拆箱（将包装类转换为基本数据类型）。</li>
</ul>
</li>
<li>
<p><strong>数组 (<code>Array</code>)：</strong></p>
<ul>
<li>数组可以存储基本数据类型，但不能直接存储对象。如果需要存储对象，需要使用对象数组。</li>
</ul>
</li>
</ul>
<h3 id="6-遍历方式">6. 遍历方式：</h3>
<ul>
<li>
<p><strong>ArrayList：</strong></p>
<ul>
<li>可以使用增强的 <code>for-each</code> 循环或迭代器进行遍历。</li>
</ul>
</li>
<li>
<p><strong>数组 (<code>Array</code>)：</strong></p>
<ul>
<li>可以使用普通的 <code>for</code> 循环进行遍历。</li>
</ul>
</li>
</ul>
<h3 id="总结-6">总结：</h3>
<ul>
<li>使用 <code>ArrayList</code> 更加灵活，适用于需要动态调整大小并进行频繁操作的场景。</li>
<li>数组更适合在创建时确定大小，并且不需要频繁改变的场景，或者在需要直接访问内存中元素的情况。</li>
</ul>
<p><code>Comparator</code> 和 <code>Comparable</code> 是 Java 中用于对象比较的两个接口，它们之间有一些关键区别：</p>
<h2 id="comparable和comparator的区别">Comparable和Comparator的区别</h2>
<h3 id="comparable-接口">Comparable 接口：</h3>
<ol>
<li>
<p><strong>位置：</strong></p>
<ul>
<li><code>Comparable</code> 接口位于 <code>java.lang</code> 包中。</li>
<li>类实现了 <code>Comparable</code> 接口后，可以通过实现 <code>compareTo</code> 方法来定义对象之间的自然排序规则。</li>
</ul>
</li>
<li>
<p><strong>自然排序：</strong></p>
<ul>
<li><code>Comparable</code> 提供对象的自然排序（自然顺序），即在对象本身的类中定义的排序方式。</li>
<li>实现了 <code>Comparable</code> 接口的类可以直接使用 <code>Arrays.sort()</code> 或 <code>Collections.sort()</code> 进行排序。</li>
</ul>
</li>
<li>
<p><strong>实现方式：</strong></p>
<ul>
<li>实现 <code>Comparable</code> 的类需要重写 <code>compareTo</code> 方法，该方法返回负数、零或正数，分别表示当前对象小于、等于或大于指定对象。</li>
</ul>
</li>
</ol>
<h3 id="comparator-接口">Comparator 接口：</h3>
<ol>
<li>
<p><strong>位置：</strong></p>
<ul>
<li><code>Comparator</code> 接口位于 <code>java.util</code> 包中。</li>
<li>类实现了 <code>Comparator</code> 接口后，可以通过实现 <code>compare</code> 方法定义对象之间的定制排序规则。</li>
</ul>
</li>
<li>
<p><strong>定制排序：</strong></p>
<ul>
<li><code>Comparator</code> 提供定制排序的能力，允许在不改变对象本身的情况下定义多种不同的比较规则。</li>
<li>定制排序可以在对象本身之外的地方定义。</li>
</ul>
</li>
<li>
<p><strong>实现方式：</strong></p>
<ul>
<li>实现 <code>Comparator</code> 的类需要重写 <code>compare</code> 方法，该方法返回负数、零或正数，分别表示第一个对象小于、等于或大于第二个对象。</li>
</ul>
</li>
</ol>
<h3 id="使用场景">使用场景：</h3>
<ul>
<li>
<p>使用 <code>Comparable</code>：</p>
<ul>
<li>当对类的自然排序顺序有明确定义，并且不需要在不同的地方进行不同的排序时，可以实现 <code>Comparable</code> 接口。</li>
</ul>
</li>
<li>
<p>使用 <code>Comparator</code>：</p>
<ul>
<li>当需要在不同的地方使用不同的排序规则，或者对已有的类进行定制排序时，可以实现 <code>Comparator</code> 接口。</li>
</ul>
</li>
</ul>
<h3 id="总结-7">总结：</h3>
<ul>
<li><code>Comparable</code> 用于定义对象的自然排序规则，直接影响对象在集合中的排序。</li>
<li><code>Comparator</code> 用于定义定制排序规则，可以在不改变对象本身的情况下实现多种排序方式。</li>
</ul>
<p>以上是一些常见Java集合类的详细比较。在选择集合类时，应根据具体需求、性能特点和线程安全性来做出合适的选择。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[分布式搜索引擎03]]></title>
        <id>https://shenshen6666.GitHub.io/post/fen-bu-shi-sou-suo-yin-qing-03/</id>
        <link href="https://shenshen6666.GitHub.io/post/fen-bu-shi-sou-suo-yin-qing-03/">
        </link>
        <updated>2023-12-28T04:38:01.000Z</updated>
        <content type="html"><![CDATA[<h1 id="0学习目标">0.学习目标</h1>
<h1 id="1数据聚合">1.数据聚合</h1>
<p>**<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html">聚合（</a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html">aggregations</a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html">）</a>**可以让我们极其方便的实现对数据的统计、分析、运算。例如：</p>
<ul>
<li>什么品牌的手机最受欢迎？</li>
<li>这些手机的平均价格、最高价格、最低价格？</li>
<li>这些手机每月的销售情况如何？</li>
</ul>
<p>实现这些统计功能的比数据库的sql要方便的多，而且查询速度非常快，可以实现近实时搜索效果。</p>
<h2 id="11聚合的种类">1.1.聚合的种类</h2>
<p>聚合常见的有三类：</p>
<ul>
<li>
<p>**桶（Bucket）**聚合：用来对文档做分组</p>
<ul>
<li>TermAggregation：按照文档字段值分组，例如按照品牌值分组、按照国家分组</li>
<li>Date Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组</li>
</ul>
</li>
<li>
<p>**度量（Metric）**聚合：用以计算一些值，比如：最大值、最小值、平均值等</p>
<ul>
<li>Avg：求平均值</li>
<li>Max：求最大值</li>
<li>Min：求最小值</li>
<li>Stats：同时求max、min、avg、sum等</li>
</ul>
</li>
<li>
<p>**管道（pipeline）**聚合：其它聚合的结果为基础做聚合</p>
</li>
</ul>
<blockquote>
<p>**注意：**参加聚合的字段必须是keyword、日期、数值、布尔类型</p>
</blockquote>
<h2 id="12dsl实现聚合">1.2.DSL实现聚合</h2>
<p>现在，我们要统计所有数据中的酒店品牌有几种，其实就是按照品牌对数据分组。此时可以根据酒店品牌的名称做聚合，也就是Bucket聚合。</p>
<h3 id="121bucket聚合语法">1.2.1.Bucket聚合语法</h3>
<p>语法如下：</p>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;size&quot;: 0,  // 设置size为0，结果中不包含文档，只包含聚合结果
  &quot;aggs&quot;: { // 定义聚合
    &quot;brandAgg&quot;: { //给聚合起个名字
      &quot;terms&quot;: { // 聚合的类型，按照品牌值聚合，所以选择term
        &quot;field&quot;: &quot;brand&quot;, // 参与聚合的字段
        &quot;size&quot;: 20 // 希望获取的聚合结果数量
      }
    }
  }
}
</code></pre>
<p>结果如图：</p>
<figure data-type="image" tabindex="1"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723171948228.png" alt="image-20210723171948228" loading="lazy"></figure>
<h3 id="122聚合结果排序">1.2.2.聚合结果排序</h3>
<p>默认情况下，Bucket聚合会统计Bucket内的文档数量，记为_count，并且按照_count降序排序。</p>
<p>我们可以指定order属性，自定义聚合的排序方式：</p>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;size&quot;: 0, 
  &quot;aggs&quot;: {
    &quot;brandAgg&quot;: {
      &quot;terms&quot;: {
        &quot;field&quot;: &quot;brand&quot;,
        &quot;order&quot;: {
          &quot;_count&quot;: &quot;asc&quot; // 按照_count升序排列
        },
        &quot;size&quot;: 20
      }
    }
  }
}
</code></pre>
<h3 id="123限定聚合范围">1.2.3.限定聚合范围</h3>
<p>默认情况下，Bucket聚合是对索引库的所有文档做聚合，但真实场景下，用户会输入搜索条件，因此聚合必须是对搜索结果聚合。那么聚合必须添加限定条件。</p>
<p>我们可以限定要聚合的文档范围，只要添加query条件即可：</p>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;query&quot;: {
    &quot;range&quot;: {
      &quot;price&quot;: {
        &quot;lte&quot;: 200 // 只对200元以下的文档聚合
      }
    }
  }, 
  &quot;size&quot;: 0, 
  &quot;aggs&quot;: {
    &quot;brandAgg&quot;: {
      &quot;terms&quot;: {
        &quot;field&quot;: &quot;brand&quot;,
        &quot;size&quot;: 20
      }
    }
  }
}
</code></pre>
<p>这次，聚合得到的品牌明显变少了：</p>
<figure data-type="image" tabindex="2"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723172404836.png" alt="image-20210723172404836" loading="lazy"></figure>
<h3 id="124metric聚合语法">1.2.4.Metric聚合语法</h3>
<p>上节课，我们对酒店按照品牌分组，形成了一个个桶。现在我们需要对桶内的酒店做运算，获取每个品牌的用户评分的min、max、avg等值。</p>
<p>这就要用到Metric聚合了，例如stat聚合：就可以获取min、max、avg等结果。</p>
<p>语法如下：</p>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;size&quot;: 0, 
  &quot;aggs&quot;: {
    &quot;brandAgg&quot;: { 
      &quot;terms&quot;: { 
        &quot;field&quot;: &quot;brand&quot;, 
        &quot;size&quot;: 20
      },
      &quot;aggs&quot;: { // 是brands聚合的子聚合，也就是分组后对每组分别计算
        &quot;score_stats&quot;: { // 聚合名称
          &quot;stats&quot;: { // 聚合类型，这里stats可以计算min、max、avg等
            &quot;field&quot;: &quot;score&quot; // 聚合字段，这里是score
          }
        }
      }
    }
  }
}
</code></pre>
<p>这次的score_stats聚合是在brandAgg的聚合内部嵌套的子聚合。因为我们需要在每个桶分别计算。</p>
<p>另外，我们还可以给聚合结果做个排序，例如按照每个桶的酒店平均分做排序：</p>
<figure data-type="image" tabindex="3"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723172917636.png" alt="image-20210723172917636" loading="lazy"></figure>
<h3 id="125小结">1.2.5.小结</h3>
<p>aggs代表聚合，与query同级，此时query的作用是？</p>
<ul>
<li>限定聚合的的文档范围</li>
</ul>
<p>聚合必须的三要素：</p>
<ul>
<li>聚合名称</li>
<li>聚合类型</li>
<li>聚合字段</li>
</ul>
<p>聚合可配置属性有：</p>
<ul>
<li>size：指定聚合结果数量</li>
<li>order：指定聚合结果排序方式</li>
<li>field：指定聚合字段</li>
</ul>
<h2 id="13restapi实现聚合">1.3.RestAPI实现聚合</h2>
<h3 id="131api语法">1.3.1.API语法</h3>
<p>聚合条件与query条件同级别，因此需要使用request.source()来指定聚合条件。</p>
<p>聚合条件的语法：</p>
<figure data-type="image" tabindex="4"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723173057733.png" alt="image-20210723173057733" loading="lazy"></figure>
<p>聚合的结果也与查询结果不同，API也比较特殊。不过同样是JSON逐层解析：</p>
<figure data-type="image" tabindex="5"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723173215728.png" alt="image-20210723173215728" loading="lazy"></figure>
<h3 id="132业务需求">1.3.2.业务需求</h3>
<p>需求：搜索页面的品牌、城市等信息不应该是在页面写死，而是通过聚合索引库中的酒店数据得来的：</p>
<figure data-type="image" tabindex="6"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723192605566.png" alt="image-20210723192605566" loading="lazy"></figure>
<p>分析：</p>
<p>目前，页面的城市列表、星级列表、品牌列表都是写死的，并不会随着搜索结果的变化而变化。但是用户搜索条件改变时，搜索结果会跟着变化。</p>
<p>例如：用户搜索“东方明珠”，那搜索的酒店肯定是在上海东方明珠附近，因此，城市只能是上海，此时城市列表中就不应该显示北京、深圳、杭州这些信息了。</p>
<p>也就是说，搜索结果中包含哪些城市，页面就应该列出哪些城市；搜索结果中包含哪些品牌，页面就应该列出哪些品牌。</p>
<p>如何得知搜索结果中包含哪些品牌？如何得知搜索结果中包含哪些城市？</p>
<p>使用聚合功能，利用Bucket聚合，对搜索结果中的文档基于品牌分组、基于城市分组，就能得知包含哪些品牌、哪些城市了。</p>
<p>因为是对搜索结果聚合，因此聚合是<strong>限定范围的聚合</strong>，也就是说聚合的限定条件跟搜索文档的条件一致。</p>
<p>查看浏览器可以发现，前端其实已经发出了这样的一个请求：</p>
<figure data-type="image" tabindex="7"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723193730799.png" alt="image-20210723193730799" loading="lazy"></figure>
<p>请求<strong>参数与搜索文档的参数完全一致</strong>。</p>
<p>返回值类型就是页面要展示的最终结果：</p>
<figure data-type="image" tabindex="8"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723203915982.png" alt="image-20210723203915982" loading="lazy"></figure>
<p>结果是一个Map结构：</p>
<ul>
<li>key是字符串，城市、星级、品牌、价格</li>
<li>value是集合，例如多个城市的名称</li>
</ul>
<h3 id="133业务实现">1.3.3.业务实现</h3>
<p>在<code>cn.itcast.hotel.web</code>包的<code>HotelController</code>中添加一个方法，遵循下面的要求：</p>
<ul>
<li>请求方式：<code>POST</code></li>
<li>请求路径：<code>/hotel/filters</code></li>
<li>请求参数：<code>RequestParams</code>，与搜索文档的参数一致</li>
<li>返回值类型：<code>Map&lt;String, List&lt;String&gt;&gt;</code></li>
</ul>
<p>代码：</p>
<pre><code class="language-java">    @PostMapping(&quot;filters&quot;)
    public Map&lt;String, List&lt;String&gt;&gt; getFilters(@RequestBody RequestParams params){
        return hotelService.getFilters(params);
    }
</code></pre>
<p>这里调用了IHotelService中的getFilters方法，尚未实现。</p>
<p>在<code>cn.itcast.hotel.service.IHotelService</code>中定义新方法：</p>
<pre><code class="language-java">Map&lt;String, List&lt;String&gt;&gt; filters(RequestParams params);
</code></pre>
<p>在<code>cn.itcast.hotel.service.impl.HotelService</code>中实现该方法：</p>
<pre><code class="language-java">@Override
public Map&lt;String, List&lt;String&gt;&gt; filters(RequestParams params) {
    try {
        // 1.准备Request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.准备DSL
        // 2.1.query
        buildBasicQuery(params, request);
        // 2.2.设置size
        request.source().size(0);
        // 2.3.聚合
        buildAggregation(request);
        // 3.发出请求
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        // 4.解析结果
        Map&lt;String, List&lt;String&gt;&gt; result = new HashMap&lt;&gt;();
        Aggregations aggregations = response.getAggregations();
        // 4.1.根据品牌名称，获取品牌结果
        List&lt;String&gt; brandList = getAggByName(aggregations, &quot;brandAgg&quot;);
        result.put(&quot;品牌&quot;, brandList);
        // 4.2.根据品牌名称，获取品牌结果
        List&lt;String&gt; cityList = getAggByName(aggregations, &quot;cityAgg&quot;);
        result.put(&quot;城市&quot;, cityList);
        // 4.3.根据品牌名称，获取品牌结果
        List&lt;String&gt; starList = getAggByName(aggregations, &quot;starAgg&quot;);
        result.put(&quot;星级&quot;, starList);

        return result;
    } catch (IOException e) {
        throw new RuntimeException(e);
    }
}

private void buildAggregation(SearchRequest request) {
    request.source().aggregation(AggregationBuilders
                                 .terms(&quot;brandAgg&quot;)
                                 .field(&quot;brand&quot;)
                                 .size(100)
                                );
    request.source().aggregation(AggregationBuilders
                                 .terms(&quot;cityAgg&quot;)
                                 .field(&quot;city&quot;)
                                 .size(100)
                                );
    request.source().aggregation(AggregationBuilders
                                 .terms(&quot;starAgg&quot;)
                                 .field(&quot;starName&quot;)
                                 .size(100)
                                );
}

private List&lt;String&gt; getAggByName(Aggregations aggregations, String aggName) {
    // 4.1.根据聚合名称获取聚合结果
    Terms brandTerms = aggregations.get(aggName);
    // 4.2.获取buckets
    List&lt;? extends Terms.Bucket&gt; buckets = brandTerms.getBuckets();
    // 4.3.遍历
    List&lt;String&gt; brandList = new ArrayList&lt;&gt;();
    for (Terms.Bucket bucket : buckets) {
        // 4.4.获取key
        String key = bucket.getKeyAsString();
        brandList.add(key);
    }
    return brandList;
}
</code></pre>
<h1 id="2自动补全">2.自动补全</h1>
<p>当用户在搜索框输入字符时，我们应该提示出与该字符有关的搜索项，如图：</p>
<figure data-type="image" tabindex="9"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723204936367.png" alt="image-20210723204936367" loading="lazy"></figure>
<p>这种根据用户输入的字母，提示完整词条的功能，就是自动补全了。</p>
<p>因为需要根据拼音字母来推断，因此要用到拼音分词功能。</p>
<h2 id="21拼音分词器">2.1.拼音分词器</h2>
<p>要实现根据字母做补全，就必须对文档按照拼音分词。在GitHub上恰好有elasticsearch的拼音分词插件。地址：https://github.com/medcl/elasticsearch-analysis-pinyin</p>
<figure data-type="image" tabindex="10"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723205932746.png" alt="image-20210723205932746" loading="lazy"></figure>
<p>课前资料中也提供了拼音分词器的安装包：</p>
<figure data-type="image" tabindex="11"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723205722303.png" alt="image-20210723205722303" loading="lazy"></figure>
<p>安装方式与IK分词器一样，分三步：</p>
<p>​	①解压</p>
<p>​	②上传到虚拟机中，elasticsearch的plugin目录</p>
<p>​	③重启elasticsearch</p>
<p>​	④测试</p>
<p>详细安装步骤可以参考IK分词器的安装过程。</p>
<p>测试用法如下：</p>
<pre><code class="language-json">POST /_analyze
{
  &quot;text&quot;: &quot;如家酒店还不错&quot;,
  &quot;analyzer&quot;: &quot;pinyin&quot;
}
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="12"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723210126506.png" alt="image-20210723210126506" loading="lazy"></figure>
<h2 id="22自定义分词器">2.2.自定义分词器</h2>
<p>默认的拼音分词器会将每个汉字单独分为拼音，而我们希望的是每个词条形成一组拼音，需要对拼音分词器做个性化定制，形成自定义分词器。</p>
<p>elasticsearch中分词器（analyzer）的组成包含三部分：</p>
<ul>
<li>character filters：在tokenizer之前对文本进行处理。例如删除字符、替换字符</li>
<li>tokenizer：将文本按照一定的规则切割成词条（term）。例如keyword，就是不分词；还有ik_smart</li>
<li>tokenizer filter：将tokenizer输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等</li>
</ul>
<p>文档分词时会依次由这三部分来处理文档：</p>
<figure data-type="image" tabindex="13"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723210427878.png" alt="image-20210723210427878" loading="lazy"></figure>
<p>声明自定义分词器的语法如下：</p>
<pre><code class="language-json">PUT /test
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: { // 自定义分词器
        &quot;my_analyzer&quot;: {  // 分词器名称
          &quot;tokenizer&quot;: &quot;ik_max_word&quot;,
          &quot;filter&quot;: &quot;py&quot;
        }
      },
      &quot;filter&quot;: { // 自定义tokenizer filter
        &quot;py&quot;: { // 过滤器名称
          &quot;type&quot;: &quot;pinyin&quot;, // 过滤器类型，这里是pinyin
		  &quot;keep_full_pinyin&quot;: false,
          &quot;keep_joined_full_pinyin&quot;: true,
          &quot;keep_original&quot;: true,
          &quot;limit_first_letter_length&quot;: 16,
          &quot;remove_duplicated_term&quot;: true,
          &quot;none_chinese_pinyin_tokenize&quot;: false
        }
      }
    }
  },
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;name&quot;: {
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;my_analyzer&quot;,
        &quot;search_analyzer&quot;: &quot;ik_smart&quot;
      }
    }
  }
}

</code></pre>
<p>测试：</p>
<figure data-type="image" tabindex="14"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723211829150.png" alt="image-20210723211829150" loading="lazy"></figure>
<p>总结：</p>
<p>如何使用拼音分词器？</p>
<ul>
<li>
<p>①下载pinyin分词器</p>
</li>
<li>
<p>②解压并放到elasticsearch的plugin目录</p>
</li>
<li>
<p>③重启即可</p>
</li>
</ul>
<p>如何自定义分词器？</p>
<ul>
<li>
<p>①创建索引库时，在settings中配置，可以包含三部分</p>
</li>
<li>
<p>②character filter</p>
</li>
<li>
<p>③tokenizer</p>
</li>
<li>
<p>④filter</p>
</li>
</ul>
<p>拼音分词器注意事项？</p>
<ul>
<li>为了避免搜索到同音字，搜索时不要使用拼音分词器</li>
</ul>
<h2 id="23自动补全查询">2.3.自动补全查询</h2>
<p>elasticsearch提供了<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.6/search-suggesters.html">Completion Suggester</a>查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束：</p>
<ul>
<li>
<p>参与补全查询的字段必须是completion类型。</p>
</li>
<li>
<p>字段的内容一般是用来补全的多个词条形成的数组。</p>
</li>
</ul>
<p>比如，一个这样的索引库：</p>
<pre><code class="language-json">// 创建索引库
PUT test
{
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;title&quot;:{
        &quot;type&quot;: &quot;completion&quot;
      }
    }
  }
}

</code></pre>
<p>然后插入下面的数据：</p>
<pre><code class="language-json">// 示例数据
POST test/_doc
{
  &quot;title&quot;: [&quot;Sony&quot;, &quot;WH-1000XM3&quot;]
}
POST test/_doc
{
  &quot;title&quot;: [&quot;SK-II&quot;, &quot;PITERA&quot;]
}
POST test/_doc
{
  &quot;title&quot;: [&quot;Nintendo&quot;, &quot;switch&quot;]
}

</code></pre>
<p>查询的DSL语句如下：</p>
<pre><code class="language-json">// 自动补全查询
GET /test/_search
{
  &quot;suggest&quot;: {
    &quot;title_suggest&quot;: {
      &quot;text&quot;: &quot;s&quot;, // 关键字
      &quot;completion&quot;: {
        &quot;field&quot;: &quot;title&quot;, // 补全查询的字段
        &quot;skip_duplicates&quot;: true, // 跳过重复的
        &quot;size&quot;: 10 // 获取前10条结果
      }
    }
  }
}

</code></pre>
<h2 id="24实现酒店搜索框自动补全">2.4.实现酒店搜索框自动补全</h2>
<p>现在，我们的hotel索引库还没有设置拼音分词器，需要修改索引库中的配置。但是我们知道索引库是无法修改的，只能删除然后重新创建。</p>
<p>另外，我们需要添加一个字段，用来做自动补全，将brand、suggestion、city等都放进去，作为自动补全的提示。</p>
<p>因此，总结一下，我们需要做的事情包括：</p>
<ol>
<li>
<p>修改hotel索引库结构，设置自定义拼音分词器</p>
</li>
<li>
<p>修改索引库的name、all字段，使用自定义分词器</p>
</li>
<li>
<p>索引库添加一个新字段suggestion，类型为completion类型，使用自定义的分词器</p>
</li>
<li>
<p>给HotelDoc类添加suggestion字段，内容包含brand、business</p>
</li>
<li>
<p>重新导入数据到hotel库</p>
</li>
</ol>
<h3 id="241修改酒店映射结构">2.4.1.修改酒店映射结构</h3>
<p>代码如下：</p>
<pre><code class="language-json">// 酒店数据索引库
PUT /hotel
{
  &quot;settings&quot;: {
    &quot;analysis&quot;: {
      &quot;analyzer&quot;: {
        &quot;text_anlyzer&quot;: {
          &quot;tokenizer&quot;: &quot;ik_max_word&quot;,
          &quot;filter&quot;: &quot;py&quot;
        },
        &quot;completion_analyzer&quot;: {
          &quot;tokenizer&quot;: &quot;keyword&quot;,
          &quot;filter&quot;: &quot;py&quot;
        }
      },
      &quot;filter&quot;: {
        &quot;py&quot;: {
          &quot;type&quot;: &quot;pinyin&quot;,
          &quot;keep_full_pinyin&quot;: false,
          &quot;keep_joined_full_pinyin&quot;: true,
          &quot;keep_original&quot;: true,
          &quot;limit_first_letter_length&quot;: 16,
          &quot;remove_duplicated_term&quot;: true,
          &quot;none_chinese_pinyin_tokenize&quot;: false
        }
      }
    }
  },
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;id&quot;:{
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;name&quot;:{
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;text_anlyzer&quot;,
        &quot;search_analyzer&quot;: &quot;ik_smart&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      },
      &quot;address&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: false
      },
      &quot;price&quot;:{
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;score&quot;:{
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;brand&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      },
      &quot;city&quot;:{
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;starName&quot;:{
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;business&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      },
      &quot;location&quot;:{
        &quot;type&quot;: &quot;geo_point&quot;
      },
      &quot;pic&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: false
      },
      &quot;all&quot;:{
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;text_anlyzer&quot;,
        &quot;search_analyzer&quot;: &quot;ik_smart&quot;
      },
      &quot;suggestion&quot;:{
          &quot;type&quot;: &quot;completion&quot;,
          &quot;analyzer&quot;: &quot;completion_analyzer&quot;
      }
    }
  }
}

</code></pre>
<h3 id="242修改hoteldoc实体">2.4.2.修改HotelDoc实体</h3>
<p>HotelDoc中要添加一个字段，用来做自动补全，内容可以是酒店品牌、城市、商圈等信息。按照自动补全字段的要求，最好是这些字段的数组。</p>
<p>因此我们在HotelDoc中添加一个suggestion字段，类型为<code>List&lt;String&gt;</code>，然后将brand、city、business等信息放到里面。</p>
<p>代码如下：</p>
<pre><code class="language-java">package cn.itcast.hotel.pojo;

import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;

@Data
@NoArgsConstructor
public class HotelDoc {
    private Long id;
    private String name;
    private String address;
    private Integer price;
    private Integer score;
    private String brand;
    private String city;
    private String starName;
    private String business;
    private String location;
    private String pic;
    private Object distance;
    private Boolean isAD;
    private List&lt;String&gt; suggestion;

    public HotelDoc(Hotel hotel) {
        this.id = hotel.getId();
        this.name = hotel.getName();
        this.address = hotel.getAddress();
        this.price = hotel.getPrice();
        this.score = hotel.getScore();
        this.brand = hotel.getBrand();
        this.city = hotel.getCity();
        this.starName = hotel.getStarName();
        this.business = hotel.getBusiness();
        this.location = hotel.getLatitude() + &quot;, &quot; + hotel.getLongitude();
        this.pic = hotel.getPic();
        // 组装suggestion
        if(this.business.contains(&quot;/&quot;)){
            // business有多个值，需要切割
            String[] arr = this.business.split(&quot;/&quot;);
            // 添加元素
            this.suggestion = new ArrayList&lt;&gt;();
            this.suggestion.add(this.brand);
            Collections.addAll(this.suggestion, arr);
        }else {
            this.suggestion = Arrays.asList(this.brand, this.business);
        }
    }
}

</code></pre>
<h3 id="243重新导入">2.4.3.重新导入</h3>
<p>重新执行之前编写的导入数据功能，可以看到新的酒店数据中包含了suggestion：</p>
<figure data-type="image" tabindex="15"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723213546183.png" alt="image-20210723213546183" loading="lazy"></figure>
<h3 id="244自动补全查询的javaapi">2.4.4.自动补全查询的JavaAPI</h3>
<p>之前我们学习了自动补全查询的DSL，而没有学习对应的JavaAPI，这里给出一个示例：</p>
<figure data-type="image" tabindex="16"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723213759922.png" alt="image-20210723213759922" loading="lazy"></figure>
<p>而自动补全的结果也比较特殊，解析的代码如下：</p>
<figure data-type="image" tabindex="17"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723213917524.png" alt="image-20210723213917524" loading="lazy"></figure>
<h3 id="245实现搜索框自动补全">2.4.5.实现搜索框自动补全</h3>
<p>查看前端页面，可以发现当我们在输入框键入时，前端会发起ajax请求：</p>
<figure data-type="image" tabindex="18"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723214021062.png" alt="image-20210723214021062" loading="lazy"></figure>
<p>返回值是补全词条的集合，类型为<code>List&lt;String&gt;</code></p>
<p>1）在<code>cn.itcast.hotel.web</code>包下的<code>HotelController</code>中添加新接口，接收新的请求：</p>
<pre><code class="language-java">@GetMapping(&quot;suggestion&quot;)
public List&lt;String&gt; getSuggestions(@RequestParam(&quot;key&quot;) String prefix) {
    return hotelService.getSuggestions(prefix);
}

</code></pre>
<p>2）在<code>cn.itcast.hotel.service</code>包下的<code>IhotelService</code>中添加方法：</p>
<pre><code class="language-java">List&lt;String&gt; getSuggestions(String prefix);

</code></pre>
<p>3）在<code>cn.itcast.hotel.service.impl.HotelService</code>中实现该方法：</p>
<pre><code class="language-java">@Override
public List&lt;String&gt; getSuggestions(String prefix) {
    try {
        // 1.准备Request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.准备DSL
        request.source().suggest(new SuggestBuilder().addSuggestion(
            &quot;suggestions&quot;,
            SuggestBuilders.completionSuggestion(&quot;suggestion&quot;)
            .prefix(prefix)
            .skipDuplicates(true)
            .size(10)
        ));
        // 3.发起请求
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        // 4.解析结果
        Suggest suggest = response.getSuggest();
        // 4.1.根据补全查询名称，获取补全结果
        CompletionSuggestion suggestions = suggest.getSuggestion(&quot;suggestions&quot;);
        // 4.2.获取options
        List&lt;CompletionSuggestion.Entry.Option&gt; options = suggestions.getOptions();
        // 4.3.遍历
        List&lt;String&gt; list = new ArrayList&lt;&gt;(options.size());
        for (CompletionSuggestion.Entry.Option option : options) {
            String text = option.getText().toString();
            list.add(text);
        }
        return list;
    } catch (IOException e) {
        throw new RuntimeException(e);
    }
}

</code></pre>
<h1 id="3数据同步">3.数据同步</h1>
<p>elasticsearch中的酒店数据来自于mysql数据库，因此mysql数据发生改变时，elasticsearch也必须跟着改变，这个就是elasticsearch与mysql之间的<strong>数据同步</strong>。</p>
<figure data-type="image" tabindex="19"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723214758392.png" alt="image-20210723214758392" loading="lazy"></figure>
<h2 id="31思路分析">3.1.思路分析</h2>
<p>常见的数据同步方案有三种：</p>
<ul>
<li>同步调用</li>
<li>异步通知</li>
<li>监听binlog</li>
</ul>
<h3 id="311同步调用">3.1.1.同步调用</h3>
<p>方案一：同步调用</p>
<figure data-type="image" tabindex="20"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723214931869.png" alt="image-20210723214931869" loading="lazy"></figure>
<p>基本步骤如下：</p>
<ul>
<li>hotel-demo对外提供接口，用来修改elasticsearch中的数据</li>
<li>酒店管理服务在完成数据库操作后，直接调用hotel-demo提供的接口，</li>
</ul>
<h3 id="312异步通知">3.1.2.异步通知</h3>
<p>方案二：异步通知</p>
<figure data-type="image" tabindex="21"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723215140735.png" alt="image-20210723215140735" loading="lazy"></figure>
<p>流程如下：</p>
<ul>
<li>hotel-admin对mysql数据库数据完成增、删、改后，发送MQ消息</li>
<li>hotel-demo监听MQ，接收到消息后完成elasticsearch数据修改</li>
</ul>
<h3 id="313监听binlog">3.1.3.监听binlog</h3>
<p>方案三：监听binlog</p>
<figure data-type="image" tabindex="22"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723215518541.png" alt="image-20210723215518541" loading="lazy"></figure>
<p>流程如下：</p>
<ul>
<li>给mysql开启binlog功能</li>
<li>mysql完成增、删、改操作都会记录在binlog中</li>
<li>hotel-demo基于canal监听binlog变化，实时更新elasticsearch中的内容</li>
</ul>
<h3 id="314选择">3.1.4.选择</h3>
<p>方式一：同步调用</p>
<ul>
<li>优点：实现简单，粗暴</li>
<li>缺点：业务耦合度高</li>
</ul>
<p>方式二：异步通知</p>
<ul>
<li>优点：低耦合，实现难度一般</li>
<li>缺点：依赖mq的可靠性</li>
</ul>
<p>方式三：监听binlog</p>
<ul>
<li>优点：完全解除服务间耦合</li>
<li>缺点：开启binlog增加数据库负担、实现复杂度高</li>
</ul>
<h2 id="32实现数据同步">3.2.实现数据同步</h2>
<h3 id="321思路">3.2.1.思路</h3>
<p>利用课前资料提供的hotel-admin项目作为酒店管理的微服务。当酒店数据发生增、删、改时，要求对elasticsearch中数据也要完成相同操作。</p>
<p>步骤：</p>
<ul>
<li>
<p>导入课前资料提供的hotel-admin项目，启动并测试酒店数据的CRUD</p>
</li>
<li>
<p>声明exchange、queue、RoutingKey</p>
</li>
<li>
<p>在hotel-admin中的增、删、改业务中完成消息发送</p>
</li>
<li>
<p>在hotel-demo中完成消息监听，并更新elasticsearch中数据</p>
</li>
<li>
<p>启动并测试数据同步功能</p>
</li>
</ul>
<h3 id="322导入demo">3.2.2.导入demo</h3>
<p>导入课前资料提供的hotel-admin项目：</p>
<figure data-type="image" tabindex="23"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723220237930.png" alt="image-20210723220237930" loading="lazy"></figure>
<p>运行后，访问 http://localhost:8099</p>
<figure data-type="image" tabindex="24"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723220354464.png" alt="image-20210723220354464" loading="lazy"></figure>
<p>其中包含了酒店的CRUD功能：</p>
<figure data-type="image" tabindex="25"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723220511090.png" alt="image-20210723220511090" loading="lazy"></figure>
<h3 id="323声明交换机-队列">3.2.3.声明交换机、队列</h3>
<p>MQ结构如图：</p>
<figure data-type="image" tabindex="26"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723215850307.png" alt="image-20210723215850307" loading="lazy"></figure>
<h4 id="1引入依赖">1）引入依赖</h4>
<p>在hotel-admin、hotel-demo中引入rabbitmq的依赖：</p>
<pre><code class="language-xml">&lt;!--amqp--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<h4 id="2声明队列交换机名称">2）声明队列交换机名称</h4>
<p>在hotel-admin和hotel-demo中的<code>cn.itcast.hotel.constatnts</code>包下新建一个类<code>MqConstants</code>：</p>
<pre><code class="language-java">package cn.itcast.hotel.constatnts;

    public class MqConstants {
    /**
     * 交换机
     */
    public final static String HOTEL_EXCHANGE = &quot;hotel.topic&quot;;
    /**
     * 监听新增和修改的队列
     */
    public final static String HOTEL_INSERT_QUEUE = &quot;hotel.insert.queue&quot;;
    /**
     * 监听删除的队列
     */
    public final static String HOTEL_DELETE_QUEUE = &quot;hotel.delete.queue&quot;;
    /**
     * 新增或修改的RoutingKey
     */
    public final static String HOTEL_INSERT_KEY = &quot;hotel.insert&quot;;
    /**
     * 删除的RoutingKey
     */
    public final static String HOTEL_DELETE_KEY = &quot;hotel.delete&quot;;
}

</code></pre>
<h4 id="3声明队列交换机">3）声明队列交换机</h4>
<p>在hotel-demo中，定义配置类，声明队列、交换机：</p>
<pre><code class="language-java">package cn.itcast.hotel.config;

import cn.itcast.hotel.constants.MqConstants;
import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.Queue;
import org.springframework.amqp.core.TopicExchange;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class MqConfig {
    @Bean
    public TopicExchange topicExchange(){
        return new TopicExchange(MqConstants.HOTEL_EXCHANGE, true, false);
    }

    @Bean
    public Queue insertQueue(){
        return new Queue(MqConstants.HOTEL_INSERT_QUEUE, true);
    }

    @Bean
    public Queue deleteQueue(){
        return new Queue(MqConstants.HOTEL_DELETE_QUEUE, true);
    }

    @Bean
    public Binding insertQueueBinding(){
        return BindingBuilder.bind(insertQueue()).to(topicExchange()).with(MqConstants.HOTEL_INSERT_KEY);
    }

    @Bean
    public Binding deleteQueueBinding(){
        return BindingBuilder.bind(deleteQueue()).to(topicExchange()).with(MqConstants.HOTEL_DELETE_KEY);
    }
}

</code></pre>
<h3 id="324发送mq消息">3.2.4.发送MQ消息</h3>
<p>在hotel-admin中的增、删、改业务中分别发送MQ消息：</p>
<figure data-type="image" tabindex="27"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723221843816.png" alt="image-20210723221843816" loading="lazy"></figure>
<h3 id="325接收mq消息">3.2.5.接收MQ消息</h3>
<p>hotel-demo接收到MQ消息要做的事情包括：</p>
<ul>
<li>新增消息：根据传递的hotel的id查询hotel信息，然后新增一条数据到索引库</li>
<li>删除消息：根据传递的hotel的id删除索引库中的一条数据</li>
</ul>
<p>1）首先在hotel-demo的<code>cn.itcast.hotel.service</code>包下的<code>IHotelService</code>中新增新增、删除业务</p>
<pre><code class="language-java">void deleteById(Long id);

void insertById(Long id);

</code></pre>
<p>2）给hotel-demo中的<code>cn.itcast.hotel.service.impl</code>包下的HotelService中实现业务：</p>
<pre><code class="language-java">@Override
public void deleteById(Long id) {
    try {
        // 1.准备Request
        DeleteRequest request = new DeleteRequest(&quot;hotel&quot;, id.toString());
        // 2.发送请求
        client.delete(request, RequestOptions.DEFAULT);
    } catch (IOException e) {
        throw new RuntimeException(e);
    }
}

@Override
public void insertById(Long id) {
    try {
        // 0.根据id查询酒店数据
        Hotel hotel = getById(id);
        // 转换为文档类型
        HotelDoc hotelDoc = new HotelDoc(hotel);

        // 1.准备Request对象
        IndexRequest request = new IndexRequest(&quot;hotel&quot;).id(hotel.getId().toString());
        // 2.准备Json文档
        request.source(JSON.toJSONString(hotelDoc), XContentType.JSON);
        // 3.发送请求
        client.index(request, RequestOptions.DEFAULT);
    } catch (IOException e) {
        throw new RuntimeException(e);
    }
}

</code></pre>
<p>3）编写监听器</p>
<p>在hotel-demo中的<code>cn.itcast.hotel.mq</code>包新增一个类：</p>
<pre><code class="language-java">package cn.itcast.hotel.mq;

import cn.itcast.hotel.constants.MqConstants;
import cn.itcast.hotel.service.IHotelService;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

@Component
public class HotelListener {

    @Autowired
    private IHotelService hotelService;

    /**
     * 监听酒店新增或修改的业务
     * @param id 酒店id
     */
    @RabbitListener(queues = MqConstants.HOTEL_INSERT_QUEUE)
    public void listenHotelInsertOrUpdate(Long id){
        hotelService.insertById(id);
    }

    /**
     * 监听酒店删除的业务
     * @param id 酒店id
     */
    @RabbitListener(queues = MqConstants.HOTEL_DELETE_QUEUE)
    public void listenHotelDelete(Long id){
        hotelService.deleteById(id);
    }
}

</code></pre>
<h1 id="4集群">4.集群</h1>
<p>单机的elasticsearch做数据存储，必然面临两个问题：海量数据存储问题、单点故障问题。</p>
<ul>
<li>海量数据存储问题：将索引库从逻辑上拆分为N个分片（shard），存储到多个节点</li>
<li>单点故障问题：将分片数据在不同节点备份（replica ）</li>
</ul>
<p><strong>ES集群相关概念</strong>:</p>
<ul>
<li>
<p>集群（cluster）：一组拥有共同的 cluster name 的 节点。</p>
</li>
<li>
<p><font color="red">节点（node)</font>   ：集群中的一个 Elasticearch 实例</p>
</li>
<li>
<p><font color="red">分片（shard）</font>：索引可以被拆分为不同的部分进行存储，称为分片。在集群环境下，一个索引的不同分片可以拆分到不同的节点中</p>
<p>解决问题：数据量太大，单点存储量有限的问题。</p>
<figure data-type="image" tabindex="28"><img src="https://shenshen6666.GitHub.io/post-images/image-20200104124440086-5602723.png" alt="image-20200104124440086" loading="lazy"></figure>
<blockquote>
<p>此处，我们把数据分成3片：shard0、shard1、shard2</p>
</blockquote>
</li>
<li>
<p>主分片（Primary shard）：相对于副本分片的定义。</p>
</li>
<li>
<p>副本分片（Replica shard）每个主分片可以有一个或者多个副本，数据和主分片一样。</p>
<p>​</p>
</li>
</ul>
<p>数据备份可以保证高可用，但是每个分片备份一份，所需要的节点数量就会翻一倍，成本实在是太高了！</p>
<p>为了在高可用和成本间寻求平衡，我们可以这样做：</p>
<ul>
<li>首先对数据分片，存储到不同节点</li>
<li>然后对每个分片进行备份，放到对方节点，完成互相备份</li>
</ul>
<p>这样可以大大减少所需要的服务节点数量，如图，我们以3分片，每个分片备份一份为例：</p>
<figure data-type="image" tabindex="29"><img src="https://shenshen6666.GitHub.io/post-images/image-20200104124551912.png" alt="image-20200104124551912" loading="lazy"></figure>
<p>现在，每个分片都有1个备份，存储在3个节点：</p>
<ul>
<li>node0：保存了分片0和1</li>
<li>node1：保存了分片0和2</li>
<li>node2：保存了分片1和2</li>
</ul>
<h2 id="41搭建es集群">4.1.搭建ES集群</h2>
<p>参考课前资料的文档：</p>
<figure data-type="image" tabindex="30"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723222732427.png" alt="image-20210723222732427" loading="lazy"></figure>
<p>其中的第四章节：</p>
<figure data-type="image" tabindex="31"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723222812619.png" alt="image-20210723222812619" loading="lazy"></figure>
<h2 id="42集群脑裂问题">4.2.集群脑裂问题</h2>
<h3 id="421集群职责划分">4.2.1.集群职责划分</h3>
<p>elasticsearch中集群节点有不同的职责划分：</p>
<figure data-type="image" tabindex="32"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723223008967.png" alt="image-20210723223008967" loading="lazy"></figure>
<p>默认情况下，集群中的任何一个节点都同时具备上述四种角色。</p>
<p>但是真实的集群一定要将集群职责分离：</p>
<ul>
<li>master节点：对CPU要求高，但是内存要求第</li>
<li>data节点：对CPU和内存要求都高</li>
<li>coordinating节点：对网络带宽、CPU要求高</li>
</ul>
<p>职责分离可以让我们根据不同节点的需求分配不同的硬件去部署。而且避免业务之间的互相干扰。</p>
<p>一个典型的es集群职责划分如图：</p>
<figure data-type="image" tabindex="33"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723223629142.png" alt="image-20210723223629142" loading="lazy"></figure>
<h3 id="422脑裂问题">4.2.2.脑裂问题</h3>
<p>脑裂是因为集群中的节点失联导致的。</p>
<p>例如一个集群中，主节点与其它节点失联：</p>
<figure data-type="image" tabindex="34"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723223804995.png" alt="image-20210723223804995" loading="lazy"></figure>
<p>此时，node2和node3认为node1宕机，就会重新选主：</p>
<figure data-type="image" tabindex="35"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723223845754.png" alt="image-20210723223845754" loading="lazy"></figure>
<p>当node3当选后，集群继续对外提供服务，node2和node3自成集群，node1自成集群，两个集群数据不同步，出现数据差异。</p>
<p>当网络恢复后，因为集群中有两个master节点，集群状态的不一致，出现脑裂的情况：</p>
<figure data-type="image" tabindex="36"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723224000555.png" alt="image-20210723224000555" loading="lazy"></figure>
<p>解决脑裂的方案是，要求选票超过 ( eligible节点数量 + 1 ）/ 2 才能当选为主，因此eligible节点数量最好是奇数。对应配置项是discovery.zen.minimum_master_nodes，在es7.0以后，已经成为默认配置，因此一般不会发生脑裂问题</p>
<p>例如：3个节点形成的集群，选票必须超过 （3 + 1） / 2 ，也就是2票。node3得到node2和node3的选票，当选为主。node1只有自己1票，没有当选。集群中依然只有1个主节点，没有出现脑裂。</p>
<h3 id="423小结">4.2.3.小结</h3>
<p>master eligible节点的作用是什么？</p>
<ul>
<li>参与集群选主</li>
<li>主节点可以管理集群状态、管理分片信息、处理创建和删除索引库的请求</li>
</ul>
<p>data节点的作用是什么？</p>
<ul>
<li>数据的CRUD</li>
</ul>
<p>coordinator节点的作用是什么？</p>
<ul>
<li>
<p>路由请求到其它节点</p>
</li>
<li>
<p>合并查询到的结果，返回给用户</p>
</li>
</ul>
<h2 id="43集群分布式存储">4.3.集群分布式存储</h2>
<p>当新增文档时，应该保存到不同分片，保证数据均衡，那么coordinating node如何确定数据该存储到哪个分片呢？</p>
<h3 id="431分片存储测试">4.3.1.分片存储测试</h3>
<p>插入三条数据：</p>
<figure data-type="image" tabindex="37"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723225006058.png" alt="image-20210723225006058" loading="lazy"></figure>
<figure data-type="image" tabindex="38"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723225034637.png" alt="image-20210723225034637" loading="lazy"></figure>
<figure data-type="image" tabindex="39"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723225112029.png" alt="image-20210723225112029" loading="lazy"></figure>
<p>测试可以看到，三条数据分别在不同分片：</p>
<figure data-type="image" tabindex="40"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723225227928.png" alt="image-20210723225227928" loading="lazy"></figure>
<p>结果：</p>
<figure data-type="image" tabindex="41"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723225342120.png" alt="image-20210723225342120" loading="lazy"></figure>
<h3 id="432分片存储原理">4.3.2.分片存储原理</h3>
<p>elasticsearch会通过hash算法来计算文档应该存储到哪个分片：</p>
<figure data-type="image" tabindex="42"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723224354904.png" alt="image-20210723224354904" loading="lazy"></figure>
<p>说明：</p>
<ul>
<li>_routing默认是文档的id</li>
<li>算法与分片数量有关，因此索引库一旦创建，分片数量不能修改！</li>
</ul>
<p>新增文档的流程如下：</p>
<figure data-type="image" tabindex="43"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723225436084.png" alt="image-20210723225436084" loading="lazy"></figure>
<p>解读：</p>
<ul>
<li>1）新增一个id=1的文档</li>
<li>2）对id做hash运算，假如得到的是2，则应该存储到shard-2</li>
<li>3）shard-2的主分片在node3节点，将数据路由到node3</li>
<li>4）保存文档</li>
<li>5）同步给shard-2的副本replica-2，在node2节点</li>
<li>6）返回结果给coordinating-node节点</li>
</ul>
<h2 id="44集群分布式查询">4.4.集群分布式查询</h2>
<p>elasticsearch的查询分成两个阶段：</p>
<ul>
<li>
<p>scatter phase：分散阶段，coordinating node会把请求分发到每一个分片</p>
</li>
<li>
<p>gather phase：聚集阶段，coordinating node汇总data node的搜索结果，并处理为最终结果集返回给用户</p>
</li>
</ul>
<figure data-type="image" tabindex="44"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723225809848.png" alt="image-20210723225809848" loading="lazy"></figure>
<h2 id="45集群故障转移">4.5.集群故障转移</h2>
<p>集群的master节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个叫做故障转移。</p>
<p>1）例如一个集群结构如图：</p>
<figure data-type="image" tabindex="45"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723225945963.png" alt="image-20210723225945963" loading="lazy"></figure>
<p>现在，node1是主节点，其它两个节点是从节点。</p>
<p>2）突然，node1发生了故障：</p>
<figure data-type="image" tabindex="46"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723230020574.png" alt="image-20210723230020574" loading="lazy"></figure>
<p>宕机后的第一件事，需要重新选主，例如选中了node2：</p>
<figure data-type="image" tabindex="47"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723230055974.png" alt="image-20210723230055974" loading="lazy"></figure>
<p>node2成为主节点后，会检测集群监控状态，发现：shard-1、shard-0没有副本节点。因此需要将node1上的数据迁移到node2、node3：</p>
<figure data-type="image" tabindex="48"><img src="https://shenshen6666.GitHub.io/post-images/image-20210723230216642.png" alt="image-20210723230216642" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[分布式搜索引擎02]]></title>
        <id>https://shenshen6666.GitHub.io/post/fen-bu-shi-sou-suo-yin-qing-02/</id>
        <link href="https://shenshen6666.GitHub.io/post/fen-bu-shi-sou-suo-yin-qing-02/">
        </link>
        <updated>2023-12-18T07:33:44.000Z</updated>
        <content type="html"><![CDATA[<h1 id="分布式搜索引擎02">分布式搜索引擎02</h1>
<p>在昨天的学习中，我们已经导入了大量数据到elasticsearch中，实现了elasticsearch的数据存储功能。但elasticsearch最擅长的还是搜索和数据分析。</p>
<p>所以今天，我们研究下elasticsearch的数据搜索功能。我们会分别使用<strong>DSL</strong>和<strong>RestClient</strong>实现搜索。</p>
<h1 id="0学习目标">0.学习目标</h1>
<h1 id="1dsl查询文档">1.DSL查询文档</h1>
<p>elasticsearch的查询依然是基于JSON风格的DSL来实现的。</p>
<h2 id="11dsl查询分类">1.1.DSL查询分类</h2>
<p>Elasticsearch提供了基于JSON的DSL（<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html">Domain Specific Language</a>）来定义查询。常见的查询类型包括：</p>
<ul>
<li>
<p><strong>查询所有</strong>：查询出所有数据，一般测试用。例如：match_all</p>
</li>
<li>
<p><strong>全文检索（full text）查询</strong>：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：</p>
<ul>
<li>match_query</li>
<li>multi_match_query</li>
</ul>
</li>
<li>
<p><strong>精确查询</strong>：根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如：</p>
<ul>
<li>ids</li>
<li>range</li>
<li>term</li>
</ul>
</li>
<li>
<p><strong>地理（geo）查询</strong>：根据经纬度查询。例如：</p>
<ul>
<li>geo_distance</li>
<li>geo_bounding_box</li>
</ul>
</li>
<li>
<p><strong>复合（compound）查询</strong>：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：</p>
<ul>
<li>bool</li>
<li>function_score</li>
</ul>
</li>
</ul>
<p>查询的语法基本一致：</p>
<pre><code class="language-json">GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;查询类型&quot;: {
      &quot;查询条件&quot;: &quot;条件值&quot;
    }
  }
}
</code></pre>
<p>我们以查询所有为例，其中：</p>
<ul>
<li>查询类型为match_all</li>
<li>没有查询条件</li>
</ul>
<pre><code class="language-json">// 查询所有
GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {
    }
  }
}
</code></pre>
<p>其它查询无非就是<strong>查询类型</strong>、<strong>查询条件</strong>的变化。</p>
<h2 id="12全文检索查询">1.2.全文检索查询</h2>
<h3 id="121使用场景">1.2.1.使用场景</h3>
<p>全文检索查询的基本流程如下：</p>
<ul>
<li>对用户搜索的内容做分词，得到词条</li>
<li>根据词条去倒排索引库中匹配，得到文档id</li>
<li>根据文档id找到文档，返回给用户</li>
</ul>
<p>比较常用的场景包括：</p>
<ul>
<li>商城的输入框搜索</li>
<li>百度输入框搜索</li>
</ul>
<p>例如京东：</p>
<figure data-type="image" tabindex="1"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721165326938.png" alt="image-20210721165326938" loading="lazy"></figure>
<p>因为是拿着词条去匹配，因此参与搜索的字段也必须是可分词的text类型的字段。</p>
<h3 id="122基本语法">1.2.2.基本语法</h3>
<p>常见的全文检索查询包括：</p>
<ul>
<li>match查询：单字段查询</li>
<li>multi_match查询：多字段查询，任意一个字段符合条件就算符合查询条件</li>
</ul>
<p>match查询语法如下：</p>
<pre><code class="language-json">GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;FIELD&quot;: &quot;TEXT&quot;
    }
  }
}
</code></pre>
<p>mulit_match语法如下：</p>
<pre><code class="language-json">GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;multi_match&quot;: {
      &quot;query&quot;: &quot;TEXT&quot;,
      &quot;fields&quot;: [&quot;FIELD1&quot;, &quot; FIELD12&quot;]
    }
  }
}
</code></pre>
<h3 id="123示例">1.2.3.示例</h3>
<p>match查询示例：</p>
<figure data-type="image" tabindex="2"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721170455419.png" alt="image-20210721170455419" loading="lazy"></figure>
<p>multi_match查询示例：</p>
<figure data-type="image" tabindex="3"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721170720691.png" alt="image-20210721170720691" loading="lazy"></figure>
<p>可以看到，两种查询结果是一样的，为什么？</p>
<p>因为我们将brand、name、business值都利用copy_to复制到了all字段中。因此你根据三个字段搜索，和根据all字段搜索效果当然一样了。</p>
<p>但是，搜索字段越多，对查询性能影响越大，因此建议采用copy_to，然后单字段查询的方式。</p>
<h3 id="124总结">1.2.4.总结</h3>
<p>match和multi_match的区别是什么？</p>
<ul>
<li>match：根据一个字段查询</li>
<li>multi_match：根据多个字段查询，参与查询字段越多，查询性能越差</li>
</ul>
<h2 id="13精准查询">1.3.精准查询</h2>
<p>精确查询一般是查找keyword、数值、日期、boolean等类型字段。所以<strong>不会</strong>对搜索条件分词。常见的有：</p>
<ul>
<li>term：根据词条精确值查询</li>
<li>range：根据值的范围查询</li>
</ul>
<h3 id="131term查询">1.3.1.term查询</h3>
<p>因为精确查询的字段搜是不分词的字段，因此查询的条件也必须是<strong>不分词</strong>的词条。查询时，用户输入的内容跟自动值完全匹配时才认为符合条件。如果用户输入的内容过多，反而搜索不到数据。</p>
<p>语法说明：</p>
<pre><code class="language-json">// term查询
GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;term&quot;: {
      &quot;FIELD&quot;: {
        &quot;value&quot;: &quot;VALUE&quot;
      }
    }
  }
}
</code></pre>
<p>示例：</p>
<p>当我搜索的是精确词条时，能正确查询出结果：</p>
<figure data-type="image" tabindex="4"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721171655308.png" alt="image-20210721171655308" loading="lazy"></figure>
<p>但是，当我搜索的内容不是词条，而是多个词语形成的短语时，反而搜索不到：</p>
<figure data-type="image" tabindex="5"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721171838378.png" alt="image-20210721171838378" loading="lazy"></figure>
<h3 id="132range查询">1.3.2.range查询</h3>
<p>范围查询，一般应用在对数值类型做范围过滤的时候。比如做价格范围过滤。</p>
<p>基本语法：</p>
<pre><code class="language-json">// range查询
GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;range&quot;: {
      &quot;FIELD&quot;: {
        &quot;gte&quot;: 10, // 这里的gte代表大于等于，gt则代表大于
        &quot;lte&quot;: 20 // lte代表小于等于，lt则代表小于
      }
    }
  }
}
</code></pre>
<p>示例：</p>
<figure data-type="image" tabindex="6"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721172307172.png" alt="image-20210721172307172" loading="lazy"></figure>
<h3 id="133总结">1.3.3.总结</h3>
<p>精确查询常见的有哪些？</p>
<ul>
<li>term查询：根据词条精确匹配，一般搜索keyword类型、数值类型、布尔类型、日期类型字段</li>
<li>range查询：根据数值范围查询，可以是数值、日期的范围</li>
</ul>
<h2 id="14地理坐标查询">1.4.地理坐标查询</h2>
<p>所谓的地理坐标查询，其实就是根据经纬度查询，官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-queries.html</p>
<p>常见的使用场景包括：</p>
<ul>
<li>携程：搜索我附近的酒店</li>
<li>滴滴：搜索我附近的出租车</li>
<li>微信：搜索我附近的人</li>
</ul>
<p>附近的酒店：</p>
<figure data-type="image" tabindex="7"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721172645103.png" alt="image-20210721172645103" loading="lazy"></figure>
<p>附近的车：</p>
<figure data-type="image" tabindex="8"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721172654880.png" alt="image-20210721172654880" loading="lazy"></figure>
<h3 id="141矩形范围查询">1.4.1.矩形范围查询</h3>
<p>矩形范围查询，也就是geo_bounding_box查询，查询坐标落在某个矩形范围的所有文档：</p>
<figure data-type="image" tabindex="9"><img src="assets/DKV9HZbVS6.gif" alt="DKV9HZbVS6" loading="lazy"></figure>
<p>查询时，需要指定矩形的<strong>左上</strong>、<strong>右下</strong>两个点的坐标，然后画出一个矩形，落在该矩形内的都是符合条件的点。</p>
<p>语法如下：</p>
<pre><code class="language-json">// geo_bounding_box查询
GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;geo_bounding_box&quot;: {
      &quot;FIELD&quot;: {
        &quot;top_left&quot;: { // 左上点
          &quot;lat&quot;: 31.1,
          &quot;lon&quot;: 121.5
        },
        &quot;bottom_right&quot;: { // 右下点
          &quot;lat&quot;: 30.9,
          &quot;lon&quot;: 121.7
        }
      }
    }
  }
}
</code></pre>
<p>这种并不符合“附近的人”这样的需求，所以我们就不做了。</p>
<h3 id="142附近查询">1.4.2.附近查询</h3>
<p>附近查询，也叫做距离查询（geo_distance）：查询到指定中心点小于某个距离值的所有文档。</p>
<p>换句话来说，在地图上找一个点作为圆心，以指定距离为半径，画一个圆，落在圆内的坐标都算符合条件：</p>
<figure data-type="image" tabindex="10"><img src="assets/vZrdKAh19C.gif" alt="vZrdKAh19C" loading="lazy"></figure>
<p>语法说明：</p>
<pre><code class="language-json">// geo_distance 查询
GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;geo_distance&quot;: {
      &quot;distance&quot;: &quot;15km&quot;, // 半径
      &quot;FIELD&quot;: &quot;31.21,121.5&quot; // 圆心
    }
  }
}
</code></pre>
<p>示例：</p>
<p>我们先搜索陆家嘴附近15km的酒店：</p>
<figure data-type="image" tabindex="11"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721175443234.png" alt="image-20210721175443234" loading="lazy"></figure>
<p>发现共有47家酒店。</p>
<p>然后把半径缩短到3公里：</p>
<figure data-type="image" tabindex="12"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721182031475.png" alt="image-20210721182031475" loading="lazy"></figure>
<p>可以发现，搜索到的酒店数量减少到了5家。</p>
<h2 id="15复合查询">1.5.复合查询</h2>
<p>复合（compound）查询：复合查询可以将其它简单查询组合起来，实现更复杂的搜索逻辑。常见的有两种：</p>
<ul>
<li>fuction score：算分函数查询，可以控制文档相关性算分，控制文档排名</li>
<li>bool query：布尔查询，利用逻辑关系组合多个其它的查询，实现复杂搜索</li>
</ul>
<h3 id="151相关性算分">1.5.1.相关性算分</h3>
<p>当我们利用match查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。</p>
<p>例如，我们搜索 &quot;虹桥如家&quot;，结果如下：</p>
<pre><code class="language-json">[
  {
    &quot;_score&quot; : 17.850193,
    &quot;_source&quot; : {
      &quot;name&quot; : &quot;虹桥如家酒店真不错&quot;,
    }
  },
  {
    &quot;_score&quot; : 12.259849,
    &quot;_source&quot; : {
      &quot;name&quot; : &quot;外滩如家酒店真不错&quot;,
    }
  },
  {
    &quot;_score&quot; : 11.91091,
    &quot;_source&quot; : {
      &quot;name&quot; : &quot;迪士尼如家酒店真不错&quot;,
    }
  }
]

</code></pre>
<p>在elasticsearch中，早期使用的打分算法是TF-IDF算法，公式如下：</p>
<figure data-type="image" tabindex="13"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721190152134.png" alt="image-20210721190152134" loading="lazy"></figure>
<p>在后来的5.1版本升级中，elasticsearch将算法改进为BM25算法，公式如下：</p>
<figure data-type="image" tabindex="14"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721190416214.png" alt="image-20210721190416214" loading="lazy"></figure>
<p>TF-IDF算法有一各缺陷，就是词条频率越高，文档得分也会越高，单个词条对文档影响较大。而BM25则会让单个词条的算分有一个上限，曲线更加平滑：</p>
<figure data-type="image" tabindex="15"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721190907320.png" alt="image-20210721190907320" loading="lazy"></figure>
<p>小结：elasticsearch会根据词条和文档的相关度做打分，算法由两种：</p>
<ul>
<li>TF-IDF算法</li>
<li>BM25算法，elasticsearch5.1版本后采用的算法</li>
</ul>
<h3 id="152算分函数查询">1.5.2.算分函数查询</h3>
<p>根据相关度打分是比较合理的需求，但<strong>合理的不一定是产品经理需要</strong>的。</p>
<p>以百度为例，你搜索的结果中，并不是相关度越高排名越靠前，而是谁掏的钱多排名就越靠前。如图：</p>
<figure data-type="image" tabindex="16"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721191144560.png" alt="image-20210721191144560" loading="lazy"></figure>
<p>要想认为控制相关性算分，就需要利用elasticsearch中的function score 查询了。</p>
<h4 id="1语法说明">1）语法说明</h4>
<figure data-type="image" tabindex="17"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721191544750.png" alt="image-20210721191544750" loading="lazy"></figure>
<p>function score 查询中包含四部分内容：</p>
<ul>
<li><strong>原始查询</strong>条件：query部分，基于这个条件搜索文档，并且基于BM25算法给文档打分，<strong>原始算分</strong>（query score)</li>
<li><strong>过滤条件</strong>：filter部分，符合该条件的文档才会重新算分</li>
<li><strong>算分函数</strong>：符合filter条件的文档要根据这个函数做运算，得到的<strong>函数算分</strong>（function score），有四种函数
<ul>
<li>weight：函数结果是常量</li>
<li>field_value_factor：以文档中的某个字段值作为函数结果</li>
<li>random_score：以随机数作为函数结果</li>
<li>script_score：自定义算分函数算法</li>
</ul>
</li>
<li><strong>运算模式</strong>：算分函数的结果、原始查询的相关性算分，两者之间的运算方式，包括：
<ul>
<li>multiply：相乘</li>
<li>replace：用function score替换query score</li>
<li>其它，例如：sum、avg、max、min</li>
</ul>
</li>
</ul>
<p>function score的运行流程如下：</p>
<ul>
<li>1）根据<strong>原始条件</strong>查询搜索文档，并且计算相关性算分，称为<strong>原始算分</strong>（query score）</li>
<li>2）根据<strong>过滤条件</strong>，过滤文档</li>
<li>3）符合<strong>过滤条件</strong>的文档，基于<strong>算分函数</strong>运算，得到<strong>函数算分</strong>（function score）</li>
<li>4）将<strong>原始算分</strong>（query score）和<strong>函数算分</strong>（function score）基于<strong>运算模式</strong>做运算，得到最终结果，作为相关性算分。</li>
</ul>
<p>因此，其中的关键点是：</p>
<ul>
<li>过滤条件：决定哪些文档的算分被修改</li>
<li>算分函数：决定函数算分的算法</li>
<li>运算模式：决定最终算分结果</li>
</ul>
<h4 id="2示例">2）示例</h4>
<p>需求：给“如家”这个品牌的酒店排名靠前一些</p>
<p>翻译一下这个需求，转换为之前说的四个要点：</p>
<ul>
<li>原始条件：不确定，可以任意变化</li>
<li>过滤条件：brand = &quot;如家&quot;</li>
<li>算分函数：可以简单粗暴，直接给固定的算分结果，weight</li>
<li>运算模式：比如求和</li>
</ul>
<p>因此最终的DSL语句如下：</p>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;query&quot;: {
    &quot;function_score&quot;: {
      &quot;query&quot;: {  .... }, // 原始查询，可以是任意条件
      &quot;functions&quot;: [ // 算分函数
        {
          &quot;filter&quot;: { // 满足的条件，品牌必须是如家
            &quot;term&quot;: {
              &quot;brand&quot;: &quot;如家&quot;
            }
          },
          &quot;weight&quot;: 2 // 算分权重为2
        }
      ],
      &quot;boost_mode&quot;: &quot;sum&quot; // 加权模式，求和
    }
  }
}

</code></pre>
<p>测试，在未添加算分函数时，如家得分如下：</p>
<figure data-type="image" tabindex="18"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721193152520.png" alt="image-20210721193152520" loading="lazy"></figure>
<p>添加了算分函数后，如家得分就提升了：</p>
<figure data-type="image" tabindex="19"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721193458182.png" alt="image-20210721193458182" loading="lazy"></figure>
<h4 id="3小结">3）小结</h4>
<p>function score query定义的三要素是什么？</p>
<ul>
<li>过滤条件：哪些文档要加分</li>
<li>算分函数：如何计算function score</li>
<li>加权方式：function score 与 query score如何运算</li>
</ul>
<h3 id="153布尔查询">1.5.3.布尔查询</h3>
<p>布尔查询是一个或多个查询子句的组合，每一个子句就是一个<strong>子查询</strong>。子查询的组合方式有：</p>
<ul>
<li>must：必须匹配每个子查询，类似“与”</li>
<li>should：选择性匹配子查询，类似“或”</li>
<li>must_not：必须不匹配，<strong>不参与算分</strong>，类似“非”</li>
<li>filter：必须匹配，<strong>不参与算分</strong></li>
</ul>
<p>比如在搜索酒店时，除了关键字搜索外，我们还可能根据品牌、价格、城市等字段做过滤：</p>
<figure data-type="image" tabindex="20"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721193822848.png" alt="image-20210721193822848" loading="lazy"></figure>
<p>每一个不同的字段，其查询的条件、方式都不一样，必须是多个不同的查询，而要组合这些查询，就必须用bool查询了。</p>
<p>需要注意的是，搜索时，参与<strong>打分的字段越多，查询的性能也越差</strong>。因此这种多条件查询时，建议这样做：</p>
<ul>
<li>搜索框的关键字搜索，是全文检索查询，使用must查询，参与算分</li>
<li>其它过滤条件，采用filter查询。不参与算分</li>
</ul>
<h4 id="1语法示例">1）语法示例：</h4>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;must&quot;: [
        {&quot;term&quot;: {&quot;city&quot;: &quot;上海&quot; }}
      ],
      &quot;should&quot;: [
        {&quot;term&quot;: {&quot;brand&quot;: &quot;皇冠假日&quot; }},
        {&quot;term&quot;: {&quot;brand&quot;: &quot;华美达&quot; }}
      ],
      &quot;must_not&quot;: [
        { &quot;range&quot;: { &quot;price&quot;: { &quot;lte&quot;: 500 } }}
      ],
      &quot;filter&quot;: [
        { &quot;range&quot;: {&quot;score&quot;: { &quot;gte&quot;: 45 } }}
      ]
    }
  }
}

</code></pre>
<h4 id="2示例-2">2）示例</h4>
<p>需求：搜索名字包含“如家”，价格不高于400，在坐标31.21,121.5周围10km范围内的酒店。</p>
<p>分析：</p>
<ul>
<li>名称搜索，属于全文检索查询，应该参与算分。放到must中</li>
<li>价格不高于400，用range查询，属于过滤条件，不参与算分。放到must_not中</li>
<li>周围10km范围内，用geo_distance查询，属于过滤条件，不参与算分。放到filter中</li>
</ul>
<figure data-type="image" tabindex="21"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721194744183.png" alt="image-20210721194744183" loading="lazy"></figure>
<h4 id="3小结-2">3）小结</h4>
<p>bool查询有几种逻辑关系？</p>
<ul>
<li>must：必须匹配的条件，可以理解为“与”</li>
<li>should：选择性匹配的条件，可以理解为“或”</li>
<li>must_not：必须不匹配的条件，不参与打分</li>
<li>filter：必须匹配的条件，不参与打分</li>
</ul>
<h1 id="2搜索结果处理">2.搜索结果处理</h1>
<p>搜索的结果可以按照用户指定的方式去处理或展示。</p>
<h2 id="21排序">2.1.排序</h2>
<p>elasticsearch默认是根据相关度算分（_score）来排序，但是也支持自定义方式对搜索<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/sort-search-results.html">结果排序</a>。可以排序字段类型有：keyword类型、数值类型、地理坐标类型、日期类型等。</p>
<h3 id="211普通字段排序">2.1.1.普通字段排序</h3>
<p>keyword、数值、日期类型排序的语法基本一致。</p>
<p><strong>语法</strong>：</p>
<pre><code class="language-json">GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  },
  &quot;sort&quot;: [
    {
      &quot;FIELD&quot;: &quot;desc&quot;  // 排序字段、排序方式ASC、DESC
    }
  ]
}

</code></pre>
<p>排序条件是一个数组，也就是可以写多个排序条件。按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推</p>
<p><strong>示例</strong>：</p>
<p>需求描述：酒店数据按照用户评价（score)降序排序，评价相同的按照价格(price)升序排序</p>
<figure data-type="image" tabindex="22"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721195728306.png" alt="image-20210721195728306" loading="lazy"></figure>
<h3 id="212地理坐标排序">2.1.2.地理坐标排序</h3>
<p>地理坐标排序略有不同。</p>
<p><strong>语法说明</strong>：</p>
<pre><code class="language-json">GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  },
  &quot;sort&quot;: [
    {
      &quot;_geo_distance&quot; : {
          &quot;FIELD&quot; : &quot;纬度，经度&quot;, // 文档中geo_point类型的字段名、目标坐标点
          &quot;order&quot; : &quot;asc&quot;, // 排序方式
          &quot;unit&quot; : &quot;km&quot; // 排序的距离单位
      }
    }
  ]
}

</code></pre>
<p>这个查询的含义是：</p>
<ul>
<li>指定一个坐标，作为目标点</li>
<li>计算每一个文档中，指定字段（必须是geo_point类型）的坐标 到目标点的距离是多少</li>
<li>根据距离排序</li>
</ul>
<p><strong>示例：</strong></p>
<p>需求描述：实现对酒店数据按照到你的位置坐标的距离升序排序</p>
<p>提示：获取你的位置的经纬度的方式：https://lbs.amap.com/demo/jsapi-v2/example/map/click-to-get-lnglat/</p>
<p>假设我的位置是：31.034661，121.612282，寻找我周围距离最近的酒店。</p>
<figure data-type="image" tabindex="23"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721200214690.png" alt="image-20210721200214690" loading="lazy"></figure>
<h2 id="22分页">2.2.分页</h2>
<p>elasticsearch 默认情况下只返回top10的数据。而如果要查询更多数据就需要修改分页参数了。elasticsearch中通过修改from、size参数来控制要返回的分页结果：</p>
<ul>
<li>from：从第几个文档开始</li>
<li>size：总共查询几个文档</li>
</ul>
<p>类似于mysql中的<code>limit ?, ?</code></p>
<h3 id="221基本的分页">2.2.1.基本的分页</h3>
<p>分页的基本语法如下：</p>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  },
  &quot;from&quot;: 0, // 分页开始的位置，默认为0
  &quot;size&quot;: 10, // 期望获取的文档总数
  &quot;sort&quot;: [
    {&quot;price&quot;: &quot;asc&quot;}
  ]
}

</code></pre>
<h3 id="222深度分页问题">2.2.2.深度分页问题</h3>
<p>现在，我要查询990~1000的数据，查询逻辑要这么写：</p>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  },
  &quot;from&quot;: 990, // 分页开始的位置，默认为0
  &quot;size&quot;: 10, // 期望获取的文档总数
  &quot;sort&quot;: [
    {&quot;price&quot;: &quot;asc&quot;}
  ]
}

</code></pre>
<p>这里是查询990开始的数据，也就是 第990~第1000条 数据。</p>
<p>不过，elasticsearch内部分页时，必须先查询 0~1000条，然后截取其中的990 ~ 1000的这10条：</p>
<figure data-type="image" tabindex="24"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721200643029.png" alt="image-20210721200643029" loading="lazy"></figure>
<p>查询TOP1000，如果es是单点模式，这并无太大影响。</p>
<p>但是elasticsearch将来一定是集群，例如我集群有5个节点，我要查询TOP1000的数据，并不是每个节点查询200条就可以了。</p>
<p>因为节点A的TOP200，在另一个节点可能排到10000名以外了。</p>
<p>因此要想获取整个集群的TOP1000，必须先查询出每个节点的TOP1000，汇总结果后，重新排名，重新截取TOP1000。</p>
<figure data-type="image" tabindex="25"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721201003229.png" alt="image-20210721201003229" loading="lazy"></figure>
<p>那如果我要查询9900~10000的数据呢？是不是要先查询TOP10000呢？那每个节点都要查询10000条？汇总到内存中？</p>
<p>当查询分页深度较大时，汇总数据过多，对内存和CPU会产生非常大的压力，因此elasticsearch会禁止from+ size 超过10000的请求。</p>
<p>针对深度分页，ES提供了两种解决方案，<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html">官方文档</a>：</p>
<ul>
<li>search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。</li>
<li>scroll：原理将排序后的文档id形成快照，保存在内存。官方已经不推荐使用。</li>
</ul>
<h3 id="223小结">2.2.3.小结</h3>
<p>分页查询的常见实现方案以及优缺点：</p>
<ul>
<li>
<p><code>from + size</code>：</p>
<ul>
<li>优点：支持随机翻页</li>
<li>缺点：深度分页问题，默认查询上限（from + size）是10000</li>
<li>场景：百度、京东、谷歌、淘宝这样的随机翻页搜索</li>
</ul>
</li>
<li>
<p><code>after search</code>：</p>
<ul>
<li>优点：没有查询上限（单次查询的size不超过10000）</li>
<li>缺点：只能向后逐页查询，不支持随机翻页</li>
<li>场景：没有随机翻页需求的搜索，例如手机向下滚动翻页</li>
</ul>
</li>
<li>
<p><code>scroll</code>：</p>
<ul>
<li>优点：没有查询上限（单次查询的size不超过10000）</li>
<li>缺点：会有额外内存消耗，并且搜索结果是非实时的</li>
<li>场景：海量数据的获取和迁移。从ES7.1开始不推荐，建议用 after search方案。</li>
</ul>
</li>
</ul>
<h2 id="23高亮">2.3.高亮</h2>
<h3 id="231高亮原理">2.3.1.高亮原理</h3>
<p>什么是高亮显示呢？</p>
<p>我们在百度，京东搜索时，关键字会变成红色，比较醒目，这叫高亮显示：</p>
<figure data-type="image" tabindex="26"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721202705030.png" alt="image-20210721202705030" loading="lazy"></figure>
<p>高亮显示的实现分为两步：</p>
<ul>
<li>1）给文档中的所有关键字都添加一个标签，例如<code>&lt;em&gt;</code>标签</li>
<li>2）页面给<code>&lt;em&gt;</code>标签编写CSS样式</li>
</ul>
<h3 id="232实现高亮">2.3.2.实现高亮</h3>
<p><strong>高亮的语法</strong>：</p>
<pre><code class="language-json">GET /hotel/_search
{
  &quot;query&quot;: {
    &quot;match&quot;: {
      &quot;FIELD&quot;: &quot;TEXT&quot; // 查询条件，高亮一定要使用全文检索查询
    }
  },
  &quot;highlight&quot;: {
    &quot;fields&quot;: { // 指定要高亮的字段
      &quot;FIELD&quot;: {
        &quot;pre_tags&quot;: &quot;&lt;em&gt;&quot;,  // 用来标记高亮字段的前置标签
        &quot;post_tags&quot;: &quot;&lt;/em&gt;&quot; // 用来标记高亮字段的后置标签
      }
    }
  }
}

</code></pre>
<p><strong>注意：</strong></p>
<ul>
<li>高亮是对关键字高亮，因此<strong>搜索条件必须带有关键字</strong>，而不能是范围这样的查询。</li>
<li>默认情况下，<strong>高亮的字段，必须与搜索指定的字段一致</strong>，否则无法高亮</li>
<li>如果要对非搜索字段高亮，则需要添加一个属性：required_field_match=false</li>
</ul>
<p><strong>示例</strong>：</p>
<figure data-type="image" tabindex="27"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721203349633.png" alt="image-20210721203349633" loading="lazy"></figure>
<h2 id="24总结">2.4.总结</h2>
<p>查询的DSL是一个大的JSON对象，包含下列属性：</p>
<ul>
<li>query：查询条件</li>
<li>from和size：分页条件</li>
<li>sort：排序条件</li>
<li>highlight：高亮条件</li>
</ul>
<p>示例：</p>
<figure data-type="image" tabindex="28"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721203657850.png" alt="image-20210721203657850" loading="lazy"></figure>
<h1 id="3restclient查询文档">3.RestClient查询文档</h1>
<p>文档的查询同样适用昨天学习的 RestHighLevelClient对象，基本步骤包括：</p>
<ul>
<li>1）准备Request对象</li>
<li>2）准备请求参数</li>
<li>3）发起请求</li>
<li>4）解析响应</li>
</ul>
<h2 id="31快速入门">3.1.快速入门</h2>
<p>我们以match_all查询为例</p>
<h3 id="311发起查询请求">3.1.1.发起查询请求</h3>
<figure data-type="image" tabindex="29"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721203950559.png" alt="image-20210721203950559" loading="lazy"></figure>
<p>代码解读：</p>
<ul>
<li>
<p>第一步，创建<code>SearchRequest</code>对象，指定索引库名</p>
</li>
<li>
<p>第二步，利用<code>request.source()</code>构建DSL，DSL中可以包含查询、分页、排序、高亮等</p>
<ul>
<li><code>query()</code>：代表查询条件，利用<code>QueryBuilders.matchAllQuery()</code>构建一个match_all查询的DSL</li>
</ul>
</li>
<li>
<p>第三步，利用client.search()发送请求，得到响应</p>
</li>
</ul>
<p>这里关键的API有两个，一个是<code>request.source()</code>，其中包含了查询、排序、分页、高亮等所有功能：</p>
<figure data-type="image" tabindex="30"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721215640790.png" alt="image-20210721215640790" loading="lazy"></figure>
<p>另一个是<code>QueryBuilders</code>，其中包含match、term、function_score、bool等各种查询：</p>
<figure data-type="image" tabindex="31"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721215729236.png" alt="image-20210721215729236" loading="lazy"></figure>
<h3 id="312解析响应">3.1.2.解析响应</h3>
<p>响应结果的解析：</p>
<figure data-type="image" tabindex="32"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721214221057.png" alt="image-20210721214221057" loading="lazy"></figure>
<p>elasticsearch返回的结果是一个JSON字符串，结构包含：</p>
<ul>
<li><code>hits</code>：命中的结果
<ul>
<li><code>total</code>：总条数，其中的value是具体的总条数值</li>
<li><code>max_score</code>：所有结果中得分最高的文档的相关性算分</li>
<li><code>hits</code>：搜索结果的文档数组，其中的每个文档都是一个json对象
<ul>
<li><code>_source</code>：文档中的原始数据，也是json对象</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>因此，我们解析响应结果，就是逐层解析JSON字符串，流程如下：</p>
<ul>
<li><code>SearchHits</code>：通过response.getHits()获取，就是JSON中的最外层的hits，代表命中的结果
<ul>
<li><code>SearchHits#getTotalHits().value</code>：获取总条数信息</li>
<li><code>SearchHits#getHits()</code>：获取SearchHit数组，也就是文档数组
<ul>
<li><code>SearchHit#getSourceAsString()</code>：获取文档结果中的_source，也就是原始的json文档数据</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="313完整代码">3.1.3.完整代码</h3>
<p>完整代码如下：</p>
<pre><code class="language-java">@Test
void testMatchAll() throws IOException {
    // 1.准备Request
    SearchRequest request = new SearchRequest(&quot;hotel&quot;);
    // 2.准备DSL
    request.source()
        .query(QueryBuilders.matchAllQuery());
    // 3.发送请求
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);

    // 4.解析响应
    handleResponse(response);
}

private void handleResponse(SearchResponse response) {
    // 4.解析响应
    SearchHits searchHits = response.getHits();
    // 4.1.获取总条数
    long total = searchHits.getTotalHits().value;
    System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;);
    // 4.2.文档数组
    SearchHit[] hits = searchHits.getHits();
    // 4.3.遍历
    for (SearchHit hit : hits) {
        // 获取文档source
        String json = hit.getSourceAsString();
        // 反序列化
        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
        System.out.println(&quot;hotelDoc = &quot; + hotelDoc);
    }
}

</code></pre>
<h3 id="314小结">3.1.4.小结</h3>
<p>查询的基本步骤是：</p>
<ol>
<li>
<p>创建SearchRequest对象</p>
</li>
<li>
<p>准备Request.source()，也就是DSL。</p>
<p>① QueryBuilders来构建查询条件</p>
<p>② 传入Request.source() 的 query() 方法</p>
</li>
<li>
<p>发送请求，得到结果</p>
</li>
<li>
<p>解析结果（参考JSON结果，从外到内，逐层解析）</p>
</li>
</ol>
<h2 id="32match查询">3.2.match查询</h2>
<p>全文检索的match和multi_match查询与match_all的API基本一致。差别是查询条件，也就是query的部分。</p>
<figure data-type="image" tabindex="33"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721215923060.png" alt="image-20210721215923060" loading="lazy"></figure>
<p>因此，Java代码上的差异主要是request.source().query()中的参数了。同样是利用QueryBuilders提供的方法：</p>
<figure data-type="image" tabindex="34"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721215843099.png" alt="image-20210721215843099" loading="lazy"></figure>
<p>而结果解析代码则完全一致，可以抽取并共享。</p>
<p>完整代码如下：</p>
<pre><code class="language-java">@Test
void testMatch() throws IOException {
    // 1.准备Request
    SearchRequest request = new SearchRequest(&quot;hotel&quot;);
    // 2.准备DSL
    request.source()
        .query(QueryBuilders.matchQuery(&quot;all&quot;, &quot;如家&quot;));
    // 3.发送请求
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    // 4.解析响应
    handleResponse(response);

}

</code></pre>
<h2 id="33精确查询">3.3.精确查询</h2>
<p>精确查询主要是两者：</p>
<ul>
<li>term：词条精确匹配</li>
<li>range：范围查询</li>
</ul>
<p>与之前的查询相比，差异同样在查询条件，其它都一样。</p>
<p>查询条件构造的API如下：</p>
<figure data-type="image" tabindex="35"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721220305140.png" alt="image-20210721220305140" loading="lazy"></figure>
<h2 id="34布尔查询">3.4.布尔查询</h2>
<p>布尔查询是用must、must_not、filter等方式组合其它查询，代码示例如下：</p>
<figure data-type="image" tabindex="36"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721220927286.png" alt="image-20210721220927286" loading="lazy"></figure>
<p>可以看到，API与其它查询的差别同样是在查询条件的构建，QueryBuilders，结果解析等其他代码完全不变。</p>
<p>完整代码如下：</p>
<pre><code class="language-java">@Test
void testBool() throws IOException {
    // 1.准备Request
    SearchRequest request = new SearchRequest(&quot;hotel&quot;);
    // 2.准备DSL
    // 2.1.准备BooleanQuery
    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
    // 2.2.添加term
    boolQuery.must(QueryBuilders.termQuery(&quot;city&quot;, &quot;杭州&quot;));
    // 2.3.添加range
    boolQuery.filter(QueryBuilders.rangeQuery(&quot;price&quot;).lte(250));

    request.source().query(boolQuery);
    // 3.发送请求
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    // 4.解析响应
    handleResponse(response);

}

</code></pre>
<h2 id="35排序-分页">3.5.排序、分页</h2>
<p>搜索结果的排序和分页是与query同级的参数，因此同样是使用request.source()来设置。</p>
<p>对应的API如下：</p>
<figure data-type="image" tabindex="37"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721221121266.png" alt="image-20210721221121266" loading="lazy"></figure>
<p>完整代码示例：</p>
<pre><code class="language-java">@Test
void testPageAndSort() throws IOException {
    // 页码，每页大小
    int page = 1, size = 5;

    // 1.准备Request
    SearchRequest request = new SearchRequest(&quot;hotel&quot;);
    // 2.准备DSL
    // 2.1.query
    request.source().query(QueryBuilders.matchAllQuery());
    // 2.2.排序 sort
    request.source().sort(&quot;price&quot;, SortOrder.ASC);
    // 2.3.分页 from、size
    request.source().from((page - 1) * size).size(5);
    // 3.发送请求
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    // 4.解析响应
    handleResponse(response);

}

</code></pre>
<h2 id="36高亮">3.6.高亮</h2>
<p>高亮的代码与之前代码差异较大，有两点：</p>
<ul>
<li>查询的DSL：其中除了查询条件，还需要添加高亮条件，同样是与query同级。</li>
<li>结果解析：结果除了要解析_source文档数据，还要解析高亮结果</li>
</ul>
<h3 id="361高亮请求构建">3.6.1.高亮请求构建</h3>
<p>高亮请求的构建API如下：</p>
<figure data-type="image" tabindex="38"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721221744883.png" alt="image-20210721221744883" loading="lazy"></figure>
<p>上述代码省略了查询条件部分，但是大家不要忘了：高亮查询必须使用全文检索查询，并且要有搜索关键字，将来才可以对关键字高亮。</p>
<p>完整代码如下：</p>
<pre><code class="language-java">@Test
void testHighlight() throws IOException {
    // 1.准备Request
    SearchRequest request = new SearchRequest(&quot;hotel&quot;);
    // 2.准备DSL
    // 2.1.query
    request.source().query(QueryBuilders.matchQuery(&quot;all&quot;, &quot;如家&quot;));
    // 2.2.高亮
    request.source().highlighter(new HighlightBuilder().field(&quot;name&quot;).requireFieldMatch(false));
    // 3.发送请求
    SearchResponse response = client.search(request, RequestOptions.DEFAULT);
    // 4.解析响应
    handleResponse(response);

}

</code></pre>
<h3 id="362高亮结果解析">3.6.2.高亮结果解析</h3>
<p>高亮的结果与查询的文档结果默认是分离的，并不在一起。</p>
<p>因此解析高亮的代码需要额外处理：</p>
<figure data-type="image" tabindex="39"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721222057212.png" alt="image-20210721222057212" loading="lazy"></figure>
<p>代码解读：</p>
<ul>
<li>第一步：从结果中获取source。hit.getSourceAsString()，这部分是非高亮结果，json字符串。还需要反序列为HotelDoc对象</li>
<li>第二步：获取高亮结果。hit.getHighlightFields()，返回值是一个Map，key是高亮字段名称，值是HighlightField对象，代表高亮值</li>
<li>第三步：从map中根据高亮字段名称，获取高亮字段值对象HighlightField</li>
<li>第四步：从HighlightField中获取Fragments，并且转为字符串。这部分就是真正的高亮字符串了</li>
<li>第五步：用高亮的结果替换HotelDoc中的非高亮结果</li>
</ul>
<p>完整代码如下：</p>
<pre><code class="language-java">private void handleResponse(SearchResponse response) {
    // 4.解析响应
    SearchHits searchHits = response.getHits();
    // 4.1.获取总条数
    long total = searchHits.getTotalHits().value;
    System.out.println(&quot;共搜索到&quot; + total + &quot;条数据&quot;);
    // 4.2.文档数组
    SearchHit[] hits = searchHits.getHits();
    // 4.3.遍历
    for (SearchHit hit : hits) {
        // 获取文档source
        String json = hit.getSourceAsString();
        // 反序列化
        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
        // 获取高亮结果
        Map&lt;String, HighlightField&gt; highlightFields = hit.getHighlightFields();
        if (!CollectionUtils.isEmpty(highlightFields)) {
            // 根据字段名获取高亮结果
            HighlightField highlightField = highlightFields.get(&quot;name&quot;);
            if (highlightField != null) {
                // 获取高亮值
                String name = highlightField.getFragments()[0].string();
                // 覆盖非高亮结果
                hotelDoc.setName(name);
            }
        }
        System.out.println(&quot;hotelDoc = &quot; + hotelDoc);
    }
}

</code></pre>
<h1 id="4黑马旅游案例">4.黑马旅游案例</h1>
<p>下面，我们通过黑马旅游的案例来实战演练下之前学习的知识。</p>
<p>我们实现四部分功能：</p>
<ul>
<li>酒店搜索和分页</li>
<li>酒店结果过滤</li>
<li>我周边的酒店</li>
<li>酒店竞价排名</li>
</ul>
<p>启动我们提供的hotel-demo项目，其默认端口是8089，访问http://localhost:8090，就能看到项目页面了：</p>
<figure data-type="image" tabindex="40"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721223159598.png" alt="image-20210721223159598" loading="lazy"></figure>
<h2 id="41酒店搜索和分页">4.1.酒店搜索和分页</h2>
<p>案例需求：实现黑马旅游的酒店搜索功能，完成关键字搜索和分页</p>
<h3 id="411需求分析">4.1.1.需求分析</h3>
<p>在项目的首页，有一个大大的搜索框，还有分页按钮：</p>
<figure data-type="image" tabindex="41"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721223859419.png" alt="image-20210721223859419" loading="lazy"></figure>
<p>点击搜索按钮，可以看到浏览器控制台发出了请求：</p>
<figure data-type="image" tabindex="42"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721224033789.png" alt="image-20210721224033789" loading="lazy"></figure>
<p>请求参数如下：</p>
<figure data-type="image" tabindex="43"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721224112708.png" alt="image-20210721224112708" loading="lazy"></figure>
<p>由此可以知道，我们这个请求的信息如下：</p>
<ul>
<li>请求方式：POST</li>
<li>请求路径：/hotel/list</li>
<li>请求参数：JSON对象，包含4个字段：
<ul>
<li>key：搜索关键字</li>
<li>page：页码</li>
<li>size：每页大小</li>
<li>sortBy：排序，目前暂不实现</li>
</ul>
</li>
<li>返回值：分页查询，需要返回分页结果PageResult，包含两个属性：
<ul>
<li><code>total</code>：总条数</li>
<li><code>List&lt;HotelDoc&gt;</code>：当前页的数据</li>
</ul>
</li>
</ul>
<p>因此，我们实现业务的流程如下：</p>
<ul>
<li>步骤一：定义实体类，接收请求参数的JSON对象</li>
<li>步骤二：编写controller，接收页面的请求</li>
<li>步骤三：编写业务实现，利用RestHighLevelClient实现搜索、分页</li>
</ul>
<h3 id="412定义实体类">4.1.2.定义实体类</h3>
<p>实体类有两个，一个是前端的请求参数实体，一个是服务端应该返回的响应结果实体。</p>
<p>1）请求参数</p>
<p>前端请求的json结构如下：</p>
<pre><code class="language-json">{
    &quot;key&quot;: &quot;搜索关键字&quot;,
    &quot;page&quot;: 1,
    &quot;size&quot;: 3,
    &quot;sortBy&quot;: &quot;default&quot;
}

</code></pre>
<p>因此，我们在<code>cn.itcast.hotel.pojo</code>包下定义一个实体类：</p>
<pre><code class="language-java">package cn.itcast.hotel.pojo;

import lombok.Data;

@Data
public class RequestParams {
    private String key;
    private Integer page;
    private Integer size;
    private String sortBy;
}

</code></pre>
<p>2）返回值</p>
<p>分页查询，需要返回分页结果PageResult，包含两个属性：</p>
<ul>
<li><code>total</code>：总条数</li>
<li><code>List&lt;HotelDoc&gt;</code>：当前页的数据</li>
</ul>
<p>因此，我们在<code>cn.itcast.hotel.pojo</code>中定义返回结果：</p>
<pre><code class="language-java">package cn.itcast.hotel.pojo;

import lombok.Data;

import java.util.List;

@Data
public class PageResult {
    private Long total;
    private List&lt;HotelDoc&gt; hotels;

    public PageResult() {
    }

    public PageResult(Long total, List&lt;HotelDoc&gt; hotels) {
        this.total = total;
        this.hotels = hotels;
    }
}

</code></pre>
<h3 id="413定义controller">4.1.3.定义controller</h3>
<p>定义一个HotelController，声明查询接口，满足下列要求：</p>
<ul>
<li>请求方式：Post</li>
<li>请求路径：/hotel/list</li>
<li>请求参数：对象，类型为RequestParam</li>
<li>返回值：PageResult，包含两个属性
<ul>
<li><code>Long total</code>：总条数</li>
<li><code>List&lt;HotelDoc&gt; hotels</code>：酒店数据</li>
</ul>
</li>
</ul>
<p>因此，我们在<code>cn.itcast.hotel.web</code>中定义HotelController：</p>
<pre><code class="language-java">@RestController
@RequestMapping(&quot;/hotel&quot;)
public class HotelController {

    @Autowired
    private IHotelService hotelService;
	// 搜索酒店数据
    @PostMapping(&quot;/list&quot;)
    public PageResult search(@RequestBody RequestParams params){
        return hotelService.search(params);
    }
}

</code></pre>
<h3 id="414实现搜索业务">4.1.4.实现搜索业务</h3>
<p>我们在controller调用了IHotelService，并没有实现该方法，因此下面我们就在IHotelService中定义方法，并且去实现业务逻辑。</p>
<p>1）在<code>cn.itcast.hotel.service</code>中的<code>IHotelService</code>接口中定义一个方法：</p>
<pre><code class="language-java">/**
 * 根据关键字搜索酒店信息
 * @param params 请求参数对象，包含用户输入的关键字 
 * @return 酒店文档列表
 */
PageResult search(RequestParams params);

</code></pre>
<p>2）实现搜索业务，肯定离不开RestHighLevelClient，我们需要把它注册到Spring中作为一个Bean。在<code>cn.itcast.hotel</code>中的<code>HotelDemoApplication</code>中声明这个Bean：</p>
<pre><code class="language-java">@Bean
public RestHighLevelClient client(){
    return  new RestHighLevelClient(RestClient.builder(
        HttpHost.create(&quot;http://192.168.150.101:9200&quot;)
    ));
}

</code></pre>
<p>3）在<code>cn.itcast.hotel.service.impl</code>中的<code>HotelService</code>中实现search方法：</p>
<pre><code class="language-java">@Override
public PageResult search(RequestParams params) {
    try {
        // 1.准备Request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.准备DSL
        // 2.1.query
        String key = params.getKey();
        if (key == null || &quot;&quot;.equals(key)) {
            boolQuery.must(QueryBuilders.matchAllQuery());
        } else {
            boolQuery.must(QueryBuilders.matchQuery(&quot;all&quot;, key));
        }

        // 2.2.分页
        int page = params.getPage();
        int size = params.getSize();
        request.source().from((page - 1) * size).size(size);

        // 3.发送请求
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        // 4.解析响应
        return handleResponse(response);
    } catch (IOException e) {
        throw new RuntimeException(e);
    }
}

// 结果解析
private PageResult handleResponse(SearchResponse response) {
    // 4.解析响应
    SearchHits searchHits = response.getHits();
    // 4.1.获取总条数
    long total = searchHits.getTotalHits().value;
    // 4.2.文档数组
    SearchHit[] hits = searchHits.getHits();
    // 4.3.遍历
    List&lt;HotelDoc&gt; hotels = new ArrayList&lt;&gt;();
    for (SearchHit hit : hits) {
        // 获取文档source
        String json = hit.getSourceAsString();
        // 反序列化
        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
		// 放入集合
        hotels.add(hotelDoc);
    }
    // 4.4.封装返回
    return new PageResult(total, hotels);
}

</code></pre>
<h2 id="42酒店结果过滤">4.2.酒店结果过滤</h2>
<p>需求：添加品牌、城市、星级、价格等过滤功能</p>
<h3 id="421需求分析">4.2.1.需求分析</h3>
<p>在页面搜索框下面，会有一些过滤项：</p>
<figure data-type="image" tabindex="44"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722091940726.png" alt="image-20210722091940726" loading="lazy"></figure>
<p>传递的参数如图：</p>
<figure data-type="image" tabindex="45"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722092051994.png" alt="image-20210722092051994" loading="lazy"></figure>
<p>包含的过滤条件有：</p>
<ul>
<li>brand：品牌值</li>
<li>city：城市</li>
<li>minPrice~maxPrice：价格范围</li>
<li>starName：星级</li>
</ul>
<p>我们需要做两件事情：</p>
<ul>
<li>修改请求参数的对象RequestParams，接收上述参数</li>
<li>修改业务逻辑，在搜索条件之外，添加一些过滤条件</li>
</ul>
<h3 id="422修改实体类">4.2.2.修改实体类</h3>
<p>修改在<code>cn.itcast.hotel.pojo</code>包下的实体类RequestParams：</p>
<pre><code class="language-java">@Data
public class RequestParams {
    private String key;
    private Integer page;
    private Integer size;
    private String sortBy;
    // 下面是新增的过滤条件参数
    private String city;
    private String brand;
    private String starName;
    private Integer minPrice;
    private Integer maxPrice;
}

</code></pre>
<h3 id="423修改搜索业务">4.2.3.修改搜索业务</h3>
<p>在HotelService的search方法中，只有一个地方需要修改：requet.source().query( ... )其中的查询条件。</p>
<p>在之前的业务中，只有match查询，根据关键字搜索，现在要添加条件过滤，包括：</p>
<ul>
<li>品牌过滤：是keyword类型，用term查询</li>
<li>星级过滤：是keyword类型，用term查询</li>
<li>价格过滤：是数值类型，用range查询</li>
<li>城市过滤：是keyword类型，用term查询</li>
</ul>
<p>多个查询条件组合，肯定是boolean查询来组合：</p>
<ul>
<li>关键字搜索放到must中，参与算分</li>
<li>其它过滤条件放到filter中，不参与算分</li>
</ul>
<p>因为条件构建的逻辑比较复杂，这里先封装为一个函数：</p>
<figure data-type="image" tabindex="46"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722092935453.png" alt="image-20210722092935453" loading="lazy"></figure>
<p>buildBasicQuery的代码如下：</p>
<pre><code class="language-java">private void buildBasicQuery(RequestParams params, SearchRequest request) {
    // 1.构建BooleanQuery
    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
    // 2.关键字搜索
    String key = params.getKey();
    if (key == null || &quot;&quot;.equals(key)) {
        boolQuery.must(QueryBuilders.matchAllQuery());
    } else {
        boolQuery.must(QueryBuilders.matchQuery(&quot;all&quot;, key));
    }
    // 3.城市条件
    if (params.getCity() != null &amp;&amp; !params.getCity().equals(&quot;&quot;)) {
        boolQuery.filter(QueryBuilders.termQuery(&quot;city&quot;, params.getCity()));
    }
    // 4.品牌条件
    if (params.getBrand() != null &amp;&amp; !params.getBrand().equals(&quot;&quot;)) {
        boolQuery.filter(QueryBuilders.termQuery(&quot;brand&quot;, params.getBrand()));
    }
    // 5.星级条件
    if (params.getStarName() != null &amp;&amp; !params.getStarName().equals(&quot;&quot;)) {
        boolQuery.filter(QueryBuilders.termQuery(&quot;starName&quot;, params.getStarName()));
    }
	// 6.价格
    if (params.getMinPrice() != null &amp;&amp; params.getMaxPrice() != null) {
        boolQuery.filter(QueryBuilders
                         .rangeQuery(&quot;price&quot;)
                         .gte(params.getMinPrice())
                         .lte(params.getMaxPrice())
                        );
    }
	// 7.放入source
    request.source().query(boolQuery);
}

</code></pre>
<h2 id="43我周边的酒店">4.3.我周边的酒店</h2>
<p>需求：我附近的酒店</p>
<h3 id="431需求分析">4.3.1.需求分析</h3>
<p>在酒店列表页的右侧，有一个小地图，点击地图的定位按钮，地图会找到你所在的位置：</p>
<figure data-type="image" tabindex="47"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722093414542.png" alt="image-20210722093414542" loading="lazy"></figure>
<p>并且，在前端会发起查询请求，将你的坐标发送到服务端：</p>
<figure data-type="image" tabindex="48"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722093642382.png" alt="image-20210722093642382" loading="lazy"></figure>
<p>我们要做的事情就是基于这个location坐标，然后按照距离对周围酒店排序。实现思路如下：</p>
<ul>
<li>修改RequestParams参数，接收location字段</li>
<li>修改search方法业务逻辑，如果location有值，添加根据geo_distance排序的功能</li>
</ul>
<h3 id="432修改实体类">4.3.2.修改实体类</h3>
<p>修改在<code>cn.itcast.hotel.pojo</code>包下的实体类RequestParams：</p>
<pre><code class="language-java">package cn.itcast.hotel.pojo;

import lombok.Data;

@Data
public class RequestParams {
    private String key;
    private Integer page;
    private Integer size;
    private String sortBy;
    private String city;
    private String brand;
    private String starName;
    private Integer minPrice;
    private Integer maxPrice;
    // 我当前的地理坐标
    private String location;
}


</code></pre>
<h3 id="433距离排序api">4.3.3.距离排序API</h3>
<p>我们以前学习过排序功能，包括两种：</p>
<ul>
<li>普通字段排序</li>
<li>地理坐标排序</li>
</ul>
<p>我们只讲了普通字段排序对应的java写法。地理坐标排序只学过DSL语法，如下：</p>
<pre><code class="language-json">GET /indexName/_search
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  },
  &quot;sort&quot;: [
    {
      &quot;price&quot;: &quot;asc&quot;  
    },
    {
      &quot;_geo_distance&quot; : {
          &quot;FIELD&quot; : &quot;纬度，经度&quot;,
          &quot;order&quot; : &quot;asc&quot;,
          &quot;unit&quot; : &quot;km&quot;
      }
    }
  ]
}

</code></pre>
<p>对应的java代码示例：</p>
<figure data-type="image" tabindex="49"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722095227059.png" alt="image-20210722095227059" loading="lazy"></figure>
<h3 id="434添加距离排序">4.3.4.添加距离排序</h3>
<p>在<code>cn.itcast.hotel.service.impl</code>的<code>HotelService</code>的<code>search</code>方法中，添加一个排序功能：</p>
<figure data-type="image" tabindex="50"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722095902314.png" alt="image-20210722095902314" loading="lazy"></figure>
<p>完整代码：</p>
<pre><code class="language-java">@Override
public PageResult search(RequestParams params) {
    try {
        // 1.准备Request
        SearchRequest request = new SearchRequest(&quot;hotel&quot;);
        // 2.准备DSL
        // 2.1.query
        buildBasicQuery(params, request);

        // 2.2.分页
        int page = params.getPage();
        int size = params.getSize();
        request.source().from((page - 1) * size).size(size);

        // 2.3.排序
        String location = params.getLocation();
        if (location != null &amp;&amp; !location.equals(&quot;&quot;)) {
            request.source().sort(SortBuilders
                                  .geoDistanceSort(&quot;location&quot;, new GeoPoint(location))
                                  .order(SortOrder.ASC)
                                  .unit(DistanceUnit.KILOMETERS)
                                 );
        }

        // 3.发送请求
        SearchResponse response = client.search(request, RequestOptions.DEFAULT);
        // 4.解析响应
        return handleResponse(response);
    } catch (IOException e) {
        throw new RuntimeException(e);
    }
}

</code></pre>
<h3 id="435排序距离显示">4.3.5.排序距离显示</h3>
<p>重启服务后，测试我的酒店功能：</p>
<figure data-type="image" tabindex="51"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722100040674.png" alt="image-20210722100040674" loading="lazy"></figure>
<p>发现确实可以实现对我附近酒店的排序，不过并没有看到酒店到底距离我多远，这该怎么办？</p>
<p>排序完成后，页面还要获取我附近每个酒店的具体<strong>距离</strong>值，这个值在响应结果中是独立的：</p>
<figure data-type="image" tabindex="52"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722095648542.png" alt="image-20210722095648542" loading="lazy"></figure>
<p>因此，我们在结果解析阶段，除了解析source部分以外，还要得到sort部分，也就是排序的距离，然后放到响应结果中。</p>
<p>我们要做两件事：</p>
<ul>
<li>修改HotelDoc，添加排序距离字段，用于页面显示</li>
<li>修改HotelService类中的handleResponse方法，添加对sort值的获取</li>
</ul>
<p>1）修改HotelDoc类，添加距离字段</p>
<pre><code class="language-java">package cn.itcast.hotel.pojo;

import lombok.Data;
import lombok.NoArgsConstructor;


@Data
@NoArgsConstructor
public class HotelDoc {
    private Long id;
    private String name;
    private String address;
    private Integer price;
    private Integer score;
    private String brand;
    private String city;
    private String starName;
    private String business;
    private String location;
    private String pic;
    // 排序时的 距离值
    private Object distance;

    public HotelDoc(Hotel hotel) {
        this.id = hotel.getId();
        this.name = hotel.getName();
        this.address = hotel.getAddress();
        this.price = hotel.getPrice();
        this.score = hotel.getScore();
        this.brand = hotel.getBrand();
        this.city = hotel.getCity();
        this.starName = hotel.getStarName();
        this.business = hotel.getBusiness();
        this.location = hotel.getLatitude() + &quot;, &quot; + hotel.getLongitude();
        this.pic = hotel.getPic();
    }
}


</code></pre>
<p>2）修改HotelService中的handleResponse方法</p>
<figure data-type="image" tabindex="53"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722100613966.png" alt="image-20210722100613966" loading="lazy"></figure>
<p>重启后测试，发现页面能成功显示距离了：</p>
<figure data-type="image" tabindex="54"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722100838604.png" alt="image-20210722100838604" loading="lazy"></figure>
<h2 id="44酒店竞价排名">4.4.酒店竞价排名</h2>
<p>需求：让指定的酒店在搜索结果中排名置顶</p>
<h3 id="441需求分析">4.4.1.需求分析</h3>
<p>要让指定酒店在搜索结果中排名置顶，效果如图：</p>
<figure data-type="image" tabindex="55"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722100947292.png" alt="image-20210722100947292" loading="lazy"></figure>
<p>页面会给指定的酒店添加<strong>广告</strong>标记。</p>
<p>那怎样才能让指定的酒店排名置顶呢？</p>
<p>我们之前学习过的function_score查询可以影响算分，算分高了，自然排名也就高了。而function_score包含3个要素：</p>
<ul>
<li>过滤条件：哪些文档要加分</li>
<li>算分函数：如何计算function score</li>
<li>加权方式：function score 与 query score如何运算</li>
</ul>
<p>这里的需求是：让<strong>指定酒店</strong>排名靠前。因此我们需要给这些酒店添加一个标记，这样在过滤条件中就可以<strong>根据这个标记来判断，是否要提高算分</strong>。</p>
<p>比如，我们给酒店添加一个字段：isAD，Boolean类型：</p>
<ul>
<li>true：是广告</li>
<li>false：不是广告</li>
</ul>
<p>这样function_score包含3个要素就很好确定了：</p>
<ul>
<li>过滤条件：判断isAD 是否为true</li>
<li>算分函数：我们可以用最简单暴力的weight，固定加权值</li>
<li>加权方式：可以用默认的相乘，大大提高算分</li>
</ul>
<p>因此，业务的实现步骤包括：</p>
<ol>
<li>
<p>给HotelDoc类添加isAD字段，Boolean类型</p>
</li>
<li>
<p>挑选几个你喜欢的酒店，给它的文档数据添加isAD字段，值为true</p>
</li>
<li>
<p>修改search方法，添加function score功能，给isAD值为true的酒店增加权重</p>
</li>
</ol>
<h3 id="442修改hoteldoc实体">4.4.2.修改HotelDoc实体</h3>
<p>给<code>cn.itcast.hotel.pojo</code>包下的HotelDoc类添加isAD字段：</p>
<figure data-type="image" tabindex="56"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722101908062.png" alt="image-20210722101908062" loading="lazy"></figure>
<h3 id="443添加广告标记">4.4.3.添加广告标记</h3>
<p>接下来，我们挑几个酒店，添加isAD字段，设置为true：</p>
<pre><code class="language-json">POST /hotel/_update/1902197537
{
    &quot;doc&quot;: {
        &quot;isAD&quot;: true
    }
}
POST /hotel/_update/2056126831
{
    &quot;doc&quot;: {
        &quot;isAD&quot;: true
    }
}
POST /hotel/_update/1989806195
{
    &quot;doc&quot;: {
        &quot;isAD&quot;: true
    }
}
POST /hotel/_update/2056105938
{
    &quot;doc&quot;: {
        &quot;isAD&quot;: true
    }
}

</code></pre>
<h3 id="444添加算分函数查询">4.4.4.添加算分函数查询</h3>
<p>接下来我们就要修改查询条件了。之前是用的boolean 查询，现在要改成function_socre查询。</p>
<p>function_score查询结构如下：</p>
<figure data-type="image" tabindex="57"><img src="https://shenshen6666.GitHub.io/post-images/image-20210721191544750.png" alt="image-20210721191544750" loading="lazy"></figure>
<p>对应的JavaAPI如下：</p>
<figure data-type="image" tabindex="58"><img src="https://shenshen6666.GitHub.io/post-images/image-20210722102850818.png" alt="image-20210722102850818" loading="lazy"></figure>
<p>我们可以将之前写的boolean查询作为<strong>原始查询</strong>条件放到query中，接下来就是添加<strong>过滤条件</strong>、<strong>算分函数</strong>、<strong>加权模式</strong>了。所以原来的代码依然可以沿用。</p>
<p>修改<code>cn.itcast.hotel.service.impl</code>包下的<code>HotelService</code>类中的<code>buildBasicQuery</code>方法，添加算分函数查询：</p>
<pre><code class="language-java">private void buildBasicQuery(RequestParams params, SearchRequest request) {
    // 1.构建BooleanQuery
    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();
    // 关键字搜索
    String key = params.getKey();
    if (key == null || &quot;&quot;.equals(key)) {
        boolQuery.must(QueryBuilders.matchAllQuery());
    } else {
        boolQuery.must(QueryBuilders.matchQuery(&quot;all&quot;, key));
    }
    // 城市条件
    if (params.getCity() != null &amp;&amp; !params.getCity().equals(&quot;&quot;)) {
        boolQuery.filter(QueryBuilders.termQuery(&quot;city&quot;, params.getCity()));
    }
    // 品牌条件
    if (params.getBrand() != null &amp;&amp; !params.getBrand().equals(&quot;&quot;)) {
        boolQuery.filter(QueryBuilders.termQuery(&quot;brand&quot;, params.getBrand()));
    }
    // 星级条件
    if (params.getStarName() != null &amp;&amp; !params.getStarName().equals(&quot;&quot;)) {
        boolQuery.filter(QueryBuilders.termQuery(&quot;starName&quot;, params.getStarName()));
    }
    // 价格
    if (params.getMinPrice() != null &amp;&amp; params.getMaxPrice() != null) {
        boolQuery.filter(QueryBuilders
                         .rangeQuery(&quot;price&quot;)
                         .gte(params.getMinPrice())
                         .lte(params.getMaxPrice())
                        );
    }

    // 2.算分控制
    FunctionScoreQueryBuilder functionScoreQuery =
        QueryBuilders.functionScoreQuery(
        // 原始查询，相关性算分的查询
        boolQuery,
        // function score的数组
        new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
            // 其中的一个function score 元素
            new FunctionScoreQueryBuilder.FilterFunctionBuilder(
                // 过滤条件
                QueryBuilders.termQuery(&quot;isAD&quot;, true),
                // 算分函数
                ScoreFunctionBuilders.weightFactorFunction(10)
            )
        });
    request.source().query(functionScoreQuery);
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一篇学懂Docker]]></title>
        <id>https://shenshen6666.GitHub.io/post/6/</id>
        <link href="https://shenshen6666.GitHub.io/post/6/">
        </link>
        <updated>2023-12-08T10:05:50.000Z</updated>
        <content type="html"><![CDATA[<h1 id="docker实用篇">Docker实用篇</h1>
<h1 id="0学习目标">0.学习目标</h1>
<h1 id="1初识docker">1.初识Docker</h1>
<h2 id="11什么是docker">1.1.什么是Docker</h2>
<p>微服务虽然具备各种各样的优势，但服务的拆分通用给部署带来了很大的麻烦。</p>
<ul>
<li>分布式系统中，依赖的组件非常多，不同组件之间部署时往往会产生一些冲突。</li>
<li>在数百上千台服务中重复部署，环境不一定一致，会遇到各种问题</li>
</ul>
<h3 id="111应用部署的环境问题">1.1.1.应用部署的环境问题</h3>
<p>大型项目组件较多，运行环境也较为复杂，部署时会碰到一些问题：</p>
<ul>
<li>
<p>依赖关系复杂，容易出现兼容性问题</p>
</li>
<li>
<p>开发、测试、生产环境有差异</p>
</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731141907366.png" alt="image-20210731141907366" loading="lazy"></figure>
<p>例如一个项目中，部署时需要依赖于node.js、Redis、RabbitMQ、MySQL等，这些服务部署时所需要的函数库、依赖项各不相同，甚至会有冲突。给部署带来了极大的困难。</p>
<h3 id="112docker解决依赖兼容问题">1.1.2.Docker解决依赖兼容问题</h3>
<p>而Docker确巧妙的解决了这些问题，Docker是如何实现的呢？</p>
<p>Docker为了解决依赖的兼容问题的，采用了两个手段：</p>
<ul>
<li>
<p>将应用的Libs（函数库）、Deps（依赖）、配置与应用一起打包</p>
</li>
<li>
<p>将每个应用放到一个隔离<strong>容器</strong>去运行，避免互相干扰</p>
</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731142219735.png" alt="image-20210731142219735" loading="lazy"></figure>
<p>这样打包好的应用包中，既包含应用本身，也保护应用所需要的Libs、Deps，无需再操作系统上安装这些，自然就不存在不同应用之间的兼容问题了。</p>
<p>虽然解决了不同应用的兼容问题，但是开发、测试等环境会存在差异，操作系统版本也会有差异，怎么解决这些问题呢？</p>
<h3 id="113docker解决操作系统环境差异">1.1.3.Docker解决操作系统环境差异</h3>
<p>要解决不同操作系统环境差异问题，必须先了解操作系统结构。以一个Ubuntu操作系统为例，结构如下：</p>
<figure data-type="image" tabindex="3"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731143401460.png" alt="image-20210731143401460" loading="lazy"></figure>
<p>结构包括：</p>
<ul>
<li>计算机硬件：例如CPU、内存、磁盘等</li>
<li>系统内核：所有Linux发行版的内核都是Linux，例如CentOS、Ubuntu、Fedora等。内核可以与计算机硬件交互，对外提供<strong>内核指令</strong>，用于操作计算机硬件。</li>
<li>系统应用：操作系统本身提供的应用、函数库。这些函数库是对内核指令的封装，使用更加方便。</li>
</ul>
<p>应用于计算机交互的流程如下：</p>
<p>1）应用调用操作系统应用（函数库），实现各种功能</p>
<p>2）系统函数库是对内核指令集的封装，会调用内核指令</p>
<p>3）内核指令操作计算机硬件</p>
<p>Ubuntu和CentOSpringBoot都是基于Linux内核，无非是系统应用不同，提供的函数库有差异：</p>
<figure data-type="image" tabindex="4"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731144304990.png" alt="image-20210731144304990" loading="lazy"></figure>
<p>此时，如果将一个Ubuntu版本的MySQL应用安装到CentOS系统，MySQL在调用Ubuntu函数库时，会发现找不到或者不匹配，就会报错了：</p>
<figure data-type="image" tabindex="5"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731144458680.png" alt="image-20210731144458680" loading="lazy"></figure>
<p>Docker如何解决不同系统环境的问题？</p>
<ul>
<li>Docker将用户程序与所需要调用的系统(比如Ubuntu)函数库一起打包</li>
<li>Docker运行到不同操作系统时，直接基于打包的函数库，借助于操作系统的Linux内核来运行</li>
</ul>
<p>如图：</p>
<figure data-type="image" tabindex="6"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731144820638.png" alt="image-20210731144820638" loading="lazy"></figure>
<h3 id="114小结">1.1.4.小结</h3>
<p>Docker如何解决大型项目依赖关系复杂，不同组件依赖的兼容性问题？</p>
<ul>
<li>Docker允许开发中将应用、依赖、函数库、配置一起<strong>打包</strong>，形成可移植镜像</li>
<li>Docker应用运行在容器中，使用沙箱机制，相互<strong>隔离</strong></li>
</ul>
<p>Docker如何解决开发、测试、生产环境有差异的问题？</p>
<ul>
<li>Docker镜像中包含完整运行环境，包括系统函数库，仅依赖系统的Linux内核，因此可以在任意Linux操作系统上运行</li>
</ul>
<p>Docker是一个快速交付应用、运行应用的技术，具备下列优势：</p>
<ul>
<li>可以将程序及其依赖、运行环境一起打包为一个镜像，可以迁移到任意Linux操作系统</li>
<li>运行时利用沙箱机制形成隔离容器，各个应用互不干扰</li>
<li>启动、移除都可以通过一行命令完成，方便快捷</li>
</ul>
<h2 id="12docker和虚拟机的区别">1.2.Docker和虚拟机的区别</h2>
<p>Docker可以让一个应用在任何操作系统中非常方便的运行。而以前我们接触的虚拟机，也能在一个操作系统中，运行另外一个操作系统，保护系统中的任何应用。</p>
<p>两者有什么差异呢？</p>
<p><strong>虚拟机</strong>（virtual machine）是在操作系统中<strong>模拟</strong>硬件设备，然后运行另一个操作系统，比如在 Windows 系统里面运行 Ubuntu 系统，这样就可以运行任意的Ubuntu应用了。</p>
<p><strong>Docker</strong>仅仅是封装函数库，并没有模拟完整的操作系统，如图：</p>
<figure data-type="image" tabindex="7"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731145914960.png" alt="image-20210731145914960" loading="lazy"></figure>
<p>对比来看：</p>
<figure data-type="image" tabindex="8"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731152243765.png" alt="image-20210731152243765" loading="lazy"></figure>
<p>小结：</p>
<p>Docker和虚拟机的差异：</p>
<ul>
<li>
<p>docker是一个系统进程；虚拟机是在操作系统中的操作系统</p>
</li>
<li>
<p>docker体积小、启动速度快、性能好；虚拟机体积大、启动速度慢、性能一般</p>
</li>
</ul>
<h2 id="13docker架构">1.3.Docker架构</h2>
<h3 id="131镜像和容器">1.3.1.镜像和容器</h3>
<p>Docker中有几个重要的概念：</p>
<p><strong>镜像（Image）</strong>：Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。</p>
<p><strong>容器（Container）</strong>：镜像中的应用程序运行后形成的进程就是<strong>容器</strong>，只是Docker会给容器进程做隔离，对外不可见。</p>
<p>一切应用最终都是代码组成，都是硬盘中的一个个的字节形成的<strong>文件</strong>。只有运行时，才会加载到内存，形成进程。</p>
<p>而<strong>镜像</strong>，就是把一个应用在硬盘上的文件、及其运行环境、部分系统函数库文件一起打包形成的文件包。这个文件包是只读的。</p>
<p><strong>容器</strong>呢，就是将这些文件中编写的程序、函数加载到内存中允许，形成进程，只不过要隔离起来。因此一个镜像可以启动多次，形成多个容器进程。</p>
<figure data-type="image" tabindex="9"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731153059464.png" alt="image-20210731153059464" loading="lazy"></figure>
<p>例如你下载了一个QQ，如果我们将QQ在磁盘上的运行<strong>文件</strong>及其运行的操作系统依赖打包，形成QQ镜像。然后你可以启动多次，双开、甚至三开QQ，跟多个妹子聊天。</p>
<h3 id="132dockerhub">1.3.2.DockerHub</h3>
<p>开源应用程序非常多，打包这些应用往往是重复的劳动。为了避免这些重复劳动，人们就会将自己打包的应用镜像，例如Redis、MySQL镜像放到网络上，共享使用，就像GitHub的代码共享一样。</p>
<ul>
<li>
<p>DockerHub：DockerHub是一个官方的Docker镜像的托管平台。这样的平台称为Docker Registry。</p>
</li>
<li>
<p>国内也有类似于DockerHub 的公开服务，比如 <a href="https://c.163yun.com/hub">网易云镜像服务</a>、<a href="https://cr.console.aliyun.com/">阿里云镜像库</a>等。</p>
</li>
</ul>
<p>我们一方面可以将自己的镜像共享到DockerHub，另一方面也可以从DockerHub拉取镜像：</p>
<figure data-type="image" tabindex="10"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731153743354.png" alt="image-20210731153743354" loading="lazy"></figure>
<h3 id="133docker架构">1.3.3.Docker架构</h3>
<p>我们要使用Docker来操作镜像、容器，就必须要安装Docker。</p>
<p>Docker是一个CS架构的程序，由两部分组成：</p>
<ul>
<li>
<p>服务端(server)：Docker守护进程，负责处理Docker指令，管理镜像、容器等</p>
</li>
<li>
<p>客户端(client)：通过命令或RestAPI向Docker服务端发送指令。可以在本地或远程向服务端发送指令。</p>
</li>
</ul>
<p>如图：</p>
<figure data-type="image" tabindex="11"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731154257653.png" alt="image-20210731154257653" loading="lazy"></figure>
<h3 id="134小结">1.3.4.小结</h3>
<p>镜像：</p>
<ul>
<li>将应用程序及其依赖、环境、配置打包在一起</li>
</ul>
<p>容器：</p>
<ul>
<li>镜像运行起来就是容器，一个镜像可以运行多个容器</li>
</ul>
<p>Docker结构：</p>
<ul>
<li>
<p>服务端：接收命令或远程请求，操作镜像或容器</p>
</li>
<li>
<p>客户端：发送命令或者请求到Docker服务端</p>
</li>
</ul>
<p>DockerHub：</p>
<ul>
<li>一个镜像托管的服务器，类似的还有阿里云镜像服务，统称为DockerRegistry</li>
</ul>
<h2 id="14安装docker">1.4.安装Docker</h2>
<p>企业部署一般都是采用Linux操作系统，而其中又数CentOS发行版占比最多，因此我们在CentOS下安装Docker。参考课前资料中的文档：</p>
<figure data-type="image" tabindex="12"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731155002425.png" alt="image-20210731155002425" loading="lazy"></figure>
<h1 id="2docker的基本操作">2.Docker的基本操作</h1>
<h2 id="21镜像操作">2.1.镜像操作</h2>
<h3 id="211镜像名称">2.1.1.镜像名称</h3>
<p>首先来看下镜像的名称组成：</p>
<ul>
<li>镜名称一般分两部分组成：[repository]:[tag]。</li>
<li>在没有指定tag时，默认是latest，代表最新版本的镜像</li>
</ul>
<p>如图：</p>
<figure data-type="image" tabindex="13"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731155141362.png" alt="image-20210731155141362" loading="lazy"></figure>
<p>这里的mysql就是repository，5.7就是tag，合一起就是镜像名称，代表5.7版本的MySQL镜像。</p>
<h3 id="212镜像命令">2.1.2.镜像命令</h3>
<p>常见的镜像操作命令如图：</p>
<figure data-type="image" tabindex="14"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731155649535.png" alt="image-20210731155649535" loading="lazy"></figure>
<h3 id="213案例1-拉取-查看镜像">2.1.3.案例1-拉取、查看镜像</h3>
<p>需求：从DockerHub中拉取一个nginx镜像并查看</p>
<p>1）首先去镜像仓库搜索nginx镜像，比如<a href="https://hub.docker.com/">DockerHub</a>:</p>
<figure data-type="image" tabindex="15"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731155844368.png" alt="image-20210731155844368" loading="lazy"></figure>
<p>2）根据查看到的镜像名称，拉取自己需要的镜像，通过命令：docker pull nginx</p>
<figure data-type="image" tabindex="16"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731155856199.png" alt="image-20210731155856199" loading="lazy"></figure>
<p>3）通过命令：docker images 查看拉取到的镜像</p>
<figure data-type="image" tabindex="17"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731155903037.png" alt="image-20210731155903037" loading="lazy"></figure>
<h3 id="214案例2-保存-导入镜像">2.1.4.案例2-保存、导入镜像</h3>
<p>需求：利用docker save将nginx镜像导出磁盘，然后再通过load加载回来</p>
<p>1）利用docker xx --help命令查看docker save和docker load的语法</p>
<p>例如，查看save命令用法，可以输入命令：</p>
<pre><code class="language-sh">docker save --help
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="18"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731161104732.png" alt="image-20210731161104732" loading="lazy"></figure>
<p>命令格式：</p>
<pre><code class="language-shell">docker save -o [保存的目标文件名称] [镜像名称]
</code></pre>
<p>2）使用docker save导出镜像到磁盘</p>
<p>运行命令：</p>
<pre><code class="language-sh">docker save -o nginx.tar nginx:latest
</code></pre>
<p>结果如图：</p>
<figure data-type="image" tabindex="19"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731161354344.png" alt="image-20210731161354344" loading="lazy"></figure>
<p>3）使用docker load加载镜像</p>
<p>先删除本地的nginx镜像：</p>
<pre><code class="language-sh">docker rmi nginx:latest
</code></pre>
<p>然后运行命令，加载本地文件：</p>
<pre><code class="language-sh">docker load -i nginx.tar
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="20"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731161746245.png" alt="image-20210731161746245" loading="lazy"></figure>
<h3 id="215练习">2.1.5.练习</h3>
<p>需求：去DockerHub搜索并拉取一个Redis镜像</p>
<p>目标：</p>
<p>1）去DockerHub搜索Redis镜像</p>
<p>2）查看Redis镜像的名称和版本</p>
<p>3）利用docker pull命令拉取镜像</p>
<p>4）利用docker save命令将 redis:latest打包为一个redis.tar包</p>
<p>5）利用docker rmi 删除本地的redis:latest</p>
<p>6）利用docker load 重新加载 redis.tar文件</p>
<h2 id="22容器操作">2.2.容器操作</h2>
<h3 id="221容器相关命令">2.2.1.容器相关命令</h3>
<p>容器操作的命令如图：</p>
<figure data-type="image" tabindex="21"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731161950495.png" alt="image-20210731161950495" loading="lazy"></figure>
<p>容器保护三个状态：</p>
<ul>
<li>运行：进程正常运行</li>
<li>暂停：进程暂停，CPU不再运行，并不释放内存</li>
<li>停止：进程终止，回收进程占用的内存、CPU等资源</li>
</ul>
<p>其中：</p>
<ul>
<li>
<p>docker run：创建并运行一个容器，处于运行状态</p>
</li>
<li>
<p>docker pause：让一个运行的容器暂停</p>
</li>
<li>
<p>docker unpause：让一个容器从暂停状态恢复运行</p>
</li>
<li>
<p>docker stop：停止一个运行的容器</p>
</li>
<li>
<p>docker start：让一个停止的容器再次运行</p>
</li>
<li>
<p>docker rm：删除一个容器</p>
</li>
</ul>
<h3 id="222案例-创建并运行一个容器">2.2.2.案例-创建并运行一个容器</h3>
<p>创建并运行nginx容器的命令：</p>
<pre><code class="language-sh">docker run --name containerName -p 80:80 -d nginx
</code></pre>
<p>命令解读：</p>
<ul>
<li>docker run ：创建并运行一个容器</li>
<li>--name : 给容器起一个名字，比如叫做mn</li>
<li>-p ：将宿主机端口与容器端口映射，冒号左侧是宿主机端口，右侧是容器端口</li>
<li>-d：后台运行容器</li>
<li>nginx：镜像名称，例如nginx</li>
</ul>
<p>这里的<code>-p</code>参数，是将容器端口映射到宿主机端口。</p>
<p>默认情况下，容器是隔离环境，我们直接访问宿主机的80端口，肯定访问不到容器中的nginx。</p>
<p>现在，将容器的80与宿主机的80关联起来，当我们访问宿主机的80端口时，就会被映射到容器的80，这样就能访问到nginx了：</p>
<figure data-type="image" tabindex="22"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731163255863.png" alt="image-20210731163255863" loading="lazy"></figure>
<h3 id="223案例-进入容器修改文件">2.2.3.案例-进入容器，修改文件</h3>
<p><strong>需求</strong>：进入Nginx容器，修改HTML文件内容，添加“传智教育欢迎您”</p>
<p><strong>提示</strong>：进入容器要用到docker exec命令。</p>
<p><strong>步骤</strong>：</p>
<p>1）进入容器。进入我们刚刚创建的nginx容器的命令为：</p>
<pre><code class="language-sh">docker exec -it mn bash
</code></pre>
<p>命令解读：</p>
<ul>
<li>
<p>docker exec ：进入容器内部，执行一个命令</p>
</li>
<li>
<p>-it : 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互</p>
</li>
<li>
<p>mn ：要进入的容器的名称</p>
</li>
<li>
<p>bash：进入容器后执行的命令，bash是一个linux终端交互命令</p>
</li>
</ul>
<p>2）进入nginx的HTML所在目录 /usr/share/nginx/html</p>
<p>容器内部会模拟一个独立的Linux文件系统，看起来如同一个linux服务器一样：</p>
<figure data-type="image" tabindex="23"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731164159811.png" alt="image-20210731164159811" loading="lazy"></figure>
<p>nginx的环境、配置、运行文件全部都在这个文件系统中，包括我们要修改的html文件。</p>
<p>查看DockerHub网站中的nginx页面，可以知道nginx的html目录位置在<code>/usr/share/nginx/html</code></p>
<p>我们执行命令，进入该目录：</p>
<pre><code class="language-sh">cd /usr/share/nginx/html
</code></pre>
<p>查看目录下文件：</p>
<figure data-type="image" tabindex="24"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731164455818.png" alt="image-20210731164455818" loading="lazy"></figure>
<p>3）修改index.html的内容</p>
<p>容器内没有vi命令，无法直接修改，我们用下面的命令来修改：</p>
<pre><code class="language-sh">sed -i -e 's#Welcome to nginx#传智教育欢迎您#g' -e 's#&lt;head&gt;#&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;#g' index.html

</code></pre>
<p>在浏览器访问自己的虚拟机地址，例如我的是：http://192.168.150.101，即可看到结果：</p>
<figure data-type="image" tabindex="25"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731164717604.png" alt="image-20210731164717604" loading="lazy"></figure>
<h3 id="224小结">2.2.4.小结</h3>
<p>docker run命令的常见参数有哪些？</p>
<ul>
<li>--name：指定容器名称</li>
<li>-p：指定端口映射</li>
<li>-d：让容器后台运行</li>
</ul>
<p>查看容器日志的命令：</p>
<ul>
<li>docker logs</li>
<li>添加 -f 参数可以持续查看日志</li>
</ul>
<p>查看容器状态：</p>
<ul>
<li>docker ps</li>
<li>docker ps -a 查看所有容器，包括已经停止的</li>
</ul>
<h2 id="23数据卷容器数据管理">2.3.数据卷（容器数据管理）</h2>
<p>在之前的nginx案例中，修改nginx的html页面时，需要进入nginx内部。并且因为没有编辑器，修改文件也很麻烦。</p>
<p>这就是因为容器与数据（容器内文件）耦合带来的后果。</p>
<figure data-type="image" tabindex="26"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731172440275.png" alt="image-20210731172440275" loading="lazy"></figure>
<p>要解决这个问题，必须将数据与容器解耦，这就要用到数据卷了。</p>
<h3 id="231什么是数据卷">2.3.1.什么是数据卷</h3>
<p>**数据卷（volume）**是一个虚拟目录，指向宿主机文件系统中的某个目录。</p>
<figure data-type="image" tabindex="27"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731173541846.png" alt="image-20210731173541846" loading="lazy"></figure>
<p>一旦完成数据卷挂载，对容器的一切操作都会作用在数据卷对应的宿主机目录了。</p>
<p>这样，我们操作宿主机的/var/lib/docker/volumes/html目录，就等于操作容器内的/usr/share/nginx/html目录了</p>
<h3 id="232数据集操作命令">2.3.2.数据集操作命令</h3>
<p>数据卷操作的基本语法如下：</p>
<pre><code class="language-sh">docker volume [COMMAND]

</code></pre>
<p>docker volume命令是数据卷操作，根据命令后跟随的command来确定下一步的操作：</p>
<ul>
<li>create 创建一个volume</li>
<li>inspect 显示一个或多个volume的信息</li>
<li>ls 列出所有的volume</li>
<li>prune 删除未使用的volume</li>
<li>rm 删除一个或多个指定的volume</li>
</ul>
<h3 id="233创建和查看数据卷">2.3.3.创建和查看数据卷</h3>
<p><strong>需求</strong>：创建一个数据卷，并查看数据卷在宿主机的目录位置</p>
<p>① 创建数据卷</p>
<pre><code class="language-sh">docker volume create html

</code></pre>
<p>② 查看所有数据</p>
<pre><code class="language-sh">docker volume ls

</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="28"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731173746910.png" alt="image-20210731173746910" loading="lazy"></figure>
<p>③ 查看数据卷详细信息卷</p>
<pre><code class="language-sh">docker volume inspect html

</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="29"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731173809877.png" alt="image-20210731173809877" loading="lazy"></figure>
<p>可以看到，我们创建的html这个数据卷关联的宿主机目录为<code>/var/lib/docker/volumes/html/_data</code>目录。</p>
<p><strong>小结</strong>：</p>
<p>数据卷的作用：</p>
<ul>
<li>将容器与数据分离，解耦合，方便操作容器内数据，保证数据安全</li>
</ul>
<p>数据卷操作：</p>
<ul>
<li>docker volume create：创建数据卷</li>
<li>docker volume ls：查看所有数据卷</li>
<li>docker volume inspect：查看数据卷详细信息，包括关联的宿主机目录位置</li>
<li>docker volume rm：删除指定数据卷</li>
<li>docker volume prune：删除所有未使用的数据卷</li>
</ul>
<h3 id="234挂载数据卷">2.3.4.挂载数据卷</h3>
<p>我们在创建容器时，可以通过 -v 参数来挂载一个数据卷到某个容器内目录，命令格式如下：</p>
<pre><code class="language-sh">docker run \
  --name mn \
  -v html:/root/html \
  -p 8080:80
  nginx \

</code></pre>
<p>这里的-v就是挂载数据卷的命令：</p>
<ul>
<li><code>-v html:/root/htm</code> ：把html数据卷挂载到容器内的/root/html这个目录中</li>
</ul>
<h3 id="235案例-给nginx挂载数据卷">2.3.5.案例-给nginx挂载数据卷</h3>
<p><strong>需求</strong>：创建一个nginx容器，修改容器内的html目录内的index.html内容</p>
<p><strong>分析</strong>：上个案例中，我们进入nginx容器内部，已经知道nginx的html目录所在位置/usr/share/nginx/html ，我们需要把这个目录挂载到html这个数据卷上，方便操作其中的内容。</p>
<p><strong>提示</strong>：运行容器时使用 -v 参数挂载数据卷</p>
<p>步骤：</p>
<p>① 创建容器并挂载数据卷到容器内的HTML目录</p>
<pre><code class="language-sh">docker run --name mn -v html:/usr/share/nginx/html -p 80:80 -d nginx

</code></pre>
<p>② 进入html数据卷所在位置，并修改HTML内容</p>
<pre><code class="language-sh"># 查看html数据卷的位置
docker volume inspect html
# 进入该目录
cd /var/lib/docker/volumes/html/_data
# 修改文件
vi index.html

</code></pre>
<h3 id="236案例-给mysql挂载本地目录">2.3.6.案例-给MySQL挂载本地目录</h3>
<p>容器不仅仅可以挂载数据卷，也可以直接挂载到宿主机目录上。关联关系如下：</p>
<ul>
<li>带数据卷模式：宿主机目录 --&gt; 数据卷 ---&gt; 容器内目录</li>
<li>直接挂载模式：宿主机目录 ---&gt; 容器内目录</li>
</ul>
<p>如图：</p>
<figure data-type="image" tabindex="30"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731175155453.png" alt="image-20210731175155453" loading="lazy"></figure>
<p><strong>语法</strong>：</p>
<p>目录挂载与数据卷挂载的语法是类似的：</p>
<ul>
<li>-v [宿主机目录]:[容器内目录]</li>
<li>-v [宿主机文件]:[容器内文件]</li>
</ul>
<p><strong>需求</strong>：创建并运行一个MySQL容器，将宿主机目录直接挂载到容器</p>
<p>实现思路如下：</p>
<p>1）在将课前资料中的mysql.tar文件上传到虚拟机，通过load命令加载为镜像</p>
<p>2）创建目录/tmp/mysql/data</p>
<p>3）创建目录/tmp/mysql/conf，将课前资料提供的hmy.cnf文件上传到/tmp/mysql/conf</p>
<p>4）去DockerHub查阅资料，创建并运行MySQL容器，要求：</p>
<p>① 挂载/tmp/mysql/data到mysql容器内数据存储目录</p>
<p>② 挂载/tmp/mysql/conf/hmy.cnf到mysql容器的配置文件</p>
<p>③ 设置MySQL密码</p>
<h3 id="237小结">2.3.7.小结</h3>
<p>docker run的命令中通过 -v 参数挂载文件或目录到容器中：</p>
<ul>
<li>-v volume名称:容器内目录</li>
<li>-v 宿主机文件:容器内文</li>
<li>-v 宿主机目录:容器内目录</li>
</ul>
<p>数据卷挂载与目录直接挂载的</p>
<ul>
<li>数据卷挂载耦合度低，由docker来管理目录，但是目录较深，不好找</li>
<li>目录挂载耦合度高，需要我们自己管理目录，不过目录容易寻找查看</li>
</ul>
<h1 id="3dockerfile自定义镜像">3.Dockerfile自定义镜像</h1>
<p>常见的镜像在DockerHub就能找到，但是我们自己写的项目就必须自己构建镜像了。</p>
<p>而要自定义镜像，就必须先了解镜像的结构才行。</p>
<h2 id="31镜像结构">3.1.镜像结构</h2>
<p>镜像是将应用程序及其需要的系统函数库、环境、配置、依赖打包而成。</p>
<p>我们以MySQL为例，来看看镜像的组成结构：</p>
<figure data-type="image" tabindex="31"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731175806273.png" alt="image-20210731175806273" loading="lazy"></figure>
<p>简单来说，镜像就是在系统函数库、运行环境基础上，添加应用程序文件、配置文件、依赖文件等组合，然后编写好启动脚本打包在一起形成的文件。</p>
<p>我们要构建镜像，其实就是实现上述打包的过程。</p>
<h2 id="32dockerfile语法">3.2.Dockerfile语法</h2>
<p>构建自定义的镜像时，并不需要一个个文件去拷贝，打包。</p>
<p>我们只需要告诉Docker，我们的镜像的组成，需要哪些BaseImage、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来Docker会帮助我们构建镜像。</p>
<p>而描述上述信息的文件就是Dockerfile文件。</p>
<p><strong>Dockerfile</strong>就是一个文本文件，其中包含一个个的<strong>指令(Instruction)</strong>，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。</p>
<figure data-type="image" tabindex="32"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731180321133.png" alt="image-20210731180321133" loading="lazy"></figure>
<p>更新详细语法说明，请参考官网文档： https://docs.docker.com/engine/reference/builder</p>
<h2 id="33构建java项目">3.3.构建Java项目</h2>
<h3 id="331基于ubuntu构建java项目">3.3.1.基于Ubuntu构建Java项目</h3>
<p>需求：基于Ubuntu镜像构建一个新镜像，运行一个java项目</p>
<ul>
<li>
<p>步骤1：新建一个空文件夹docker-demo</p>
<figure data-type="image" tabindex="33"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801101207444.png" alt="image-20210801101207444" loading="lazy"></figure>
</li>
<li>
<p>步骤2：拷贝课前资料中的docker-demo.jar文件到docker-demo这个目录</p>
<figure data-type="image" tabindex="34"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801101314816.png" alt="image-20210801101314816" loading="lazy"></figure>
</li>
<li>
<p>步骤3：拷贝课前资料中的jdk8.tar.gz文件到docker-demo这个目录</p>
<figure data-type="image" tabindex="35"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801101410200.png" alt="image-20210801101410200" loading="lazy"></figure>
</li>
<li>
<p>步骤4：拷贝课前资料提供的Dockerfile到docker-demo这个目录</p>
<figure data-type="image" tabindex="36"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801101455590.png" alt="image-20210801101455590" loading="lazy"></figure>
<p>其中的内容如下：</p>
<pre><code class="language-dockerfile"># 指定基础镜像
FROM ubuntu:16.04
# 配置环境变量，JDK的安装目录
ENV JAVA_DIR=/usr/local

# 拷贝jdk和java项目的包
COPY ./jdk8.tar.gz $JAVA_DIR/
COPY ./docker-demo.jar /tmp/app.jar

# 安装JDK
RUN cd $JAVA_DIR \
 &amp;&amp; tar -xf ./jdk8.tar.gz \
 &amp;&amp; mv ./jdk1.8.0_144 ./java8

# 配置环境变量
ENV JAVA_HOME=$JAVA_DIR/java8
ENV PATH=$PATH:$JAVA_HOME/bin

# 暴露端口
EXPOSE 8090
# 入口，java项目的启动命令
ENTRYPOINT java -jar /tmp/app.jar

</code></pre>
</li>
<li>
<p>步骤5：进入docker-demo</p>
<p>将准备好的docker-demo上传到虚拟机任意目录，然后进入docker-demo目录下</p>
</li>
<li>
<p>步骤6：运行命令：</p>
<pre><code class="language-sh">docker build -t javaweb:1.0 .

</code></pre>
</li>
</ul>
<p>最后访问 http://192.168.150.101:8090/hello/count，其中的ip改成你的虚拟机ip</p>
<h3 id="332基于java8构建java项目">3.3.2.基于java8构建Java项目</h3>
<p>虽然我们可以基于Ubuntu基础镜像，添加任意自己需要的安装包，构建镜像，但是却比较麻烦。所以大多数情况下，我们都可以在一些安装了部分软件的基础镜像上做改造。</p>
<p>例如，构建java项目的镜像，可以在已经准备了JDK的基础镜像基础上构建。</p>
<p>需求：基于java:8-alpine镜像，将一个Java项目构建为镜像</p>
<p>实现思路如下：</p>
<ul>
<li>
<p>① 新建一个空的目录，然后在目录中新建一个文件，命名为Dockerfile</p>
</li>
<li>
<p>② 拷贝课前资料提供的docker-demo.jar到这个目录中</p>
</li>
<li>
<p>③ 编写Dockerfile文件：</p>
<ul>
<li>
<p>a ）基于java:8-alpine作为基础镜像</p>
</li>
<li>
<p>b ）将app.jar拷贝到镜像中</p>
</li>
<li>
<p>c ）暴露端口</p>
</li>
<li>
<p>d ）编写入口ENTRYPOINT</p>
<p>内容如下：</p>
<pre><code class="language-dockerfile">FROM java:8-alpine
COPY ./app.jar /tmp/app.jar
EXPOSE 8090
ENTRYPOINT java -jar /tmp/app.jar

</code></pre>
</li>
</ul>
</li>
<li>
<p>④ 使用docker build命令构建镜像</p>
</li>
<li>
<p>⑤ 使用docker run创建容器并运行</p>
</li>
</ul>
<h2 id="34小结">3.4.小结</h2>
<p>小结：</p>
<ol>
<li>
<p>Dockerfile的本质是一个文件，通过指令描述镜像的构建过程</p>
</li>
<li>
<p>Dockerfile的第一行必须是FROM，从一个基础镜像来构建</p>
</li>
<li>
<p>基础镜像可以是基本操作系统，如Ubuntu。也可以是其他人制作好的镜像，例如：java:8-alpine</p>
</li>
</ol>
<h1 id="4docker-compose">4.Docker-Compose</h1>
<p>Docker Compose可以基于Compose文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器！</p>
<figure data-type="image" tabindex="37"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731180921742.png" alt="image-20210731180921742" loading="lazy"></figure>
<h2 id="41初识dockercompose">4.1.初识DockerCompose</h2>
<p>Compose文件是一个文本文件，通过指令定义集群中的每个容器如何运行。格式如下：</p>
<pre><code class="language-json">version: &quot;3.8&quot;
 services:
  mysql:
    image: mysql:5.7.25
    environment:
     MYSQL_ROOT_PASSWORD: 123 
    volumes:
     - &quot;/tmp/mysql/data:/var/lib/mysql&quot;
     - &quot;/tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf&quot;
  web:
    build: .
    ports:
     - &quot;8090:8090&quot;


</code></pre>
<p>上面的Compose文件就描述一个项目，其中包含两个容器：</p>
<ul>
<li>mysql：一个基于<code>mysql:5.7.25</code>镜像构建的容器，并且挂载了两个目录</li>
<li>web：一个基于<code>docker build</code>临时构建的镜像容器，映射端口时8090</li>
</ul>
<p>DockerCompose的详细语法参考官网：https://docs.docker.com/compose/compose-file/</p>
<p>其实DockerCompose文件可以看做是将多个docker run命令写到一个文件，只是语法稍有差异。</p>
<h2 id="42安装dockercompose">4.2.安装DockerCompose</h2>
<p>参考课前资料</p>
<h2 id="43部署微服务集群">4.3.部署微服务集群</h2>
<p><strong>需求</strong>：将之前学习的cloud-demo微服务集群利用DockerCompose部署</p>
<p><strong>实现思路</strong>：</p>
<p>① 查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件</p>
<p>② 修改自己的cloud-demo项目，将数据库、nacos地址都命名为docker-compose中的服务名</p>
<p>③ 使用maven打包工具，将项目中的每个微服务都打包为app.jar</p>
<p>④ 将打包好的app.jar拷贝到cloud-demo中的每一个对应的子目录中</p>
<p>⑤ 将cloud-demo上传至虚拟机，利用 docker-compose up -d 来部署</p>
<h3 id="431compose文件">4.3.1.compose文件</h3>
<p>查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件，而且每个微服务都准备了一个独立的目录：</p>
<figure data-type="image" tabindex="38"><img src="https://shenshen6666.GitHub.io/post-images/image-20210731181341330.png" alt="image-20210731181341330" loading="lazy"></figure>
<p>内容如下：</p>
<pre><code class="language-yaml">version: &quot;3.2&quot;

services:
  nacos:
    image: nacos/nacos-server
    environment:
      MODE: standalone
    ports:
      - &quot;8848:8848&quot;
  mysql:
    image: mysql:5.7.25
    environment:
      MYSQL_ROOT_PASSWORD: 123
    volumes:
      - &quot;$PWD/mysql/data:/var/lib/mysql&quot;
      - &quot;$PWD/mysql/conf:/etc/mysql/conf.d/&quot;
  userservice:
    build: ./user-service
  orderservice:
    build: ./order-service
  gateway:
    build: ./gateway
    ports:
      - &quot;10010:10010&quot;

</code></pre>
<p>可以看到，其中包含5个service服务：</p>
<ul>
<li><code>nacos</code>：作为注册中心和配置中心
<ul>
<li><code>image: nacos/nacos-server</code>： 基于nacos/nacos-server镜像构建</li>
<li><code>environment</code>：环境变量
<ul>
<li><code>MODE: standalone</code>：单点模式启动</li>
</ul>
</li>
<li><code>ports</code>：端口映射，这里暴露了8848端口</li>
</ul>
</li>
<li><code>mysql</code>：数据库
<ul>
<li><code>image: mysql:5.7.25</code>：镜像版本是mysql:5.7.25</li>
<li><code>environment</code>：环境变量
<ul>
<li><code>MYSQL_ROOT_PASSWORD: 123</code>：设置数据库root账户的密码为123</li>
</ul>
</li>
<li><code>volumes</code>：数据卷挂载，这里挂载了mysql的data、conf目录，其中有我提前准备好的数据</li>
</ul>
</li>
<li><code>userservice</code>、<code>orderservice</code>、<code>gateway</code>：都是基于Dockerfile临时构建的</li>
</ul>
<p>查看mysql目录，可以看到其中已经准备好了cloud_order、cloud_user表：</p>
<figure data-type="image" tabindex="39"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801095205034.png" alt="image-20210801095205034" loading="lazy"></figure>
<p>查看微服务目录，可以看到都包含Dockerfile文件：</p>
<figure data-type="image" tabindex="40"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801095320586.png" alt="image-20210801095320586" loading="lazy"></figure>
<p>内容如下：</p>
<pre><code class="language-dockerfile">FROM java:8-alpine
COPY ./app.jar /tmp/app.jar
ENTRYPOINT java -jar /tmp/app.jar

</code></pre>
<h3 id="432修改微服务配置">4.3.2.修改微服务配置</h3>
<p>因为微服务将来要部署为docker容器，而容器之间互联不是通过IP地址，而是通过容器名。这里我们将order-service、user-service、gateway服务的mysql、nacos地址都修改为基于容器名的访问。</p>
<p>如下所示：</p>
<pre><code class="language-yaml">spring:
  datasource:
    url: jdbc:mysql://mysql:3306/cloud_order?useSSL=false
    username: root
    password: 123
    driver-class-name: com.mysql.jdbc.Driver
  application:
    name: orderservice
  cloud:
    nacos:
      server-addr: nacos:8848 # nacos服务地址

</code></pre>
<h3 id="433打包">4.3.3.打包</h3>
<p>接下来需要将我们的每个微服务都打包。因为之前查看到Dockerfile中的jar包名称都是app.jar，因此我们的每个微服务都需要用这个名称。</p>
<p>可以通过修改pom.xml中的打包名称来实现，每个微服务都需要修改：</p>
<pre><code class="language-xml">&lt;build&gt;
  &lt;!-- 服务打包的最终名称 --&gt;
  &lt;finalName&gt;app&lt;/finalName&gt;
  &lt;plugins&gt;
    &lt;plugin&gt;
      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
      &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
    &lt;/plugin&gt;
  &lt;/plugins&gt;
&lt;/build&gt;

</code></pre>
<p>打包后：</p>
<figure data-type="image" tabindex="41"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801095951030.png" alt="image-20210801095951030" loading="lazy"></figure>
<h3 id="434拷贝jar包到部署目录">4.3.4.拷贝jar包到部署目录</h3>
<p>编译打包好的app.jar文件，需要放到Dockerfile的同级目录中。注意：每个微服务的app.jar放到与服务名称对应的目录，别搞错了。</p>
<p>user-service：</p>
<figure data-type="image" tabindex="42"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801100201253.png" alt="image-20210801100201253" loading="lazy"></figure>
<p>order-service：</p>
<figure data-type="image" tabindex="43"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801100231495.png" alt="image-20210801100231495" loading="lazy"></figure>
<p>gateway：</p>
<figure data-type="image" tabindex="44"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801100308102.png" alt="image-20210801100308102" loading="lazy"></figure>
<h3 id="435部署">4.3.5.部署</h3>
<p>最后，我们需要将文件整个cloud-demo文件夹上传到虚拟机中，理由DockerCompose部署。</p>
<p>上传到任意目录：</p>
<figure data-type="image" tabindex="45"><img src="https://shenshen6666.GitHub.io/post-images/image-20210801100955653.png" alt="image-20210801100955653" loading="lazy"></figure>
<p>部署：</p>
<p>进入cloud-demo目录，然后运行下面的命令：</p>
<pre><code class="language-sh">docker-compose up -d

</code></pre>
<h1 id="5docker镜像仓库">5.Docker镜像仓库</h1>
<h2 id="51搭建私有镜像仓库">5.1.搭建私有镜像仓库</h2>
<p>参考课前资料《CentOS7安装Docker.md》</p>
<h2 id="52推送-拉取镜像">5.2.推送、拉取镜像</h2>
<p>推送镜像到私有镜像服务必须先tag，步骤如下：</p>
<p>① 重新tag本地镜像，名称前缀为私有仓库的地址：192.168.150.101:8080/</p>
<pre><code class="language-sh">docker tag nginx:latest 192.168.150.101:8080/nginx:1.0 

</code></pre>
<p>② 推送镜像</p>
<pre><code class="language-sh">docker push 192.168.150.101:8080/nginx:1.0 

</code></pre>
<p>③ 拉取镜像</p>
<pre><code class="language-sh">docker pull 192.168.150.101:8080/nginx:1.0 

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[分布式搜索引擎]]></title>
        <id>https://shenshen6666.GitHub.io/post/fen-bu-shi-sou-suo-yin-qing/</id>
        <link href="https://shenshen6666.GitHub.io/post/fen-bu-shi-sou-suo-yin-qing/">
        </link>
        <updated>2023-11-29T04:11:07.000Z</updated>
        <content type="html"><![CDATA[<h1 id="分布式搜索引擎01">分布式搜索引擎01</h1>
<p>-- elasticsearch基础</p>
<h1 id="0学习目标">0.学习目标</h1>
<h1 id="1初识elasticsearch">1.初识elasticsearch</h1>
<h2 id="11了解es">1.1.了解ES</h2>
<h3 id="111elasticsearch的作用">1.1.1.elasticsearch的作用</h3>
<p>elasticsearch是一款非常强大的开源搜索引擎，具备非常多强大功能，可以帮助我们从海量数据中快速找到需要的内容</p>
<p>例如：</p>
<ul>
<li>
<p>在GitHub搜索代码</p>
<figure data-type="image" tabindex="1"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720193623245.png" alt="image-20210720193623245" loading="lazy"></figure>
</li>
<li>
<p>在电商网站搜索商品</p>
<figure data-type="image" tabindex="2"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720193633483.png" alt="image-20210720193633483" loading="lazy"></figure>
</li>
<li>
<p>在百度搜索答案</p>
<figure data-type="image" tabindex="3"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720193641907.png" alt="image-20210720193641907" loading="lazy"></figure>
</li>
<li>
<p>在打车软件搜索附近的车</p>
<figure data-type="image" tabindex="4"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720193648044.png" alt="image-20210720193648044" loading="lazy"></figure>
</li>
</ul>
<h3 id="112elk技术栈">1.1.2.ELK技术栈</h3>
<p>elasticsearch结合kibana、Logstash、Beats，也就是elastic stack（ELK）。被广泛应用在日志数据分析、实时监控等领域：</p>
<figure data-type="image" tabindex="5"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720194008781.png" alt="image-20210720194008781" loading="lazy"></figure>
<p>而elasticsearch是elastic stack的核心，负责存储、搜索、分析数据。</p>
<figure data-type="image" tabindex="6"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720194230265.png" alt="image-20210720194230265" loading="lazy"></figure>
<h3 id="113elasticsearch和lucene">1.1.3.elasticsearch和lucene</h3>
<p>elasticsearch底层是基于<strong>lucene</strong>来实现的。</p>
<p><strong>Lucene</strong>是一个Java语言的搜索引擎类库，是Apache公司的顶级项目，由DougCutting于1999年研发。官网地址：https://lucene.apache.org/ 。</p>
<figure data-type="image" tabindex="7"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720194547780.png" alt="image-20210720194547780" loading="lazy"></figure>
<p><strong>elasticsearch</strong>的发展历史：</p>
<ul>
<li>2004年Shay Banon基于Lucene开发了Compass</li>
<li>2010年Shay Banon 重写了Compass，取名为Elasticsearch。</li>
</ul>
<figure data-type="image" tabindex="8"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720195001221.png" alt="image-20210720195001221" loading="lazy"></figure>
<h3 id="114为什么不是其他搜索技术">1.1.4.为什么不是其他搜索技术？</h3>
<p>目前比较知名的搜索引擎技术排名：</p>
<figure data-type="image" tabindex="9"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720195142535.png" alt="image-20210720195142535" loading="lazy"></figure>
<p>虽然在早期，Apache Solr是最主要的搜索引擎技术，但随着发展elasticsearch已经渐渐超越了Solr，独占鳌头：</p>
<figure data-type="image" tabindex="10"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720195306484.png" alt="image-20210720195306484" loading="lazy"></figure>
<h3 id="115总结">1.1.5.总结</h3>
<p>什么是elasticsearch？</p>
<ul>
<li>一个开源的分布式搜索引擎，可以用来实现搜索、日志统计、分析、系统监控等功能</li>
</ul>
<p>什么是elastic stack（ELK）？</p>
<ul>
<li>是以elasticsearch为核心的技术栈，包括beats、Logstash、kibana、elasticsearch</li>
</ul>
<p>什么是Lucene？</p>
<ul>
<li>是Apache的开源搜索引擎类库，提供了搜索引擎的核心API</li>
</ul>
<h2 id="12倒排索引">1.2.倒排索引</h2>
<p>倒排索引的概念是基于MySQL这样的正向索引而言的。</p>
<h3 id="121正向索引">1.2.1.正向索引</h3>
<p>那么什么是正向索引呢？例如给下表（tb_goods）中的id创建索引：</p>
<figure data-type="image" tabindex="11"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720195531539.png" alt="image-20210720195531539" loading="lazy"></figure>
<p>如果是根据id查询，那么直接走索引，查询速度非常快。</p>
<p>但如果是基于title做模糊查询，只能是逐行扫描数据，流程如下：</p>
<p>1）用户搜索数据，条件是title符合<code>&quot;%手机%&quot;</code></p>
<p>2）逐行获取数据，比如id为1的数据</p>
<p>3）判断数据中的title是否符合用户搜索条件</p>
<p>4）如果符合则放入结果集，不符合则丢弃。回到步骤1</p>
<p>逐行扫描，也就是全表扫描，随着数据量增加，其查询效率也会越来越低。当数据量达到数百万时，就是一场灾难。</p>
<h3 id="122倒排索引">1.2.2.倒排索引</h3>
<p>倒排索引中有两个非常重要的概念：</p>
<ul>
<li>文档（<code>Document</code>）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息</li>
<li>词条（<code>Term</code>）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条</li>
</ul>
<p><strong>创建倒排索引</strong>是对正向索引的一种特殊处理，流程如下：</p>
<ul>
<li>将每一个文档的数据利用算法分词，得到一个个词条</li>
<li>创建表，每行数据包括词条、词条所在文档id、位置等信息</li>
<li>因为词条唯一性，可以给词条创建索引，例如hash表结构索引</li>
</ul>
<p>如图：</p>
<figure data-type="image" tabindex="12"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720200457207.png" alt="image-20210720200457207" loading="lazy"></figure>
<p>倒排索引的<strong>搜索流程</strong>如下（以搜索&quot;华为手机&quot;为例）：</p>
<p>1）用户输入条件<code>&quot;华为手机&quot;</code>进行搜索。</p>
<p>2）对用户输入内容<strong>分词</strong>，得到词条：<code>华为</code>、<code>手机</code>。</p>
<p>3）拿着词条在倒排索引中查找，可以得到包含词条的文档id：1、2、3。</p>
<p>4）拿着文档id到正向索引中查找具体文档。</p>
<p>如图：</p>
<figure data-type="image" tabindex="13"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720201115192.png" alt="image-20210720201115192" loading="lazy"></figure>
<p>虽然要先查询倒排索引，再查询倒排索引，但是无论是词条、还是文档id都建立了索引，查询速度非常快！无需全表扫描。</p>
<h3 id="123正向和倒排">1.2.3.正向和倒排</h3>
<p>那么为什么一个叫做正向索引，一个叫做倒排索引呢？</p>
<ul>
<li>
<p><strong>正向索引</strong>是最传统的，根据id索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是<strong>根据文档找词条的过程</strong>。</p>
</li>
<li>
<p>而<strong>倒排索引</strong>则相反，是先找到用户要搜索的词条，根据词条得到保护词条的文档的id，然后根据id获取文档。是<strong>根据词条找文档的过程</strong>。</p>
</li>
</ul>
<p>是不是恰好反过来了？</p>
<p>那么两者方式的优缺点是什么呢？</p>
<p><strong>正向索引</strong>：</p>
<ul>
<li>优点：
<ul>
<li>可以给多个字段创建索引</li>
<li>根据索引字段搜索、排序速度非常快</li>
</ul>
</li>
<li>缺点：
<ul>
<li>根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。</li>
</ul>
</li>
</ul>
<p><strong>倒排索引</strong>：</p>
<ul>
<li>优点：
<ul>
<li>根据词条搜索、模糊搜索时，速度非常快</li>
</ul>
</li>
<li>缺点：
<ul>
<li>只能给词条创建索引，而不是字段</li>
<li>无法根据字段做排序</li>
</ul>
</li>
</ul>
<h2 id="13es的一些概念">1.3.es的一些概念</h2>
<p>elasticsearch中有很多独有的概念，与mysql中略有差别，但也有相似之处。</p>
<h3 id="131文档和字段">1.3.1.文档和字段</h3>
<p>elasticsearch是面向**文档（Document）**存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为json格式后存储在elasticsearch中：</p>
<figure data-type="image" tabindex="14"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720202707797.png" alt="image-20210720202707797" loading="lazy"></figure>
<p>而Json文档中往往包含很多的<strong>字段（Field）</strong>，类似于数据库中的列。</p>
<h3 id="132索引和映射">1.3.2.索引和映射</h3>
<p><strong>索引（Index）</strong>，就是相同类型的文档的集合。</p>
<p>例如：</p>
<ul>
<li>所有用户文档，就可以组织在一起，称为用户的索引；</li>
<li>所有商品的文档，可以组织在一起，称为商品的索引；</li>
<li>所有订单的文档，可以组织在一起，称为订单的索引；</li>
</ul>
<figure data-type="image" tabindex="15"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720203022172.png" alt="image-20210720203022172" loading="lazy"></figure>
<p>因此，我们可以把索引当做是数据库中的表。</p>
<p>数据库的表会有约束信息，用来定义表的结构、字段的名称、类型等信息。因此，索引库中就有<strong>映射（mapping）</strong>，是索引中文档的字段约束信息，类似表的结构约束。</p>
<h3 id="133mysql与elasticsearch">1.3.3.mysql与elasticsearch</h3>
<p>我们统一的把mysql与elasticsearch的概念做一下对比：</p>
<table>
<thead>
<tr>
<th><strong>MySQL</strong></th>
<th><strong>Elasticsearch</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Table</td>
<td>Index</td>
<td>索引(index)，就是文档的集合，类似数据库的表(table)</td>
</tr>
<tr>
<td>Row</td>
<td>Document</td>
<td>文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式</td>
</tr>
<tr>
<td>Column</td>
<td>Field</td>
<td>字段（Field），就是JSON文档中的字段，类似数据库中的列（Column）</td>
</tr>
<tr>
<td>Schema</td>
<td>Mapping</td>
<td>Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema）</td>
</tr>
<tr>
<td>SQL</td>
<td>DSL</td>
<td>DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD</td>
</tr>
</tbody>
</table>
<p>是不是说，我们学习了elasticsearch就不再需要mysql了呢？</p>
<p>并不是如此，两者各自有自己的擅长支出：</p>
<ul>
<li>
<p>Mysql：擅长事务类型操作，可以确保数据的安全和一致性</p>
</li>
<li>
<p>Elasticsearch：擅长海量数据的搜索、分析、计算</p>
</li>
</ul>
<p>因此在企业中，往往是两者结合使用：</p>
<ul>
<li>对安全性要求较高的写操作，使用mysql实现</li>
<li>对查询性能要求较高的搜索需求，使用elasticsearch实现</li>
<li>两者再基于某种方式，实现数据的同步，保证一致性</li>
</ul>
<figure data-type="image" tabindex="16"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720203534945.png" alt="image-20210720203534945" loading="lazy"></figure>
<h2 id="14安装es-kibana">1.4.安装es、kibana</h2>
<h3 id="141安装">1.4.1.安装</h3>
<p>参考课前资料：</p>
<figure data-type="image" tabindex="17"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720203805350.png" alt="image-20210720203805350" loading="lazy"></figure>
<h3 id="142分词器">1.4.2.分词器</h3>
<p>参考课前资料：</p>
<figure data-type="image" tabindex="18"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720203805350.png" alt="image-20210720203805350" loading="lazy"></figure>
<h3 id="143总结">1.4.3.总结</h3>
<p>分词器的作用是什么？</p>
<ul>
<li>创建倒排索引时对文档分词</li>
<li>用户搜索时，对输入的内容分词</li>
</ul>
<p>IK分词器有几种模式？</p>
<ul>
<li>ik_smart：智能切分，粗粒度</li>
<li>ik_max_word：最细切分，细粒度</li>
</ul>
<p>IK分词器如何拓展词条？如何停用词条？</p>
<ul>
<li>利用config目录的IkAnalyzer.cfg.xml文件添加拓展词典和停用词典</li>
<li>在词典中添加拓展词条或者停用词条</li>
</ul>
<h1 id="2索引库操作">2.索引库操作</h1>
<p>索引库就类似数据库表，mapping映射就类似表的结构。</p>
<p>我们要向es中存储数据，必须先创建“库”和“表”。</p>
<h2 id="21mapping映射属性">2.1.mapping映射属性</h2>
<p>mapping是对索引库中文档的约束，常见的mapping属性包括：</p>
<ul>
<li>type：字段数据类型，常见的简单类型有：
<ul>
<li>字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip地址）</li>
<li>数值：long、integer、short、byte、double、float、</li>
<li>布尔：boolean</li>
<li>日期：date</li>
<li>对象：object</li>
</ul>
</li>
<li>index：是否创建索引，默认为true</li>
<li>analyzer：使用哪种分词器</li>
<li>properties：该字段的子字段</li>
</ul>
<p>例如下面的json文档：</p>
<pre><code class="language-json">{
    &quot;age&quot;: 21,
    &quot;weight&quot;: 52.1,
    &quot;isMarried&quot;: false,
    &quot;info&quot;: &quot;黑马程序员Java讲师&quot;,
    &quot;email&quot;: &quot;zy@itcast.cn&quot;,
    &quot;score&quot;: [99.1, 99.5, 98.9],
    &quot;name&quot;: {
        &quot;firstName&quot;: &quot;云&quot;,
        &quot;lastName&quot;: &quot;赵&quot;
    }
}
</code></pre>
<p>对应的每个字段映射（mapping）：</p>
<ul>
<li>age：类型为 integer；参与搜索，因此需要index为true；无需分词器</li>
<li>weight：类型为float；参与搜索，因此需要index为true；无需分词器</li>
<li>isMarried：类型为boolean；参与搜索，因此需要index为true；无需分词器</li>
<li>info：类型为字符串，需要分词，因此是text；参与搜索，因此需要index为true；分词器可以用ik_smart</li>
<li>email：类型为字符串，但是不需要分词，因此是keyword；不参与搜索，因此需要index为false；无需分词器</li>
<li>score：虽然是数组，但是我们只看元素的类型，类型为float；参与搜索，因此需要index为true；无需分词器</li>
<li>name：类型为object，需要定义多个子属性
<ul>
<li>name.firstName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器</li>
<li>name.lastName；类型为字符串，但是不需要分词，因此是keyword；参与搜索，因此需要index为true；无需分词器</li>
</ul>
</li>
</ul>
<h2 id="22索引库的crud">2.2.索引库的CRUD</h2>
<p>这里我们统一使用Kibana编写DSL的方式来演示。</p>
<h3 id="221创建索引库和映射">2.2.1.创建索引库和映射</h3>
<h4 id="基本语法">基本语法：</h4>
<ul>
<li>请求方式：PUT</li>
<li>请求路径：/索引库名，可以自定义</li>
<li>请求参数：mapping映射</li>
</ul>
<p>格式：</p>
<pre><code class="language-json">PUT /索引库名称
{
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;字段名&quot;:{
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_smart&quot;
      },
      &quot;字段名2&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: &quot;false&quot;
      },
      &quot;字段名3&quot;:{
        &quot;properties&quot;: {
          &quot;子字段&quot;: {
            &quot;type&quot;: &quot;keyword&quot;
          }
        }
      },
      // ...略
    }
  }
}
</code></pre>
<h4 id="示例">示例：</h4>
<pre><code class="language-sh">PUT /heima
{
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;info&quot;:{
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_smart&quot;
      },
      &quot;email&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: &quot;falsae&quot;
      },
      &quot;name&quot;:{
        &quot;properties&quot;: {
          &quot;firstName&quot;: {
            &quot;type&quot;: &quot;keyword&quot;
          }
        }
      },
      // ... 略
    }
  }
}
</code></pre>
<h3 id="222查询索引库">2.2.2.查询索引库</h3>
<p><strong>基本语法</strong>：</p>
<ul>
<li>
<p>请求方式：GET</p>
</li>
<li>
<p>请求路径：/索引库名</p>
</li>
<li>
<p>请求参数：无</p>
</li>
</ul>
<p><strong>格式</strong>：</p>
<pre><code>GET /索引库名
</code></pre>
<p><strong>示例</strong>：</p>
<figure data-type="image" tabindex="19"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720211019329.png" alt="image-20210720211019329" loading="lazy"></figure>
<h3 id="223修改索引库">2.2.3.修改索引库</h3>
<p>倒排索引结构虽然不复杂，但是一旦数据结构改变（比如改变了分词器），就需要重新创建倒排索引，这简直是灾难。因此索引库<strong>一旦创建，无法修改mapping</strong>。</p>
<p>虽然无法修改mapping中已有的字段，但是却允许添加新的字段到mapping中，因为不会对倒排索引产生影响。</p>
<p><strong>语法说明</strong>：</p>
<pre><code class="language-json">PUT /索引库名/_mapping
{
  &quot;properties&quot;: {
    &quot;新字段名&quot;:{
      &quot;type&quot;: &quot;integer&quot;
    }
  }
}
</code></pre>
<p><strong>示例</strong>：</p>
<figure data-type="image" tabindex="20"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720212357390.png" alt="image-20210720212357390" loading="lazy"></figure>
<h3 id="224删除索引库">2.2.4.删除索引库</h3>
<p><strong>语法：</strong></p>
<ul>
<li>
<p>请求方式：DELETE</p>
</li>
<li>
<p>请求路径：/索引库名</p>
</li>
<li>
<p>请求参数：无</p>
</li>
</ul>
<p><strong>格式：</strong></p>
<pre><code>DELETE /索引库名
</code></pre>
<p>在kibana中测试：</p>
<figure data-type="image" tabindex="21"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720212123420.png" alt="image-20210720212123420" loading="lazy"></figure>
<h3 id="225总结">2.2.5.总结</h3>
<p>索引库操作有哪些？</p>
<ul>
<li>创建索引库：PUT /索引库名</li>
<li>查询索引库：GET /索引库名</li>
<li>删除索引库：DELETE /索引库名</li>
<li>添加字段：PUT /索引库名/_mapping</li>
</ul>
<h1 id="3文档操作">3.文档操作</h1>
<h2 id="31新增文档">3.1.新增文档</h2>
<p><strong>语法：</strong></p>
<pre><code class="language-json">POST /索引库名/_doc/文档id
{
    &quot;字段1&quot;: &quot;值1&quot;,
    &quot;字段2&quot;: &quot;值2&quot;,
    &quot;字段3&quot;: {
        &quot;子属性1&quot;: &quot;值3&quot;,
        &quot;子属性2&quot;: &quot;值4&quot;
    },
    // ...
}
</code></pre>
<p><strong>示例：</strong></p>
<pre><code class="language-json">POST /heima/_doc/1
{
    &quot;info&quot;: &quot;黑马程序员Java讲师&quot;,
    &quot;email&quot;: &quot;zy@itcast.cn&quot;,
    &quot;name&quot;: {
        &quot;firstName&quot;: &quot;云&quot;,
        &quot;lastName&quot;: &quot;赵&quot;
    }
}
</code></pre>
<p><strong>响应：</strong></p>
<figure data-type="image" tabindex="22"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720212933362.png" alt="image-20210720212933362" loading="lazy"></figure>
<h2 id="32查询文档">3.2.查询文档</h2>
<p>根据rest风格，新增是post，查询应该是get，不过查询一般都需要条件，这里我们把文档id带上。</p>
<p><strong>语法：</strong></p>
<pre><code class="language-json">GET /{索引库名称}/_doc/{id}
</code></pre>
<p><strong>通过kibana查看数据：</strong></p>
<pre><code class="language-js">GET /heima/_doc/1
</code></pre>
<p><strong>查看结果：</strong></p>
<figure data-type="image" tabindex="23"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720213345003.png" alt="image-20210720213345003" loading="lazy"></figure>
<h2 id="33删除文档">3.3.删除文档</h2>
<p>删除使用DELETE请求，同样，需要根据id进行删除：</p>
<p><strong>语法：</strong></p>
<pre><code class="language-js">DELETE /{索引库名}/_doc/id值
</code></pre>
<p><strong>示例：</strong></p>
<pre><code class="language-json"># 根据id删除数据
DELETE /heima/_doc/1
</code></pre>
<p><strong>结果：</strong></p>
<figure data-type="image" tabindex="24"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720213634918.png" alt="image-20210720213634918" loading="lazy"></figure>
<h2 id="34修改文档">3.4.修改文档</h2>
<p>修改有两种方式：</p>
<ul>
<li>全量修改：直接覆盖原来的文档</li>
<li>增量修改：修改文档中的部分字段</li>
</ul>
<h3 id="341全量修改">3.4.1.全量修改</h3>
<p>全量修改是覆盖原来的文档，其本质是：</p>
<ul>
<li>根据指定的id删除文档</li>
<li>新增一个相同id的文档</li>
</ul>
<p><strong>注意</strong>：如果根据id删除时，id不存在，第二步的新增也会执行，也就从修改变成了新增操作了。</p>
<p><strong>语法：</strong></p>
<pre><code class="language-json">PUT /{索引库名}/_doc/文档id
{
    &quot;字段1&quot;: &quot;值1&quot;,
    &quot;字段2&quot;: &quot;值2&quot;,
    // ... 略
}

</code></pre>
<p><strong>示例：</strong></p>
<pre><code class="language-json">PUT /heima/_doc/1
{
    &quot;info&quot;: &quot;黑马程序员高级Java讲师&quot;,
    &quot;email&quot;: &quot;zy@itcast.cn&quot;,
    &quot;name&quot;: {
        &quot;firstName&quot;: &quot;云&quot;,
        &quot;lastName&quot;: &quot;赵&quot;
    }
}
</code></pre>
<h3 id="342增量修改">3.4.2.增量修改</h3>
<p>增量修改是只修改指定id匹配的文档中的部分字段。</p>
<p><strong>语法：</strong></p>
<pre><code class="language-json">POST /{索引库名}/_update/文档id
{
    &quot;doc&quot;: {
         &quot;字段名&quot;: &quot;新的值&quot;,
    }
}
</code></pre>
<p><strong>示例：</strong></p>
<pre><code class="language-json">POST /heima/_update/1
{
  &quot;doc&quot;: {
    &quot;email&quot;: &quot;ZhaoYun@itcast.cn&quot;
  }
}
</code></pre>
<h2 id="35总结">3.5.总结</h2>
<p>文档操作有哪些？</p>
<ul>
<li>创建文档：POST /{索引库名}/_doc/文档id   { json文档 }</li>
<li>查询文档：GET /{索引库名}/_doc/文档id</li>
<li>删除文档：DELETE /{索引库名}/_doc/文档id</li>
<li>修改文档：
<ul>
<li>全量修改：PUT /{索引库名}/_doc/文档id { json文档 }</li>
<li>增量修改：POST /{索引库名}/_update/文档id { &quot;doc&quot;: {字段}}</li>
</ul>
</li>
</ul>
<h1 id="4restapi">4.RestAPI</h1>
<p>ES官方提供了各种不同语言的客户端，用来操作ES。这些客户端的本质就是组装DSL语句，通过http请求发送给ES。官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html</p>
<p>其中的Java Rest Client又包括两种：</p>
<ul>
<li>Java Low Level Rest Client</li>
<li>Java High Level Rest Client</li>
</ul>
<figure data-type="image" tabindex="25"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720214555863.png" alt="image-20210720214555863" loading="lazy"></figure>
<p>我们学习的是Java HighLevel Rest Client客户端API</p>
<h2 id="40导入demo工程">4.0.导入Demo工程</h2>
<h3 id="401导入数据">4.0.1.导入数据</h3>
<p>首先导入课前资料提供的数据库数据：</p>
<figure data-type="image" tabindex="26"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720220400297.png" alt="image-20210720220400297" loading="lazy"></figure>
<p>数据结构如下：</p>
<pre><code class="language-sql">CREATE TABLE `tb_hotel` (
  `id` bigint(20) NOT NULL COMMENT '酒店id',
  `name` varchar(255) NOT NULL COMMENT '酒店名称；例：7天酒店',
  `address` varchar(255) NOT NULL COMMENT '酒店地址；例：航头路',
  `price` int(10) NOT NULL COMMENT '酒店价格；例：329',
  `score` int(2) NOT NULL COMMENT '酒店评分；例：45，就是4.5分',
  `brand` varchar(32) NOT NULL COMMENT '酒店品牌；例：如家',
  `city` varchar(32) NOT NULL COMMENT '所在城市；例：上海',
  `star_name` varchar(16) DEFAULT NULL COMMENT '酒店星级，从低到高分别是：1星到5星，1钻到5钻',
  `business` varchar(255) DEFAULT NULL COMMENT '商圈；例：虹桥',
  `latitude` varchar(32) NOT NULL COMMENT '纬度；例：31.2497',
  `longitude` varchar(32) NOT NULL COMMENT '经度；例：120.3925',
  `pic` varchar(255) DEFAULT NULL COMMENT '酒店图片；例:/img/1.jpg',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

</code></pre>
<h3 id="402导入项目">4.0.2.导入项目</h3>
<p>然后导入课前资料提供的项目:</p>
<figure data-type="image" tabindex="27"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720220503411.png" alt="image-20210720220503411" loading="lazy"></figure>
<p>项目结构如图：</p>
<figure data-type="image" tabindex="28"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720220647541.png" alt="image-20210720220647541" loading="lazy"></figure>
<h3 id="403mapping映射分析">4.0.3.mapping映射分析</h3>
<p>创建索引库，最关键的是mapping映射，而mapping映射要考虑的信息包括：</p>
<ul>
<li>字段名</li>
<li>字段数据类型</li>
<li>是否参与搜索</li>
<li>是否需要分词</li>
<li>如果分词，分词器是什么？</li>
</ul>
<p>其中：</p>
<ul>
<li>字段名、字段数据类型，可以参考数据表结构的名称和类型</li>
<li>是否参与搜索要分析业务来判断，例如图片地址，就无需参与搜索</li>
<li>是否分词呢要看内容，内容如果是一个整体就无需分词，反之则要分词</li>
<li>分词器，我们可以统一使用ik_max_word</li>
</ul>
<p>来看下酒店数据的索引库结构:</p>
<pre><code class="language-json">PUT /hotel
{
  &quot;mappings&quot;: {
    &quot;properties&quot;: {
      &quot;id&quot;: {
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;name&quot;:{
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      },
      &quot;address&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: false
      },
      &quot;price&quot;:{
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;score&quot;:{
        &quot;type&quot;: &quot;integer&quot;
      },
      &quot;brand&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      },
      &quot;city&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;copy_to&quot;: &quot;all&quot;
      },
      &quot;starName&quot;:{
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;business&quot;:{
        &quot;type&quot;: &quot;keyword&quot;
      },
      &quot;location&quot;:{
        &quot;type&quot;: &quot;geo_point&quot;
      },
      &quot;pic&quot;:{
        &quot;type&quot;: &quot;keyword&quot;,
        &quot;index&quot;: false
      },
      &quot;all&quot;:{
        &quot;type&quot;: &quot;text&quot;,
        &quot;analyzer&quot;: &quot;ik_max_word&quot;
      }
    }
  }
}

</code></pre>
<p>几个特殊字段说明：</p>
<ul>
<li>location：地理坐标，里面包含精度、纬度</li>
<li>all：一个组合字段，其目的是将多字段的值 利用copy_to合并，提供给用户搜索</li>
</ul>
<p>地理坐标说明：</p>
<figure data-type="image" tabindex="29"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720222110126.png" alt="image-20210720222110126" loading="lazy"></figure>
<p>copy_to说明：</p>
<figure data-type="image" tabindex="30"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720222221516.png" alt="image-20210720222221516" loading="lazy"></figure>
<h3 id="404初始化restclient">4.0.4.初始化RestClient</h3>
<p>在elasticsearch提供的API中，与elasticsearch一切交互都封装在一个名为RestHighLevelClient的类中，必须先完成这个对象的初始化，建立与elasticsearch的连接。</p>
<p>分为三步：</p>
<p>1）引入es的RestHighLevelClient依赖：</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;
    &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<p>2）因为SpringBoot默认的ES版本是7.6.2，所以我们需要覆盖默认的ES版本：</p>
<pre><code class="language-xml">&lt;properties&gt;
    &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;elasticsearch.version&gt;7.12.1&lt;/elasticsearch.version&gt;
&lt;/properties&gt;

</code></pre>
<p>3）初始化RestHighLevelClient：</p>
<p>初始化的代码如下：</p>
<pre><code class="language-java">RestHighLevelClient client = new RestHighLevelClient(RestClient.builder(
        HttpHost.create(&quot;http://192.168.150.101:9200&quot;)
));

</code></pre>
<p>这里为了单元测试方便，我们创建一个测试类HotelIndexTest，然后将初始化的代码编写在@BeforeEach方法中：</p>
<pre><code class="language-java">package cn.itcast.hotel;

import org.apache.http.HttpHost;
import org.elasticsearch.client.RestHighLevelClient;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import java.io.IOException;

public class HotelIndexTest {
    private RestHighLevelClient client;

    @BeforeEach
    void setUp() {
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.150.101:9200&quot;)
        ));
    }

    @AfterEach
    void tearDown() throws IOException {
        this.client.close();
    }
}

</code></pre>
<h2 id="41创建索引库">4.1.创建索引库</h2>
<h3 id="411代码解读">4.1.1.代码解读</h3>
<p>创建索引库的API如下：</p>
<figure data-type="image" tabindex="31"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720223049408.png" alt="image-20210720223049408" loading="lazy"></figure>
<p>代码分为三步：</p>
<ul>
<li>1）创建Request对象。因为是创建索引库的操作，因此Request是CreateIndexRequest。</li>
<li>2）添加请求参数，其实就是DSL的JSON参数部分。因为json字符串很长，这里是定义了静态字符串常量MAPPING_TEMPLATE，让代码看起来更加优雅。</li>
<li>3）发送请求，client.indices()方法的返回值是IndicesClient类型，封装了所有与索引库操作有关的方法。</li>
</ul>
<h3 id="412完整示例">4.1.2.完整示例</h3>
<p>在hotel-demo的cn.itcast.hotel.constants包下，创建一个类，定义mapping映射的JSON字符串常量：</p>
<pre><code class="language-java">package cn.itcast.hotel.constants;

public class HotelConstants {
    public static final String MAPPING_TEMPLATE = &quot;{\n&quot; +
            &quot;  \&quot;mappings\&quot;: {\n&quot; +
            &quot;    \&quot;properties\&quot;: {\n&quot; +
            &quot;      \&quot;id\&quot;: {\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;name\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;text\&quot;,\n&quot; +
            &quot;        \&quot;analyzer\&quot;: \&quot;ik_max_word\&quot;,\n&quot; +
            &quot;        \&quot;copy_to\&quot;: \&quot;all\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;address\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;,\n&quot; +
            &quot;        \&quot;index\&quot;: false\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;price\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;integer\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;score\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;integer\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;brand\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;,\n&quot; +
            &quot;        \&quot;copy_to\&quot;: \&quot;all\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;city\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;,\n&quot; +
            &quot;        \&quot;copy_to\&quot;: \&quot;all\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;starName\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;business\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;location\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;geo_point\&quot;\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;pic\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;keyword\&quot;,\n&quot; +
            &quot;        \&quot;index\&quot;: false\n&quot; +
            &quot;      },\n&quot; +
            &quot;      \&quot;all\&quot;:{\n&quot; +
            &quot;        \&quot;type\&quot;: \&quot;text\&quot;,\n&quot; +
            &quot;        \&quot;analyzer\&quot;: \&quot;ik_max_word\&quot;\n&quot; +
            &quot;      }\n&quot; +
            &quot;    }\n&quot; +
            &quot;  }\n&quot; +
            &quot;}&quot;;
}

</code></pre>
<p>在hotel-demo中的HotelIndexTest测试类中，编写单元测试，实现创建索引：</p>
<pre><code class="language-java">@Test
void createHotelIndex() throws IOException {
    // 1.创建Request对象
    CreateIndexRequest request = new CreateIndexRequest(&quot;hotel&quot;);
    // 2.准备请求的参数：DSL语句
    request.source(MAPPING_TEMPLATE, XContentType.JSON);
    // 3.发送请求
    client.indices().create(request, RequestOptions.DEFAULT);
}

</code></pre>
<h2 id="42删除索引库">4.2.删除索引库</h2>
<p>删除索引库的DSL语句非常简单：</p>
<pre><code class="language-json">DELETE /hotel

</code></pre>
<p>与创建索引库相比：</p>
<ul>
<li>请求方式从PUT变为DELTE</li>
<li>请求路径不变</li>
<li>无请求参数</li>
</ul>
<p>所以代码的差异，注意体现在Request对象上。依然是三步走：</p>
<ul>
<li>1）创建Request对象。这次是DeleteIndexRequest对象</li>
<li>2）准备参数。这里是无参</li>
<li>3）发送请求。改用delete方法</li>
</ul>
<p>在hotel-demo中的HotelIndexTest测试类中，编写单元测试，实现删除索引：</p>
<pre><code class="language-java">@Test
void testDeleteHotelIndex() throws IOException {
    // 1.创建Request对象
    DeleteIndexRequest request = new DeleteIndexRequest(&quot;hotel&quot;);
    // 2.发送请求
    client.indices().delete(request, RequestOptions.DEFAULT);
}

</code></pre>
<h2 id="43判断索引库是否存在">4.3.判断索引库是否存在</h2>
<p>判断索引库是否存在，本质就是查询，对应的DSL是：</p>
<pre><code class="language-json">GET /hotel

</code></pre>
<p>因此与删除的Java代码流程是类似的。依然是三步走：</p>
<ul>
<li>1）创建Request对象。这次是GetIndexRequest对象</li>
<li>2）准备参数。这里是无参</li>
<li>3）发送请求。改用exists方法</li>
</ul>
<pre><code class="language-java">@Test
void testExistsHotelIndex() throws IOException {
    // 1.创建Request对象
    GetIndexRequest request = new GetIndexRequest(&quot;hotel&quot;);
    // 2.发送请求
    boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
    // 3.输出
    System.err.println(exists ? &quot;索引库已经存在！&quot; : &quot;索引库不存在！&quot;);
}

</code></pre>
<h2 id="44总结">4.4.总结</h2>
<p>JavaRestClient操作elasticsearch的流程基本类似。核心是client.indices()方法来获取索引库的操作对象。</p>
<p>索引库操作的基本步骤：</p>
<ul>
<li>初始化RestHighLevelClient</li>
<li>创建XxxIndexRequest。XXX是Create、Get、Delete</li>
<li>准备DSL（ Create时需要，其它是无参）</li>
<li>发送请求。调用RestHighLevelClient#indices().xxx()方法，xxx是create、exists、delete</li>
</ul>
<h1 id="5restclient操作文档">5.RestClient操作文档</h1>
<p>为了与索引库操作分离，我们再次参加一个测试类，做两件事情：</p>
<ul>
<li>初始化RestHighLevelClient</li>
<li>我们的酒店数据在数据库，需要利用IHotelService去查询，所以注入这个接口</li>
</ul>
<pre><code class="language-java">package cn.itcast.hotel;

import cn.itcast.hotel.pojo.Hotel;
import cn.itcast.hotel.service.IHotelService;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;

import java.io.IOException;
import java.util.List;

@SpringBootTest
public class HotelDocumentTest {
    @Autowired
    private IHotelService hotelService;

    private RestHighLevelClient client;

    @BeforeEach
    void setUp() {
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create(&quot;http://192.168.150.101:9200&quot;)
        ));
    }

    @AfterEach
    void tearDown() throws IOException {
        this.client.close();
    }
}


</code></pre>
<h2 id="51新增文档">5.1.新增文档</h2>
<p>我们要将数据库的酒店数据查询出来，写入elasticsearch中。</p>
<h3 id="511索引库实体类">5.1.1.索引库实体类</h3>
<p>数据库查询后的结果是一个Hotel类型的对象。结构如下：</p>
<pre><code class="language-java">@Data
@TableName(&quot;tb_hotel&quot;)
public class Hotel {
    @TableId(type = IdType.INPUT)
    private Long id;
    private String name;
    private String address;
    private Integer price;
    private Integer score;
    private String brand;
    private String city;
    private String starName;
    private String business;
    private String longitude;
    private String latitude;
    private String pic;
}

</code></pre>
<p>与我们的索引库结构存在差异：</p>
<ul>
<li>longitude和latitude需要合并为location</li>
</ul>
<p>因此，我们需要定义一个新的类型，与索引库结构吻合：</p>
<pre><code class="language-java">package cn.itcast.hotel.pojo;

import lombok.Data;
import lombok.NoArgsConstructor;

@Data
@NoArgsConstructor
public class HotelDoc {
    private Long id;
    private String name;
    private String address;
    private Integer price;
    private Integer score;
    private String brand;
    private String city;
    private String starName;
    private String business;
    private String location;
    private String pic;

    public HotelDoc(Hotel hotel) {
        this.id = hotel.getId();
        this.name = hotel.getName();
        this.address = hotel.getAddress();
        this.price = hotel.getPrice();
        this.score = hotel.getScore();
        this.brand = hotel.getBrand();
        this.city = hotel.getCity();
        this.starName = hotel.getStarName();
        this.business = hotel.getBusiness();
        this.location = hotel.getLatitude() + &quot;, &quot; + hotel.getLongitude();
        this.pic = hotel.getPic();
    }
}


</code></pre>
<h3 id="512语法说明">5.1.2.语法说明</h3>
<p>新增文档的DSL语句如下：</p>
<pre><code class="language-json">POST /{索引库名}/_doc/1
{
    &quot;name&quot;: &quot;Jack&quot;,
    &quot;age&quot;: 21
}

</code></pre>
<p>对应的java代码如图：</p>
<figure data-type="image" tabindex="32"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720230027240.png" alt="image-20210720230027240" loading="lazy"></figure>
<p>可以看到与创建索引库类似，同样是三步走：</p>
<ul>
<li>1）创建Request对象</li>
<li>2）准备请求参数，也就是DSL中的JSON文档</li>
<li>3）发送请求</li>
</ul>
<p>变化的地方在于，这里直接使用client.xxx()的API，不再需要client.indices()了。</p>
<h3 id="513完整代码">5.1.3.完整代码</h3>
<p>我们导入酒店数据，基本流程一致，但是需要考虑几点变化：</p>
<ul>
<li>酒店数据来自于数据库，我们需要先查询出来，得到hotel对象</li>
<li>hotel对象需要转为HotelDoc对象</li>
<li>HotelDoc需要序列化为json格式</li>
</ul>
<p>因此，代码整体步骤如下：</p>
<ul>
<li>1）根据id查询酒店数据Hotel</li>
<li>2）将Hotel封装为HotelDoc</li>
<li>3）将HotelDoc序列化为JSON</li>
<li>4）创建IndexRequest，指定索引库名和id</li>
<li>5）准备请求参数，也就是JSON文档</li>
<li>6）发送请求</li>
</ul>
<p>在hotel-demo的HotelDocumentTest测试类中，编写单元测试：</p>
<pre><code class="language-java">@Test
void testAddDocument() throws IOException {
    // 1.根据id查询酒店数据
    Hotel hotel = hotelService.getById(61083L);
    // 2.转换为文档类型
    HotelDoc hotelDoc = new HotelDoc(hotel);
    // 3.将HotelDoc转json
    String json = JSON.toJSONString(hotelDoc);

    // 1.准备Request对象
    IndexRequest request = new IndexRequest(&quot;hotel&quot;).id(hotelDoc.getId().toString());
    // 2.准备Json文档
    request.source(json, XContentType.JSON);
    // 3.发送请求
    client.index(request, RequestOptions.DEFAULT);
}

</code></pre>
<h2 id="52查询文档">5.2.查询文档</h2>
<h3 id="521语法说明">5.2.1.语法说明</h3>
<p>查询的DSL语句如下：</p>
<pre><code class="language-json">GET /hotel/_doc/{id}

</code></pre>
<p>非常简单，因此代码大概分两步：</p>
<ul>
<li>准备Request对象</li>
<li>发送请求</li>
</ul>
<p>不过查询的目的是得到结果，解析为HotelDoc，因此难点是结果的解析。完整代码如下：</p>
<figure data-type="image" tabindex="33"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720230811674.png" alt="image-20210720230811674" loading="lazy"></figure>
<p>可以看到，结果是一个JSON，其中文档放在一个<code>_source</code>属性中，因此解析就是拿到<code>_source</code>，反序列化为Java对象即可。</p>
<p>与之前类似，也是三步走：</p>
<ul>
<li>1）准备Request对象。这次是查询，所以是GetRequest</li>
<li>2）发送请求，得到结果。因为是查询，这里调用client.get()方法</li>
<li>3）解析结果，就是对JSON做反序列化</li>
</ul>
<h3 id="522完整代码">5.2.2.完整代码</h3>
<p>在hotel-demo的HotelDocumentTest测试类中，编写单元测试：</p>
<pre><code class="language-java">@Test
void testGetDocumentById() throws IOException {
    // 1.准备Request
    GetRequest request = new GetRequest(&quot;hotel&quot;, &quot;61082&quot;);
    // 2.发送请求，得到响应
    GetResponse response = client.get(request, RequestOptions.DEFAULT);
    // 3.解析响应结果
    String json = response.getSourceAsString();

    HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);
    System.out.println(hotelDoc);
}

</code></pre>
<h2 id="53删除文档">5.3.删除文档</h2>
<p>删除的DSL为是这样的：</p>
<pre><code class="language-json">DELETE /hotel/_doc/{id}

</code></pre>
<p>与查询相比，仅仅是请求方式从DELETE变成GET，可以想象Java代码应该依然是三步走：</p>
<ul>
<li>1）准备Request对象，因为是删除，这次是DeleteRequest对象。要指定索引库名和id</li>
<li>2）准备参数，无参</li>
<li>3）发送请求。因为是删除，所以是client.delete()方法</li>
</ul>
<p>在hotel-demo的HotelDocumentTest测试类中，编写单元测试：</p>
<pre><code class="language-java">@Test
void testDeleteDocument() throws IOException {
    // 1.准备Request
    DeleteRequest request = new DeleteRequest(&quot;hotel&quot;, &quot;61083&quot;);
    // 2.发送请求
    client.delete(request, RequestOptions.DEFAULT);
}

</code></pre>
<h2 id="54修改文档">5.4.修改文档</h2>
<h3 id="541语法说明">5.4.1.语法说明</h3>
<p>修改我们讲过两种方式：</p>
<ul>
<li>全量修改：本质是先根据id删除，再新增</li>
<li>增量修改：修改文档中的指定字段值</li>
</ul>
<p>在RestClient的API中，全量修改与新增的API完全一致，判断依据是ID：</p>
<ul>
<li>如果新增时，ID已经存在，则修改</li>
<li>如果新增时，ID不存在，则新增</li>
</ul>
<p>这里不再赘述，我们主要关注增量修改。</p>
<p>代码示例如图：</p>
<figure data-type="image" tabindex="34"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720231040875.png" alt="image-20210720231040875" loading="lazy"></figure>
<p>与之前类似，也是三步走：</p>
<ul>
<li>1）准备Request对象。这次是修改，所以是UpdateRequest</li>
<li>2）准备参数。也就是JSON文档，里面包含要修改的字段</li>
<li>3）更新文档。这里调用client.update()方法</li>
</ul>
<h3 id="542完整代码">5.4.2.完整代码</h3>
<p>在hotel-demo的HotelDocumentTest测试类中，编写单元测试：</p>
<pre><code class="language-java">@Test
void testUpdateDocument() throws IOException {
    // 1.准备Request
    UpdateRequest request = new UpdateRequest(&quot;hotel&quot;, &quot;61083&quot;);
    // 2.准备请求参数
    request.doc(
        &quot;price&quot;, &quot;952&quot;,
        &quot;starName&quot;, &quot;四钻&quot;
    );
    // 3.发送请求
    client.update(request, RequestOptions.DEFAULT);
}

</code></pre>
<h2 id="55批量导入文档">5.5.批量导入文档</h2>
<p>案例需求：利用BulkRequest批量将数据库数据导入到索引库中。</p>
<p>步骤如下：</p>
<ul>
<li>
<p>利用mybatis-plus查询酒店数据</p>
</li>
<li>
<p>将查询到的酒店数据（Hotel）转换为文档类型数据（HotelDoc）</p>
</li>
<li>
<p>利用JavaRestClient中的BulkRequest批处理，实现批量新增文档</p>
</li>
</ul>
<h3 id="551语法说明">5.5.1.语法说明</h3>
<p>批量处理BulkRequest，其本质就是将多个普通的CRUD请求组合在一起发送。</p>
<p>其中提供了一个add方法，用来添加其他请求：</p>
<figure data-type="image" tabindex="35"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720232105943.png" alt="image-20210720232105943" loading="lazy"></figure>
<p>可以看到，能添加的请求包括：</p>
<ul>
<li>IndexRequest，也就是新增</li>
<li>UpdateRequest，也就是修改</li>
<li>DeleteRequest，也就是删除</li>
</ul>
<p>因此Bulk中添加了多个IndexRequest，就是批量新增功能了。示例：</p>
<figure data-type="image" tabindex="36"><img src="https://shenshen6666.GitHub.io/post-images/image-20210720232431383.png" alt="image-20210720232431383" loading="lazy"></figure>
<p>其实还是三步走：</p>
<ul>
<li>1）创建Request对象。这里是BulkRequest</li>
<li>2）准备参数。批处理的参数，就是其它Request对象，这里就是多个IndexRequest</li>
<li>3）发起请求。这里是批处理，调用的方法为client.bulk()方法</li>
</ul>
<p>我们在导入酒店数据时，将上述代码改造成for循环处理即可。</p>
<h3 id="552完整代码">5.5.2.完整代码</h3>
<p>在hotel-demo的HotelDocumentTest测试类中，编写单元测试：</p>
<pre><code class="language-java">@Test
void testBulkRequest() throws IOException {
    // 批量查询酒店数据
    List&lt;Hotel&gt; hotels = hotelService.list();

    // 1.创建Request
    BulkRequest request = new BulkRequest();
    // 2.准备参数，添加多个新增的Request
    for (Hotel hotel : hotels) {
        // 2.1.转换为文档类型HotelDoc
        HotelDoc hotelDoc = new HotelDoc(hotel);
        // 2.2.创建新增文档的Request对象
        request.add(new IndexRequest(&quot;hotel&quot;)
                    .id(hotelDoc.getId().toString())
                    .source(JSON.toJSONString(hotelDoc), XContentType.JSON));
    }
    // 3.发送请求
    client.bulk(request, RequestOptions.DEFAULT);
}

</code></pre>
<h2 id="56小结">5.6.小结</h2>
<p>文档操作的基本步骤：</p>
<ul>
<li>初始化RestHighLevelClient</li>
<li>创建XxxRequest。XXX是Index、Get、Update、Delete、Bulk</li>
<li>准备参数（Index、Update、Bulk时需要）</li>
<li>发送请求。调用RestHighLevelClient#.xxx()方法，xxx是index、get、update、delete、bulk</li>
<li>解析结果（Get时需要）</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[深入剖析 Java Stream 的 Collect 操作：解锁高级玩法]]></title>
        <id>https://shenshen6666.GitHub.io/post/jiang-tou-java-stream-de-collect-yong-fa-yu-yuan-li-yuan-bi-ni-xiang-xiang-de-geng-qiang-da/</id>
        <link href="https://shenshen6666.GitHub.io/post/jiang-tou-java-stream-de-collect-yong-fa-yu-yuan-li-yuan-bi-ni-xiang-xiang-de-geng-qiang-da/">
        </link>
        <updated>2023-11-13T07:12:26.000Z</updated>
        <content type="html"><![CDATA[<p>大家好，又见面了。在我前面的文章《吃透 JAVA 的 Stream 流操作，多年实践总结》中，对 Stream 的整体情况进行了细致全面的讲解，也大概介绍了下结果收集器 Collectors 的常见用法 —— 但远不是全部。</p>
<p>本篇文章就来专门剖析 <code>collect</code> 操作，一起解锁更多高级玩法，让 Stream 操作真正成为我们编码中的神兵利器。</p>
<h2 id="初识-collector">初识 Collector</h2>
<p>先看一个简单的场景：现有集团内所有人员列表，需要从中筛选出上海子公司的全部人员。假定人员信息数据如下：</p>
<pre><code class="language-java">姓名       子公司      部门      年龄      工资
大壮       上海公司    研发一部   28       3000
二牛       上海公司    研发一部   24       2000
铁柱       上海公司    研发二部   34       5000
翠花       南京公司    测试一部   27       3000
玲玲       南京公司    测试二部   31       4000
</code></pre>
<p>如果你曾经用过 Stream 流，或者你看过我前面关于 Stream 用法介绍的文章，那么借助 Stream 可以很轻松地实现上述诉求：</p>
<pre><code class="language-java">public void filterEmployeesByCompany() {
    List&lt;Employee&gt; employees = getAllEmployees().stream()
            .filter(employee -&gt; &quot;上海公司&quot;.equals(employee.getSubCompany()))
            .collect(Collectors.toList());
    System.out.println(employees);
}
</code></pre>
<p>上述代码中，先创建流，然后通过一系列中间流操作（filter 方法）进行业务层面的处理，然后经由终止操作（collect 方法）将处理后的结果输出为 List 对象。</p>
<p>但我们实际面对的需求场景中，往往会有一些更复杂的诉求，比如说：现有集团内所有人员列表，需要从中筛选出上海子公司的全部人员，并按照部门进行分组。其实也就是加了个新的分组诉求，那就是先按照前面的代码实现逻辑基础上，再对结果进行分组处理就好：</p>
<pre><code class="language-java">public void filterEmployeesThenGroupByStream() {
    Map&lt;String, List&lt;Employee&gt;&gt; resultMap = getAllEmployees().stream()
            .filter(employee -&gt; &quot;上海公司&quot;.equals(employee.getSubCompany()))
            .collect(Collectors.groupingBy(Employee::getDepartment));
    System.out.println(resultMap);
}
</code></pre>
<p>两种写法都可以得到相同的结果：<br>
{<br>
研发二部=[Employee(subCompany=上海公司, department=研发二部, name=铁柱, age=34, salary=5000)],<br>
研发一部=[Employee(subCompany=上海公司, department=研发一部, name=大壮, age=28, salary=3000),<br>
Employee(subCompany=上海公司, department=研发一部, name=二牛, age=24, salary=2000)]<br>
}<br>
上述两种写法相比而言，第二种是不是代码上要简洁很多？而且是不是有种自注释的味道了？通过 collect 方法的合理恰当利用，可以让 Stream 适应更多实际的使用场景，大大提升我们的开发编码效率。下面就一起来全面认识下 collect，解锁更多高级操作吧。</p>
<p>collect、Collector、Collectors 区别与关联<br>
刚接触 Stream 收集器的时候，很多同学都会被 collect、Collector、Collectors 这几个概念搞的晕头转向，甚至还有很多人即使已经使用 Stream 好多年，也只是知道 collect 里面需要传入类似 Collectors.toList() 这种简单的用法，对其背后的细节也不甚了解。</p>
<p>这里以一个 collect 收集器最简单的使用场景来剖析说明下其中的关系：</p>
<p>概括来说：</p>
<p>collect 是 Stream 流的一个终止方法，会使用传入的收集器（入参）对结果执行相关的操作，这个收集器必须是 Collector 接口的某个具体实现类。<br>
Collector 是一个接口，collect 方法的收集器是 Collector 接口的具体实现类。<br>
Collectors 是一个工具类，提供了很多的静态工厂方法，提供了很多 Collector 接口的具体实现类，是为了方便程序员使用而预置的一些较为通用的收集器（如果不使用 Collectors 类，而是自己去实现 Collector 接口，也可以）。<br>
Collector 使用与剖析<br>
到这里我们可以看出，Stream 结果收集操作的本质，其实就是将 Stream 中的元素通过收集器定义的函数处理逻辑进行加工，然后输出加工后的结果。</p>
<p>根据其执行的操作类型来划分，又可将收集器分为几种不同的大类。下面分别阐述下。</p>
<h2 id="恒等处理-collector">恒等处理 Collector</h2>
<p>所谓恒等处理，指的就是 Stream 的元素在经过 Collector 函数处理前后完全不变，例如 <code>toList()</code> 操作，只是最终将结果从 Stream 中取出放入到 <code>List</code> 对象中，并没有对元素本身做任何的更改处理。</p>
<p>恒等处理类型的 Collector 是实际编码中最常被使用的一种，比如：</p>
<pre><code class="language-java">list.stream().collect(Collectors.toList());
list.stream().collect(Collectors.toSet());
list.stream().collect(Collectors.toCollection());
</code></pre>
<h2 id="归约汇总-collector">归约汇总 Collector</h2>
<p>对于归约汇总类的操作，Stream 流中的元素逐个遍历，进入到 Collector 处理函数中，然后会与上一个元素的处理结果进行合并处理，并得到一个新的结果，以此类推，直到遍历完成后，输出最终的结果。比如 Collectors.summingInt() 方法的处理逻辑如下：</p>
<p>例如，如果需要计算上海子公司每个月需要支付的员工总工资，使用 Collectors.summingInt() 可以这么实现</p>
<pre><code class="language-java">public void calculateSum() {
    Integer salarySum = getAllEmployees().stream()
            .filter(employee -&gt; &quot;上海公司&quot;.equals(employee.getSubCompany()))
            .collect(Collectors.summingInt(Employee::getSalary));
    System.out.println(salarySum);
}
</code></pre>
<p>需要注意的是，这里的汇总计算不仅仅是数学层面的累加汇总，而是一个广义上的汇总概念，即将多个元素进行处理操作，最终生成 1 个结果的操作，比如计算 Stream 中最大值的操作，最终也是多个元素中，得到一个结果：</p>
<p>使用 max 方法来简化，即上述代码与下面的写法等价：</p>
<pre><code class="language-java">public void findHighestSalaryEmployee2() {
    Optional&lt;Employee&gt; highestSalaryEmployee = getAllEmployees().stream()
            .filter(employee -&gt; &quot;上海公司&quot;.equals(employee.getSubCompany()))
            .max(Comparator.comparingInt(Employee::getSalary));
    System.out.println(highestSalaryEmployee.get());
}
</code></pre>
<h2 id="分组分区-collector">分组分区 Collector</h2>
<p>Collectors 工具类中提供了 groupingBy 方法用来得到一个分组操作 Collector，其内部处理逻辑可以参见下图的说明：</p>
<p>groupingBy() 操作需要指定两个关键输入，即分组函数和值收集器：</p>
<p>分组函数：一个处理函数，用于基于指定的元素进行处理，返回一个用于分组的值（即分组结果 HashMap 的 Key 值），对于经过此函数处理后返回值相同的元素，将被分配到同一个组里。<br>
值收集器：对于分组后的数据元素的进一步处理转换逻辑，此处还是一个常规的 Collector 收集器，和 collect() 方法中传入的收集器完全等同。<br>
对于 groupingBy 分组操作而言，分组函数与值收集器二者必不可少。为了方便使用，在 Collectors 工具类中，提供了两个 groupingBy 重载实现，其中有一个方法只需要传入一个分组函数即可，这是因为其默认使用了 toList() 作为值收集器：</p>
<p>例如：仅仅是做一个常规的数据分组操作时，可以仅传入一个分组函数即可：</p>
<pre><code class="language-Java">public void groupBySubCompany() {
    // 按照子公司维度将员工分组
    ```java
    Map&lt;String, List&lt;Employee&gt;&gt; resultMap =
            getAllEmployees().stream()
                    .collect(Collectors.groupingBy(Employee::getSubCompany));
    System.out.println(resultMap);
}
</code></pre>
<p>这样 collect 返回的结果就是一个 HashMap，其每一个 HashValue 的值为一个 List 类型。</p>
<p>而如果不仅需要分组，还需要对分组后的数据进行处理的时候，则需要同时给定分组函数以及值收集器：</p>
<pre><code class="language-java">public void groupAndCaculate() {
    // 按照子公司分组，并统计每个子公司的员工数
    Map&lt;String, Long&gt; resultMap = getAllEmployees().stream()
            .collect(Collectors.groupingBy(Employee::getSubCompany,
                    Collectors.counting()));
    System.out.println(resultMap);
}
</code></pre>
<p>这样就同时实现了分组与组内数据的处理操作：<br>
{南京公司=2, 上海公司=3}<br>
上面的代码中 Collectors.groupingBy() 是一个分组 Collector，而其内又传入了一个归约汇总 Collector Collectors.counting()，也就是一个收集器中嵌套了另一个收集器。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java项目的代码如何实现]]></title>
        <id>https://shenshen6666.GitHub.io/post/ping-lun-ce-shi/</id>
        <link href="https://shenshen6666.GitHub.io/post/ping-lun-ce-shi/">
        </link>
        <updated>2023-05-19T08:07:32.000Z</updated>
        <content type="html"><![CDATA[<p>Java项目的代码实现基本是使用Java语言进行编写，Java代码的编写遵循一定的规范和约定。本文将介绍Java项目代码实现的主要概念和技术。</p>
<p>1.类和对象<br>
Java是一种面向对象的语言，类是创建Java对象的模板，而对象则是类的一个实例。在Java中，类具有属性和方法。属性是类的特征，而方法是执行的操作。在Java中使用关键字“class”声明一个类。类的属性和方法都可以由访问修饰符控制访问级别，包括public、private、protected和default。</p>
<p>2.继承<br>
Java中可以使用继承概念来实现代码的复用。子类可以继承父类的属性和方法，并可以添加自己的属性和方法。使用关键字“extends”来实现继承。在Java中，子类只能继承一个父类。</p>
<p>3.接口<br>
Java中的接口表示一组方法的声明，但是这些方法没有实现。通过实现接口，类可以具有接口的功能。在Java中使用关键字“interface”声明一个接口。类实现一个接口，并通过关键字“implements”来进行声明。</p>
<p>4.包<br>
Java中的包是一种组织代码的方式。它提供了一种将相关类和接口组合在一起的方式，以便开发人员可以更好地组织代码，使代码更具可读性。Java中使用关键字“package”来声明一个包。</p>
<p>5.异常处理<br>
Java中的异常处理是一个非常重要的概念。当代码出现异常时，可以使用异常处理来捕获和处理异常。异常处理的基础是Java中的try-catch块。try块中包含可能会产生异常的代码，而catch块则用于处理捕获到的异常。</p>
<p>6.注解<br>
Java中的注解是用于定义和标记代码元素的一种机制。注解可以在代码的类、方法、参数、变量等位置使用。在Java中使用@符号来表示一个注解，可以包含一些参数。注解可以帮助防止代码错误、增强代码可读性和更好地管理代码。</p>
<p>7.泛型<br>
Java中的泛型是一种允许在代码中使用类型参数的语言特性。类型参数允许开发人员编写通用代码，该代码可以与多种类型一起使用。在Java中，泛型由尖括号“&lt;&gt;”表示，其中包含类型参数。</p>
<p>8.多线程<br>
Java中的多线程允许同时执行多个线程，以提高程序的性能。Java中的多线程是基于线程类Thread实现的。线程的状态包括新建状态、运行状态、阻塞状态、等待状态和死亡状态。使用synchronized关键字可以控制线程之间的并发性和同步性。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringCloud02]]></title>
        <id>https://shenshen6666.GitHub.io/post/2/</id>
        <link href="https://shenshen6666.GitHub.io/post/2/">
        </link>
        <updated>2023-02-23T11:04:13.000Z</updated>
        <content type="html"><![CDATA[<h1 id="springcloud实用篇02">SpringCloud实用篇02</h1>
<h1 id="0学习目标">0.学习目标</h1>
<h1 id="1nacos配置管理">1.Nacos配置管理</h1>
<p>Nacos除了可以做注册中心，同样可以做配置管理来使用。</p>
<h2 id="11统一配置管理">1.1.统一配置管理</h2>
<p>当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。</p>
<figure data-type="image" tabindex="1"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714164426792.png" alt="image-20210714164426792" loading="lazy"></figure>
<p>Nacos一方面可以将配置集中管理，另一方可以在配置变更时，及时通知微服务，实现配置的热更新。</p>
<h3 id="111在nacos中添加配置文件">1.1.1.在nacos中添加配置文件</h3>
<p>如何在nacos中管理配置呢？</p>
<figure data-type="image" tabindex="2"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714164742924.png" alt="image-20210714164742924" loading="lazy"></figure>
<p>然后在弹出的表单中，填写配置信息：</p>
<figure data-type="image" tabindex="3"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714164856664.png" alt="image-20210714164856664" loading="lazy"></figure>
<blockquote>
<p>注意：项目的核心配置，需要热更新的配置才有放到nacos管理的必要。基本不会变更的一些配置还是保存在微服务本地比较好。</p>
</blockquote>
<h3 id="112从微服务拉取配置">1.1.2.从微服务拉取配置</h3>
<p>微服务要拉取nacos中管理的配置，并且与本地的application.yml配置合并，才能完成项目启动。</p>
<p>但如果尚未读取application.yml，又如何得知nacos地址呢？</p>
<p>因此spring引入了一种新的配置文件：bootstrap.yaml文件，会在application.yml之前被读取，流程如下：</p>
<figure data-type="image" tabindex="4"><img src="assets/L0iFYNF.png" alt="img" loading="lazy"></figure>
<p>1）引入nacos-config依赖</p>
<p>首先，在user-service服务中，引入nacos-config的客户端依赖：</p>
<pre><code class="language-xml">&lt;!--nacos配置管理依赖--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>2）添加bootstrap.yaml</p>
<p>然后，在user-service中添加一个bootstrap.yaml文件，内容如下：</p>
<pre><code class="language-yaml">spring:
  application:
    name: userservice # 服务名称
  profiles:
    active: dev #开发环境，这里是dev 
  cloud:
    nacos:
      server-addr: localhost:8848 # Nacos地址
      config:
        file-extension: yaml # 文件后缀名
</code></pre>
<p>这里会根据spring.cloud.nacos.server-addr获取nacos地址，再根据</p>
<p><code>${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}</code>作为文件id，来读取配置。</p>
<p>本例中，就是去读取<code>userservice-dev.yaml</code>：</p>
<figure data-type="image" tabindex="5"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714170845901.png" alt="image-20210714170845901" loading="lazy"></figure>
<p>3）读取nacos配置</p>
<p>在user-service中的UserController中添加业务逻辑，读取pattern.dateformat配置：</p>
<figure data-type="image" tabindex="6"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714170337448.png" alt="image-20210714170337448" loading="lazy"></figure>
<p>完整代码：</p>
<pre><code class="language-java">package cn.itcast.user.web;

import cn.itcast.user.pojo.User;
import cn.itcast.user.service.UserService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.*;

import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;

@Slf4j
@RestController
@RequestMapping(&quot;/user&quot;)
public class UserController {

    @Autowired
    private UserService userService;

    @Value(&quot;${pattern.dateformat}&quot;)
    private String dateformat;
    
    @GetMapping(&quot;now&quot;)
    public String now(){
        return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat));
    }
    // ...略
}
</code></pre>
<p>在页面访问，可以看到效果：</p>
<figure data-type="image" tabindex="7"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714170449612.png" alt="image-20210714170449612" loading="lazy"></figure>
<h2 id="12配置热更新">1.2.配置热更新</h2>
<p>我们最终的目的，是修改nacos中的配置后，微服务中无需重启即可让配置生效，也就是<strong>配置热更新</strong>。</p>
<p>要实现配置热更新，可以使用两种方式：</p>
<h3 id="121方式一">1.2.1.方式一</h3>
<p>在@Value注入的变量所在类上添加注解@RefreshScope：</p>
<figure data-type="image" tabindex="8"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714171036335.png" alt="image-20210714171036335" loading="lazy"></figure>
<h3 id="122方式二">1.2.2.方式二</h3>
<p>使用@ConfigurationProperties注解代替@Value注解。</p>
<p>在user-service服务中，添加一个类，读取patterrn.dateformat属性：</p>
<pre><code class="language-java">package cn.itcast.user.config;

import lombok.Data;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.stereotype.Component;

@Component
@Data
@ConfigurationProperties(prefix = &quot;pattern&quot;)
public class PatternProperties {
    private String dateformat;
}
</code></pre>
<p>在UserController中使用这个类代替@Value：</p>
<figure data-type="image" tabindex="9"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714171316124.png" alt="image-20210714171316124" loading="lazy"></figure>
<p>完整代码：</p>
<pre><code class="language-java">package cn.itcast.user.web;

import cn.itcast.user.config.PatternProperties;
import cn.itcast.user.pojo.User;
import cn.itcast.user.service.UserService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;

@Slf4j
@RestController
@RequestMapping(&quot;/user&quot;)
public class UserController {

    @Autowired
    private UserService userService;

    @Autowired
    private PatternProperties patternProperties;

    @GetMapping(&quot;now&quot;)
    public String now(){
        return LocalDateTime.now().format(DateTimeFormatter.ofPattern(patternProperties.getDateformat()));
    }

    // 略
}
</code></pre>
<h2 id="13配置共享">1.3.配置共享</h2>
<p>其实微服务启动时，会去nacos读取多个配置文件，例如：</p>
<ul>
<li>
<p><code>[spring.application.name]-[spring.profiles.active].yaml</code>，例如：userservice-dev.yaml</p>
</li>
<li>
<p><code>[spring.application.name].yaml</code>，例如：userservice.yaml</p>
</li>
</ul>
<p>而<code>[spring.application.name].yaml</code>不包含环境，因此可以被多个环境共享。</p>
<p>下面我们通过案例来测试配置共享</p>
<h3 id="1添加一个环境共享配置">1）添加一个环境共享配置</h3>
<p>我们在nacos中添加一个userservice.yaml文件：</p>
<figure data-type="image" tabindex="10"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714173233650.png" alt="image-20210714173233650" loading="lazy"></figure>
<h3 id="2在user-service中读取共享配置">2）在user-service中读取共享配置</h3>
<p>在user-service服务中，修改PatternProperties类，读取新添加的属性：</p>
<figure data-type="image" tabindex="11"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714173324231.png" alt="image-20210714173324231" loading="lazy"></figure>
<p>在user-service服务中，修改UserController，添加一个方法：</p>
<figure data-type="image" tabindex="12"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714173721309.png" alt="image-20210714173721309" loading="lazy"></figure>
<h3 id="3运行两个userapplication使用不同的profile">3）运行两个UserApplication，使用不同的profile</h3>
<p>修改UserApplication2这个启动项，改变其profile值：</p>
<figure data-type="image" tabindex="13"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714173538538.png" alt="image-20210714173538538" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714173519963.png" alt="image-20210714173519963" loading="lazy"></figure>
<p>这样，UserApplication(8081)使用的profile是dev，UserApplication2(8082)使用的profile是test。</p>
<p>启动UserApplication和UserApplication2</p>
<p>访问http://localhost:8081/user/prop，结果：</p>
<figure data-type="image" tabindex="15"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714174313344.png" alt="image-20210714174313344" loading="lazy"></figure>
<p>访问http://localhost:8082/user/prop，结果：</p>
<figure data-type="image" tabindex="16"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714174424818.png" alt="image-20210714174424818" loading="lazy"></figure>
<p>可以看出来，不管是dev，还是test环境，都读取到了envSharedValue这个属性的值。</p>
<h3 id="4配置共享的优先级">4）配置共享的优先级</h3>
<p>当nacos、服务本地同时出现相同属性时，优先级有高低之分：</p>
<figure data-type="image" tabindex="17"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714174623557.png" alt="image-20210714174623557" loading="lazy"></figure>
<h2 id="14搭建nacos集群">1.4.搭建Nacos集群</h2>
<p>Nacos生产环境下一定要部署为集群状态，部署方式参考课前资料中的文档：</p>
<figure data-type="image" tabindex="18"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714174728042.png" alt="image-20210714174728042" loading="lazy"></figure>
<h1 id="2feign远程调用">2.Feign远程调用</h1>
<p>先来看我们以前利用RestTemplate发起远程调用的代码：</p>
<figure data-type="image" tabindex="19"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714174814204.png" alt="image-20210714174814204" loading="lazy"></figure>
<p>存在下面的问题：</p>
<p>•代码可读性差，编程体验不统一</p>
<p>•参数复杂URL难以维护</p>
<p>Feign是一个声明式的http客户端，官方地址：https://github.com/OpenFeign/feign</p>
<p>其作用就是帮助我们优雅的实现http请求的发送，解决上面提到的问题。</p>
<figure data-type="image" tabindex="20"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714174918088.png" alt="image-20210714174918088" loading="lazy"></figure>
<h2 id="21feign替代resttemplate">2.1.Feign替代RestTemplate</h2>
<p>Fegin的使用步骤如下：</p>
<h3 id="1引入依赖">1）引入依赖</h3>
<p>我们在order-service服务的pom文件中引入feign的依赖：</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="2添加注解">2）添加注解</h3>
<p>在order-service的启动类添加注解开启Feign的功能：</p>
<figure data-type="image" tabindex="21"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714175102524.png" alt="image-20210714175102524" loading="lazy"></figure>
<h3 id="3编写feign的客户端">3）编写Feign的客户端</h3>
<p>在order-service中新建一个接口，内容如下：</p>
<pre><code class="language-java">package cn.itcast.order.client;

import cn.itcast.order.pojo.User;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;

@FeignClient(&quot;userservice&quot;)
public interface UserClient {
    @GetMapping(&quot;/user/{id}&quot;)
    User findById(@PathVariable(&quot;id&quot;) Long id);
}
</code></pre>
<p>这个客户端主要是基于SpringMVC的注解来声明远程调用的信息，比如：</p>
<ul>
<li>服务名称：userservice</li>
<li>请求方式：GET</li>
<li>请求路径：/user/{id}</li>
<li>请求参数：Long id</li>
<li>返回值类型：User</li>
</ul>
<p>这样，Feign就可以帮助我们发送http请求，无需自己使用RestTemplate来发送了。</p>
<h3 id="4测试">4）测试</h3>
<p>修改order-service中的OrderService类中的queryOrderById方法，使用Feign客户端代替RestTemplate：</p>
<figure data-type="image" tabindex="22"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714175415087.png" alt="image-20210714175415087" loading="lazy"></figure>
<p>是不是看起来优雅多了。</p>
<h3 id="5总结">5）总结</h3>
<p>使用Feign的步骤：</p>
<p>① 引入依赖</p>
<p>② 添加@EnableFeignClients注解</p>
<p>③ 编写FeignClient接口</p>
<p>④ 使用FeignClient中定义的方法代替RestTemplate</p>
<h2 id="22自定义配置">2.2.自定义配置</h2>
<p>Feign可以支持很多的自定义配置，如下表所示：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>作用</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>feign.Logger.Level</strong></td>
<td>修改日志级别</td>
<td>包含四种不同的级别：NONE、BASIC、HEADERS、FULL</td>
</tr>
<tr>
<td>feign.codec.Decoder</td>
<td>响应结果的解析器</td>
<td>http远程调用的结果做解析，例如解析json字符串为java对象</td>
</tr>
<tr>
<td>feign.codec.Encoder</td>
<td>请求参数编码</td>
<td>将请求参数编码，便于通过http请求发送</td>
</tr>
<tr>
<td>feign. Contract</td>
<td>支持的注解格式</td>
<td>默认是SpringMVC的注解</td>
</tr>
<tr>
<td>feign. Retryer</td>
<td>失败重试机制</td>
<td>请求失败的重试机制，默认是没有，不过会使用Ribbon的重试</td>
</tr>
</tbody>
</table>
<p>一般情况下，默认值就能满足我们使用，如果要自定义时，只需要创建自定义的@Bean覆盖默认Bean即可。</p>
<p>下面以日志为例来演示如何自定义配置。</p>
<h3 id="221配置文件方式">2.2.1.配置文件方式</h3>
<p>基于配置文件修改feign的日志级别可以针对单个服务：</p>
<pre><code class="language-yaml">feign:  
  client:
    config: 
      userservice: # 针对某个微服务的配置
        loggerLevel: FULL #  日志级别 
</code></pre>
<p>也可以针对所有服务：</p>
<pre><code class="language-yaml">feign:  
  client:
    config: 
      default: # 这里用default就是全局配置，如果是写服务名称，则是针对某个微服务的配置
        loggerLevel: FULL #  日志级别 

</code></pre>
<p>而日志的级别分为四种：</p>
<ul>
<li>NONE：不记录任何日志信息，这是默认值。</li>
<li>BASIC：仅记录请求的方法，URL以及响应状态码和执行时间</li>
<li>HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息</li>
<li>FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。</li>
</ul>
<h3 id="222java代码方式">2.2.2.Java代码方式</h3>
<p>也可以基于Java代码来修改日志级别，先声明一个类，然后声明一个Logger.Level的对象：</p>
<pre><code class="language-java">public class DefaultFeignConfiguration  {
    @Bean
    public Logger.Level feignLogLevel(){
        return Logger.Level.BASIC; // 日志级别为BASIC
    }
}

</code></pre>
<p>如果要<strong>全局生效</strong>，将其放到启动类的@EnableFeignClients这个注解中：</p>
<pre><code class="language-java">@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration .class) 

</code></pre>
<p>如果是<strong>局部生效</strong>，则把它放到对应的@FeignClient这个注解中：</p>
<pre><code class="language-java">@FeignClient(value = &quot;userservice&quot;, configuration = DefaultFeignConfiguration .class) 

</code></pre>
<h2 id="23feign使用优化">2.3.Feign使用优化</h2>
<p>Feign底层发起http请求，依赖于其它的框架。其底层客户端实现包括：</p>
<p>•URLConnection：默认实现，不支持连接池</p>
<p>•Apache HttpClient ：支持连接池</p>
<p>•OKHttp：支持连接池</p>
<p>因此提高Feign的性能主要手段就是使用<strong>连接池</strong>代替默认的URLConnection。</p>
<p>这里我们用Apache的HttpClient来演示。</p>
<p>1）引入依赖</p>
<p>在order-service的pom文件中引入Apache的HttpClient依赖：</p>
<pre><code class="language-xml">&lt;!--httpClient的依赖 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt;
    &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<p>2）配置连接池</p>
<p>在order-service的application.yml中添加配置：</p>
<pre><code class="language-yaml">feign:
  client:
    config:
      default: # default全局的配置
        loggerLevel: BASIC # 日志级别，BASIC就是基本的请求和响应信息
  httpclient:
    enabled: true # 开启feign对HttpClient的支持
    max-connections: 200 # 最大的连接数
    max-connections-per-route: 50 # 每个路径的最大连接数

</code></pre>
<p>接下来，在FeignClientFactoryBean中的loadBalance方法中打断点：</p>
<figure data-type="image" tabindex="23"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714185925910.png" alt="image-20210714185925910" loading="lazy"></figure>
<p>Debug方式启动order-service服务，可以看到这里的client，底层就是Apache HttpClient：</p>
<figure data-type="image" tabindex="24"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714190041542.png" alt="image-20210714190041542" loading="lazy"></figure>
<p>总结，Feign的优化：</p>
<p>1.日志级别尽量用basic</p>
<p>2.使用HttpClient或OKHttp代替URLConnection</p>
<p>①  引入feign-httpClient依赖</p>
<p>②  配置文件开启httpClient功能，设置连接池参数</p>
<h2 id="24最佳实践">2.4.最佳实践</h2>
<p>所谓最近实践，就是使用过程中总结的经验，最好的一种使用方式。</p>
<p>自习观察可以发现，Feign的客户端与服务提供者的controller代码非常相似：</p>
<p>feign客户端：</p>
<figure data-type="image" tabindex="25"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714190542730.png" alt="image-20210714190542730" loading="lazy"></figure>
<p>UserController：</p>
<figure data-type="image" tabindex="26"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714190528450.png" alt="image-20210714190528450" loading="lazy"></figure>
<p>有没有一种办法简化这种重复的代码编写呢？</p>
<h3 id="241继承方式">2.4.1.继承方式</h3>
<p>一样的代码可以通过继承来共享：</p>
<p>1）定义一个API接口，利用定义方法，并基于SpringMVC注解做声明。</p>
<p>2）Feign客户端和Controller都集成改接口</p>
<figure data-type="image" tabindex="27"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714190640857.png" alt="image-20210714190640857" loading="lazy"></figure>
<p>优点：</p>
<ul>
<li>简单</li>
<li>实现了代码共享</li>
</ul>
<p>缺点：</p>
<ul>
<li>
<p>服务提供方、服务消费方紧耦合</p>
</li>
<li>
<p>参数列表中的注解映射并不会继承，因此Controller中必须再次声明方法、参数列表、注解</p>
</li>
</ul>
<h3 id="242抽取方式">2.4.2.抽取方式</h3>
<p>将Feign的Client抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，提供给所有消费者使用。</p>
<p>例如，将UserClient、User、Feign的默认配置都抽取到一个feign-api包中，所有微服务引用该依赖包，即可直接使用。</p>
<figure data-type="image" tabindex="28"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714214041796.png" alt="image-20210714214041796" loading="lazy"></figure>
<h3 id="243实现基于抽取的最佳实践">2.4.3.实现基于抽取的最佳实践</h3>
<h4 id="1抽取">1）抽取</h4>
<p>首先创建一个module，命名为feign-api：</p>
<figure data-type="image" tabindex="29"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714204557771.png" alt="image-20210714204557771" loading="lazy"></figure>
<p>项目结构：</p>
<figure data-type="image" tabindex="30"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714204656214.png" alt="image-20210714204656214" loading="lazy"></figure>
<p>在feign-api中然后引入feign的starter依赖</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<p>然后，order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中</p>
<figure data-type="image" tabindex="31"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714205221970.png" alt="image-20210714205221970" loading="lazy"></figure>
<h4 id="2在order-service中使用feign-api">2）在order-service中使用feign-api</h4>
<p>首先，删除order-service中的UserClient、User、DefaultFeignConfiguration等类或接口。</p>
<p>在order-service的pom文件中中引入feign-api的依赖：</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;cn.itcast.demo&lt;/groupId&gt;
    &lt;artifactId&gt;feign-api&lt;/artifactId&gt;
    &lt;version&gt;1.0&lt;/version&gt;
&lt;/dependency&gt;

</code></pre>
<p>修改order-service中的所有与上述三个组件有关的导包部分，改成导入feign-api中的包</p>
<h4 id="3重启测试">3）重启测试</h4>
<p>重启后，发现服务报错了：</p>
<figure data-type="image" tabindex="32"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714205623048.png" alt="image-20210714205623048" loading="lazy"></figure>
<p>这是因为UserClient现在在cn.itcast.feign.clients包下，</p>
<p>而order-service的@EnableFeignClients注解是在cn.itcast.order包下，不在同一个包，无法扫描到UserClient。</p>
<h4 id="4解决扫描包问题">4）解决扫描包问题</h4>
<p>方式一：</p>
<p>指定Feign应该扫描的包：</p>
<pre><code class="language-java">@EnableFeignClients(basePackages = &quot;cn.itcast.feign.clients&quot;)

</code></pre>
<p>方式二：</p>
<p>指定需要加载的Client接口：</p>
<pre><code class="language-java">@EnableFeignClients(clients = {UserClient.class})

</code></pre>
<h1 id="3gateway服务网关">3.Gateway服务网关</h1>
<p>Spring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。</p>
<h2 id="31为什么需要网关">3.1.为什么需要网关</h2>
<p>Gateway网关是我们服务的守门神，所有微服务的统一入口。</p>
<p>网关的<strong>核心功能特性</strong>：</p>
<ul>
<li>请求路由</li>
<li>权限控制</li>
<li>限流</li>
</ul>
<p>架构图：</p>
<figure data-type="image" tabindex="33"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714210131152.png" alt="image-20210714210131152" loading="lazy"></figure>
<p><strong>权限控制</strong>：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。</p>
<p><strong>路由和负载均衡</strong>：一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。</p>
<p><strong>限流</strong>：当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。</p>
<p>在SpringCloud中网关的实现包括两种：</p>
<ul>
<li>gateway</li>
<li>zuul</li>
</ul>
<p>Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于响应式编程的实现，具备更好的性能。</p>
<h2 id="32gateway快速入门">3.2.gateway快速入门</h2>
<p>下面，我们就演示下网关的基本路由功能。基本步骤如下：</p>
<ol>
<li>创建SpringBoot工程gateway，引入网关依赖</li>
<li>编写启动类</li>
<li>编写基础配置和路由规则</li>
<li>启动网关服务进行测试</li>
</ol>
<h3 id="1创建gateway服务引入依赖">1）创建gateway服务，引入依赖</h3>
<p>创建服务：</p>
<figure data-type="image" tabindex="34"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714210919458.png" alt="image-20210714210919458" loading="lazy"></figure>
<p>引入依赖：</p>
<pre><code class="language-xml">&lt;!--网关--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;!--nacos服务发现依赖--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
&lt;/dependency&gt;

</code></pre>
<h3 id="2编写启动类">2）编写启动类</h3>
<pre><code class="language-java">package cn.itcast.gateway;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class GatewayApplication {

	public static void main(String[] args) {
		SpringApplication.run(GatewayApplication.class, args);
	}
}

</code></pre>
<h3 id="3编写基础配置和路由规则">3）编写基础配置和路由规则</h3>
<p>创建application.yml文件，内容如下：</p>
<pre><code class="language-yaml">server:
  port: 10010 # 网关端口
spring:
  application:
    name: gateway # 服务名称
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes: # 网关路由配置
        - id: user-service # 路由id，自定义，只要唯一即可
          # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址
          uri: lb://userservice # 路由的目标地址 lb就是负载均衡，后面跟服务名称
          predicates: # 路由断言，也就是判断请求是否符合路由规则的条件
            - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求

</code></pre>
<p>我们将符合<code>Path</code> 规则的一切请求，都代理到 <code>uri</code>参数指定的地址。</p>
<p>本例中，我们将 <code>/user/**</code>开头的请求，代理到<code>lb://userservice</code>，lb是负载均衡，根据服务名拉取服务列表，实现负载均衡。</p>
<h3 id="4重启测试">4）重启测试</h3>
<p>重启网关，访问http://localhost:10010/user/1时，符合<code>/user/**</code>规则，请求转发到uri：http://userservice/user/1，得到了结果：</p>
<figure data-type="image" tabindex="35"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714211908341.png" alt="image-20210714211908341" loading="lazy"></figure>
<h3 id="5网关路由的流程图">5）网关路由的流程图</h3>
<p>整个访问的流程如下：</p>
<figure data-type="image" tabindex="36"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714211742956.png" alt="image-20210714211742956" loading="lazy"></figure>
<p>总结：</p>
<p>网关搭建步骤：</p>
<ol>
<li>
<p>创建项目，引入nacos服务发现和gateway依赖</p>
</li>
<li>
<p>配置application.yml，包括服务基本信息、nacos地址、路由</p>
</li>
</ol>
<p>路由配置包括：</p>
<ol>
<li>
<p>路由id：路由的唯一标示</p>
</li>
<li>
<p>路由目标（uri）：路由的目标地址，http代表固定地址，lb代表根据服务名负载均衡</p>
</li>
<li>
<p>路由断言（predicates）：判断路由的规则，</p>
</li>
<li>
<p>路由过滤器（filters）：对请求或响应做处理</p>
</li>
</ol>
<p>接下来，就重点来学习路由断言和路由过滤器的详细知识</p>
<h2 id="33断言工厂">3.3.断言工厂</h2>
<p>我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件</p>
<p>例如Path=/user/**是按照路径匹配，这个规则是由</p>
<p><code>org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory</code>类来</p>
<p>处理的，像这样的断言工厂在SpringCloudGateway还有十几个:</p>
<table>
<thead>
<tr>
<th><strong>名称</strong></th>
<th><strong>说明</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>After</td>
<td>是某个时间点后的请求</td>
<td>-  After=2037-01-20T17:42:47.789-07:00[America/Denver]</td>
</tr>
<tr>
<td>Before</td>
<td>是某个时间点之前的请求</td>
<td>-  Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai]</td>
</tr>
<tr>
<td>Between</td>
<td>是某两个时间点之前的请求</td>
<td>-  Between=2037-01-20T17:42:47.789-07:00[America/Denver],  2037-01-21T17:42:47.789-07:00[America/Denver]</td>
</tr>
<tr>
<td>Cookie</td>
<td>请求必须包含某些cookie</td>
<td>- Cookie=chocolate, ch.p</td>
</tr>
<tr>
<td>Header</td>
<td>请求必须包含某些header</td>
<td>- Header=X-Request-Id, \d+</td>
</tr>
<tr>
<td>Host</td>
<td>请求必须是访问某个host（域名）</td>
<td>-  Host=<strong>.somehost.org,</strong>.anotherhost.org</td>
</tr>
<tr>
<td>Method</td>
<td>请求方式必须是指定方式</td>
<td>- Method=GET,POST</td>
</tr>
<tr>
<td>Path</td>
<td>请求路径必须符合指定规则</td>
<td>- Path=/red/{segment},/blue/**</td>
</tr>
<tr>
<td>Query</td>
<td>请求参数必须包含指定参数</td>
<td>- Query=name, Jack或者-  Query=name</td>
</tr>
<tr>
<td>RemoteAddr</td>
<td>请求者的ip必须是指定范围</td>
<td>- RemoteAddr=192.168.1.1/24</td>
</tr>
<tr>
<td>Weight</td>
<td>权重处理</td>
<td></td>
</tr>
</tbody>
</table>
<p>我们只需要掌握Path这种路由工程就可以了。</p>
<h2 id="34过滤器工厂">3.4.过滤器工厂</h2>
<p>GatewayFilter是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理：</p>
<figure data-type="image" tabindex="37"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714212312871.png" alt="image-20210714212312871" loading="lazy"></figure>
<h3 id="341路由过滤器的种类">3.4.1.路由过滤器的种类</h3>
<p>Spring提供了31种不同的路由过滤器工厂。例如：</p>
<table>
<thead>
<tr>
<th><strong>名称</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>AddRequestHeader</td>
<td>给当前请求添加一个请求头</td>
</tr>
<tr>
<td>RemoveRequestHeader</td>
<td>移除请求中的一个请求头</td>
</tr>
<tr>
<td>AddResponseHeader</td>
<td>给响应结果中添加一个响应头</td>
</tr>
<tr>
<td>RemoveResponseHeader</td>
<td>从响应结果中移除有一个响应头</td>
</tr>
<tr>
<td>RequestRateLimiter</td>
<td>限制请求的流量</td>
</tr>
</tbody>
</table>
<h3 id="342请求头过滤器">3.4.2.请求头过滤器</h3>
<p>下面我们以AddRequestHeader 为例来讲解。</p>
<blockquote>
<p><strong>需求</strong>：给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome!</p>
</blockquote>
<p>只需要修改gateway服务的application.yml文件，添加路由过滤即可：</p>
<pre><code class="language-yaml">spring:
  cloud:
    gateway:
      routes:
      - id: user-service 
        uri: lb://userservice 
        predicates: 
        - Path=/user/** 
        filters: # 过滤器
        - AddRequestHeader=Truth, Itcast is freaking awesome! # 添加请求头

</code></pre>
<p>当前过滤器写在userservice路由下，因此仅仅对访问userservice的请求有效。</p>
<h3 id="343默认过滤器">3.4.3.默认过滤器</h3>
<p>如果要对所有的路由都生效，则可以将过滤器工厂写到default下。格式如下：</p>
<pre><code class="language-yaml">spring:
  cloud:
    gateway:
      routes:
      - id: user-service 
        uri: lb://userservice 
        predicates: 
        - Path=/user/**
      default-filters: # 默认过滤项
      - AddRequestHeader=Truth, Itcast is freaking awesome! 

</code></pre>
<h3 id="344总结">3.4.4.总结</h3>
<p>过滤器的作用是什么？</p>
<p>① 对路由的请求或响应做加工处理，比如添加请求头</p>
<p>② 配置在路由下的过滤器只对当前路由的请求生效</p>
<p>defaultFilters的作用是什么？</p>
<p>① 对所有路由都生效的过滤器</p>
<h2 id="35全局过滤器">3.5.全局过滤器</h2>
<p>上一节学习的过滤器，网关提供了31种，但每一种过滤器的作用都是固定的。如果我们希望拦截请求，做自己的业务逻辑则没办法实现。</p>
<h3 id="351全局过滤器作用">3.5.1.全局过滤器作用</h3>
<p>全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与GatewayFilter的作用一样。区别在于GatewayFilter通过配置定义，处理逻辑是固定的；而GlobalFilter的逻辑需要自己写代码实现。</p>
<p>定义方式是实现GlobalFilter接口。</p>
<pre><code class="language-java">public interface GlobalFilter {
    /**
     *  处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理
     *
     * @param exchange 请求上下文，里面可以获取Request、Response等信息
     * @param chain 用来把请求委托给下一个过滤器 
     * @return {@code Mono&lt;Void&gt;} 返回标示当前过滤器业务结束
     */
    Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain);
}

</code></pre>
<p>在filter中编写自定义逻辑，可以实现下列功能：</p>
<ul>
<li>登录状态判断</li>
<li>权限校验</li>
<li>请求限流等</li>
</ul>
<h3 id="352自定义全局过滤器">3.5.2.自定义全局过滤器</h3>
<p>需求：定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件：</p>
<ul>
<li>
<p>参数中是否有authorization，</p>
</li>
<li>
<p>authorization参数值是否为admin</p>
</li>
</ul>
<p>如果同时满足则放行，否则拦截</p>
<p>实现：</p>
<p>在gateway中定义一个过滤器：</p>
<pre><code class="language-java">package cn.itcast.gateway.filters;

import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.annotation.Order;
import org.springframework.http.HttpStatus;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

@Order(-1)
@Component
public class AuthorizeFilter implements GlobalFilter {
    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        // 1.获取请求参数
        MultiValueMap&lt;String, String&gt; params = exchange.getRequest().getQueryParams();
        // 2.获取authorization参数
        String auth = params.getFirst(&quot;authorization&quot;);
        // 3.校验
        if (&quot;admin&quot;.equals(auth)) {
            // 放行
            return chain.filter(exchange);
        }
        // 4.拦截
        // 4.1.禁止访问，设置状态码
        exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN);
        // 4.2.结束处理
        return exchange.getResponse().setComplete();
    }
}

</code></pre>
<h3 id="353过滤器执行顺序">3.5.3.过滤器执行顺序</h3>
<p>请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter</p>
<p>请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器：</p>
<figure data-type="image" tabindex="38"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714214228409.png" alt="image-20210714214228409" loading="lazy"></figure>
<p>排序的规则是什么呢？</p>
<ul>
<li>每一个过滤器都必须指定一个int类型的order值，<strong>order值越小，优先级越高，执行顺序越靠前</strong>。</li>
<li>GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定</li>
<li>路由过滤器和defaultFilter的order由Spring指定，默认是按照声明顺序从1递增。</li>
<li>当过滤器的order值一样时，会按照 defaultFilter &gt; 路由过滤器 &gt; GlobalFilter的顺序执行。</li>
</ul>
<p>详细内容，可以查看源码：</p>
<p><code>org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator#getFilters()</code>方法是先加载defaultFilters，然后再加载某个route的filters，然后合并。</p>
<p><code>org.springframework.cloud.gateway.handler.FilteringWebHandler#handle()</code>方法会加载全局过滤器，与前面的过滤器合并后根据order排序，组织过滤器链</p>
<h2 id="36跨域问题">3.6.跨域问题</h2>
<h3 id="361什么是跨域问题">3.6.1.什么是跨域问题</h3>
<p>跨域：域名不一致就是跨域，主要包括：</p>
<ul>
<li>
<p>域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com</p>
</li>
<li>
<p>域名相同，端口不同：localhost:8080和localhost8081</p>
</li>
</ul>
<p>跨域问题：浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题</p>
<p>解决方案：CORS，这个以前应该学习过，这里不再赘述了。不知道的小伙伴可以查看https://www.ruanyifeng.com/blog/2016/04/cors.html</p>
<h3 id="362模拟跨域问题">3.6.2.模拟跨域问题</h3>
<p>找到课前资料的页面文件：</p>
<figure data-type="image" tabindex="39"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714215713563.png" alt="image-20210714215713563" loading="lazy"></figure>
<p>放入tomcat或者nginx这样的web服务器中，启动并访问。</p>
<p>可以在浏览器控制台看到下面的错误：</p>
<figure data-type="image" tabindex="40"><img src="https://shenshen6666.GitHub.io/post-images/image-20210714215832675.png" alt="image-20210714215832675" loading="lazy"></figure>
<p>从localhost:8090访问localhost:10010，端口不同，显然是跨域的请求。</p>
<h3 id="363解决跨域问题">3.6.3.解决跨域问题</h3>
<p>在gateway服务的application.yml文件中，添加下面的配置：</p>
<pre><code class="language-yaml">spring:
  cloud:
    gateway:
      # 。。。
      globalcors: # 全局的跨域处理
        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
        corsConfigurations:
          '[/**]':
            allowedOrigins: # 允许哪些网站的跨域请求 
              - &quot;http://localhost:8090&quot;
            allowedMethods: # 允许的跨域ajax的请求方式
              - &quot;GET&quot;
              - &quot;POST&quot;
              - &quot;DELETE&quot;
              - &quot;PUT&quot;
              - &quot;OPTIONS&quot;
            allowedHeaders: &quot;*&quot; # 允许在请求中携带的头信息
            allowCredentials: true # 是否允许携带cookie
            maxAge: 360000 # 这次跨域检测的有效期

</code></pre>
]]></content>
    </entry>
</feed>